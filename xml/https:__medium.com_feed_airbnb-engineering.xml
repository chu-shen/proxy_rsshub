<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[The Airbnb Tech Blog - Medium]]></title>
        <description><![CDATA[Creative engineers and data scientists building a world where you can belong anywhere. http://airbnb.io - Medium]]></description>
        <link>https://medium.com/airbnb-engineering?source=rss----53c7c27702d5---4</link>
        <image>
            <url>https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png</url>
            <title>The Airbnb Tech Blog - Medium</title>
            <link>https://medium.com/airbnb-engineering?source=rss----53c7c27702d5---4</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Tue, 06 Jun 2023 01:13:11 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/airbnb-engineering" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Improving Performance with HTTP Streaming]]></title>
            <link>https://medium.com/airbnb-engineering/improving-performance-with-http-streaming-ba9e72c66408?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/ba9e72c66408</guid>
            <category><![CDATA[http-streaming]]></category>
            <category><![CDATA[infrastructure]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[web-performance]]></category>
            <category><![CDATA[server-side-rendering]]></category>
            <dc:creator><![CDATA[Victor]]></dc:creator>
            <pubDate>Wed, 17 May 2023 16:48:22 GMT</pubDate>
            <atom:updated>2023-05-17T16:48:22.122Z</atom:updated>
            <content:encoded><![CDATA[<p>How HTTP Streaming can improve page performance and how Airbnb enabled it on an existing codebase</p><p><strong>By:</strong> <a href="https://www.linkedin.com/in/victorhlin/">Victor Lin</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*q2A2ZjnULygCKIWuiSBKXg.jpeg" /></figure><h3>Introduction</h3><p>You may have heard a joke that the <a href="https://en.wikipedia.org/wiki/Series_of_tubes">Internet is a series of tubes</a>. In this blog post, we’re going to talk about how we get a cool, refreshing stream of Airbnb.com bytes into your browser as quickly as possible using HTTP Streaming.</p><p>Let’s first understand what streaming means. Imagine we had a spigot and two options:</p><ul><li>Fill a big cup, and then pour it all down the tube (the “buffered” strategy)</li><li>Connect the spigot directly to the tube (the “streaming” strategy)</li></ul><p>In the buffered strategy, everything happens sequentially — our servers first generate the entire response into a buffer (filling the cup), and then more time is spent sending it over the network (pouring it down). The streaming strategy happens in parallel. We break the response into chunks, which are sent as soon as they are ready. The server can start working on the next chunk while previous chunks are still being sent, and the client (e.g, a browser) can begin handling the response before it has been fully received.</p><h3>Implementing Streaming at Airbnb</h3><p>Streaming has clear advantages, but most websites today still rely on a buffered approach to generate responses. One reason for this is the additional engineering effort required to break the page into independent chunks. This just isn’t feasible sometimes. For example, if all of the content on the page relies on a slow backend query, then we won’t be able to send anything until that query finishes.</p><p>However, there’s one use case that’s universally applicable. We can use streaming to reduce <strong>network waterfalls</strong>. This term refers to when one network request triggers another, resulting in a cascading series of sequential requests. This is easily visualized in a tool like Chrome’s <a href="https://developer.chrome.com/docs/devtools/network/reference/#waterfall">Waterfall</a>:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*qhOyK4HxTnhImOTPhSA4DQ.png" /><figcaption>Chrome Network Waterfall illustrating a cascade of sequential requests</figcaption></figure><p>Most web pages rely on external JavaScript and CSS files linked within the HTML, resulting in a network waterfall — downloading the HTML triggers JavaScript and CSS downloads. As a result, it’s a best practice to place all CSS and JavaScript tags near the beginning of the HTML in the &lt;head&gt; tag. This ensures that the browser sees them earlier. With streaming, we can reduce this delay further, by sending that portion of the &lt;head&gt; tag first.</p><h3>Early Flush</h3><p>The most straightforward way to send an early &lt;head&gt; tag is by breaking a standard response into two parts. This technique is called <strong>Early Flush</strong>, as one part is sent (“flushed”) before the other.</p><p>The first part contains things that are fast to compute and can be sent quickly. At Airbnb, we include tags for fonts, CSS, and JavaScript, so that we get the browser benefits mentioned above. The second part contains the rest of the page, including content that relies on API or database queries to compute. The end result looks like this:</p><p>Early chunk:</p><pre>&lt;html&gt;<br>  &lt;head&gt;<br>    &lt;script src=… defer /&gt;<br>    &lt;link rel=”stylesheet” href=… /&gt;<br>    &lt;!--lots of other &lt;meta&gt; and other tags… -&gt;</pre><p>Late chunk:</p><pre>&lt;!-- &lt;head&gt; tags that depend on data go here -&gt;<br>  &lt;/head&gt;<br>  &lt;body&gt;<br>    &lt;! — Body content here →<br>  &lt;/body&gt;<br>&lt;/html&gt;</pre><p>We had to restructure our app to make this possible. For context, Airbnb uses an Express-based NodeJS server to render web pages using React. We previously had a single React component in charge of rendering the complete HTML document. However, this presented two problems:</p><ul><li>Producing incremental chunks of content means we need to work with partial/unclosed HTML tags. For example, the examples you saw above are invalid HTML. The &lt;html&gt; and &lt;head&gt; tags are opened in the Early chunk, but closed in the Late chunk. There’s no way to generate this sort of output using the standard React rendering functions.</li><li>We can’t render this component until we have all of the data for it.</li></ul><p>We solved these problems by breaking our monolithic component into three:</p><ul><li>an “Early &lt;head&gt;” component</li><li>a “Late &lt;head&gt;” component, for &lt;head&gt; tags that depend on data</li><li>a “&lt;body&gt;” component</li></ul><p>Each component renders the <em>contents</em> of the head or body tag. Then we stitch them together by writing open/close tags directly to the HTTP response stream. Overall, the process looks like this:</p><ol><li>Write &lt;html&gt;&lt;head&gt;</li><li>Render and write the Early &lt;head&gt; to the response</li><li>Wait for data</li><li>Render and write the Late &lt;head&gt; to the response</li><li>Write &lt;/head&gt;&lt;body&gt;</li><li>Render and write the &lt;body&gt; to the response</li><li>Finish up by writing &lt;/body&gt;&lt;/html&gt;</li></ol><h3>Data Streaming</h3><p>Early Flush optimizes CSS and JavaScript network waterfalls. However, users will still be staring at a blank page until the &lt;body&gt; tag arrives. We’d like to improve this by rendering a loading state when there’s no data, which gets replaced once the data arrives. Conveniently, we already have loading states in this situation for client side routing, so we could accomplish this by just rendering the app without waiting for data!</p><p>Unfortunately, this causes another network waterfall. Browsers have to receive the SSR (Server-Side Render), and then JavaScript triggers another network request to fetch the actual data:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*6kTkLA-UnBm5UGayU0WAcw.png" /><figcaption>Graph showing a network waterfall where SSR and client-side data fetch happen sequentially</figcaption></figure><p>In our testing, this resulted in a slower <em>total</em> loading time.</p><p>What if we could include this data in the HTML? This would allow our server-side rendering and data fetching to happen in parallel:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*AKzOqc2Nd6BcrV-1LZbfxA.png" /><figcaption>Graph showing SSR and client-side data fetch happening in parallel</figcaption></figure><p>Given that we had already broken the page into two chunks with Early Flush, it’s relatively straightforward to introduce a third chunk for what we call <strong>Deferred Data</strong>. This chunk goes after all of the visible content and does not block rendering. We execute the network requests on the server and stream the responses into the Deferred Data chunk. In the end, our three chunks look like this:</p><p>Early chunk</p><pre>&lt;html&gt;<br>  &lt;head&gt;<br>    &lt;link rel=”preload” as=”script” href=… /&gt;<br>    &lt;link rel=”stylesheet” href=… /&gt;<br>    &lt;! — lots of other &lt;meta&gt; and other tags… →</pre><p>Body chunk</p><pre>    &lt;! — &lt;head&gt; tags that depend on data go here →<br>  &lt;/head&gt;<br>  &lt;body&gt;<br>     &lt;! — Body content here →<br>     &lt;script src=… /&gt;</pre><p>Deferred Data chunk</p><pre>    &lt;script type=”application/json” &gt;<br>      &lt;!-- data --&gt;<br>    &lt;/script&gt; <br>  &lt;/body&gt;<br>&lt;/html&gt;</pre><p>With this implemented on the server, the only remaining task is to write some JavaScript to detect when our Deferred Data chunk arrives. We did this with a <a href="https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver">MutationObserver</a>, which is an efficient way to observe DOM changes. Once the Deferred Data JSON element is detected, we parse the result and inject it into our application’s network data store. From the application’s perspective, it’s as though a normal network request has been completed.</p><p><strong>Watch out for `defer`</strong></p><p>You may notice that some tags are re-ordered from the Early Flush example. The script tags moved from the Early chunk to the Body chunk and no longer have the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/script#attributes">defer attribute</a>. This attribute avoids render-blocking script execution by deferring scripts until after the HTML has been downloaded and parsed. This is suboptimal when using Deferred Data, as all of the visible content has already been received by the end of the Body chunk, and we no longer worry about render-blocking at that point. We can fix this by moving the script tags to the end of the Body chunk, and removing the defer attribute. Moving the tags later in the document does introduce a network waterfall, which we solved by adding <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Attributes/rel/preload">preload</a> tags into the Early chunk.</p><h3>Implementation Challenges</h3><h3>Status codes and headers</h3><p>Early Flush prevents subsequent changes to the headers (e.g to redirect or change the status code). In the React + NodeJS world, it’s common to delegate redirects and error throwing to a React app rendered after the data has been fetched. This won’t work if you’ve already sent an early &lt;head&gt; tag and a 200 OK status.</p><p>We solved this problem by moving error and redirect logic out of our React app. That logic is now performed in <a href="https://expressjs.com/en/guide/using-middleware.html">Express server middleware</a> before we attempt to Early Flush.</p><h3>Buffering</h3><p>We found that <a href="https://www.nginx.com/resources/wiki/start/topics/examples/x-accel/#x-accel-buffering">nginx</a> buffer responses by default. This has resource utilization benefits but is counterproductive when the goal is sending incremental responses. We had to configure these services to disable buffering. We expected a potential increase in resource usage with this change but found the impact to be negligible.</p><h3>Response delays</h3><p>We noticed that our Early Flush responses had an unexpected delay of around 200ms, which disappeared when we disabled gzip compression. This turned out to be an interaction between <a href="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">Nagle’s algorithm</a> and <a href="https://en.wikipedia.org/wiki/TCP_delayed_acknowledgment">Delayed ACK</a>. These optimizations attempt to maximize data sent per packet, introducing latency when sending small amounts of data. It’s especially easy to run into this issue with <a href="https://en.wikipedia.org/wiki/Jumbo_frame">jumbo frames</a>, which increases maximum packet sizes. It turns out that gzip reduced the size of our writes to the point where they couldn’t fill a packet, and the solution was to disable Nagle’s algorithm in our <a href="https://www.haproxy.com/documentation/hapee/latest/onepage/#4.2-option%20http-no-delay">haproxy</a> load balancer.</p><h3>Conclusion</h3><p>HTTP Streaming has been a very successful strategy for improving web performance at Airbnb. Our experiments showed that Early Flush produced a flat reduction in <a href="https://web.dev/fcp/">First Contentful Paint</a> (FCP) of around 100ms on every page tested, including the Airbnb homepage. Data streaming further eliminated the FCP costs of slow backend queries. While there were challenges along the way, we found that adapting our existing React application to support streaming was very feasible and robust, despite not being designed for it originally. We’re also excited to see the broader frontend ecosystem trend in the direction of prioritizing streaming, from <a href="https://graphql.org/blog/2020-12-08-improving-latency-with-defer-and-stream-directives/">@defer and @stream in GraphQL</a> to <a href="https://nextjs.org/docs/advanced-features/react-18/streaming">streaming SSR in Next.js</a>. Whether you’re using these new technologies, or extending an existing codebase, we hope you’ll explore streaming to build a faster frontend for all!</p><p>If this type of work interests you, check out some of our related positions <a href="https://careers.airbnb.com/">here</a>.</p><h3>Acknowledgments</h3><p>Elliott Sprehn, Aditya Punjani, Jason Jian, Changgeng Li, Siyuan Zhou, Bruce Paul, Max Sadrieh, and everyone else who helped design and implement streaming at Airbnb!</p><h3>****************</h3><p><em>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ba9e72c66408" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/improving-performance-with-http-streaming-ba9e72c66408">Improving Performance with HTTP Streaming</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Journey Platform: A low-code tool for creating interactive user workflows]]></title>
            <link>https://medium.com/airbnb-engineering/journey-platform-a-low-code-tool-for-creating-interactive-user-workflows-9954f51fa3f8?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/9954f51fa3f8</guid>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[infrastructure]]></category>
            <category><![CDATA[airbnb]]></category>
            <category><![CDATA[technology]]></category>
            <dc:creator><![CDATA[Arjun Raman]]></dc:creator>
            <pubDate>Thu, 11 May 2023 19:13:03 GMT</pubDate>
            <atom:updated>2023-05-11T19:13:03.804Z</atom:updated>
            <content:encoded><![CDATA[<p>Journey Platform: Low-code notification workflow platform that allows technical and non-technical users to create complex workflows through a simple drag and drop user interface.</p><p><strong>By: </strong><a href="https://www.linkedin.com/in/arraman/">Arjun Raman</a>, <a href="https://www.linkedin.com/in/dsalcoda/">Ken Snyder</a>, <a href="https://www.linkedin.com/in/mengtingli1010/">Mengting Li</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*rLBEt8kz__tykm6lCLxDtQ.jpeg" /></figure><h3>Introduction</h3><p>Effective communication hinges on delivering the right message, to the right audience, at the right time. At Airbnb, our goal is to engage our users — both guests and hosts — by delivering inspirational and informational notifications through various channels, such as email or in-app messages.</p><p><a href="https://medium.com/airbnb-engineering/airbnbs-promotions-and-communications-platform-6266f1ffe2bd">Historically</a> at Airbnb, complex notification workflows have been solely managed by engineering teams, with each workflow requiring the deployment of code. As our platform evolved, we recognized the need for a low-code or no-code solution to streamline the creation of these intricate notification workflows. In response, the Marketing Technology team developed the Journey Platform, a powerful tool that enables non-technical users to build and deliver personalized notifications based on our users’ engagement with Airbnb.</p><p>The goals of the Journey Platform are:</p><ol><li>Empower users to easily create event-driven notification workflows using an intuitive drag and drop interface.</li><li>Enable real-time execution of these notification workflows for timely and relevant communication.</li><li>Offer a unified interface for managing transaction notifications, such as upcoming trip reminders and promotional notifications.</li><li>Guarantee Service Level Agreements (SLAs) for processing various types of notification workflows, including transactional and promotional communications.</li><li>Reduce the time required to develop complex notification workflows.</li></ol><p>Journey Platform allows users to iterate faster by allowing self-serve workflow creation. It has reduced the time taken to support a new use-case from 1–2 months to just 1–2 weeks.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*cDveTV8b43tf7n5NDqE5Qw.png" /><figcaption><em>Figure 1: Time saved in Journey Platform</em></figcaption></figure><h3>Overview</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*IGcKH8fAA0EbmTevIoTEYg.png" /><figcaption><em>Figure 2: Journey Platform architecture overview</em></figcaption></figure><p>The key components of the Journey Platform are:</p><ol><li><strong>Journey Platform UI:</strong> <a href="https://en.wikipedia.org/wiki/WYSIWYG">WYSIWYG</a> tool allows users to drag and drop components and create a workflow. The workflow definition is then converted to a custom <a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSL (Domain-specific language)</a> which can be interpreted and executed by the workflow orchestrator.</li><li><strong>Workflow Orchestrator:</strong> Brain of the system, the workflow orchestrator takes in the workflow definition DSL from the UI. Once a workflow is launched, it listens for events from the event store that can start the execution of a workflow, interprets then parses the DSL to execute workflows on the workflow engine, and relies on the Action store to perform specific tasks.</li><li><strong>Platform Store:</strong></li></ol><ul><li>Event Store: Pre-configured catalog of Kafka events which Journey Platform can listen to and trigger new executions of a workflow or pass events to existing workflow execution.</li><li>Action store: Repository of predefined, specific-purpose functions allows users to perform various tasks, such as sending emails, push notifications, or emitting Kafka events. Custom actions can be defined and integrated into the tool, making them accessible to all Journey Platform users.</li><li>Attribute store: Central repository for essential data, such as user metadata (e.g. user’s geolocation, Airbnb search history, etc.) and contextual information. It supports decision-making in workflow branching processes by exposing these data as a parameter to set conditions upon through the parameter manager.</li><li>Custom stores: Ability to create custom action or attribute stores which aren’t already defined in the platform.</li><li>Workflow Orchestrator: Brain of the system, the workflow orchestrator takes in the workflow definition DSL from the UI. Once a workflow is launched, it listens for events from the event store that can start the execution of a workflow, interprets then parses the DSL to execute workflows on the workflow engine, and relies on the Action store to perform specific tasks.</li></ul><h3>User Interface</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Uwbm2Eg4Qr5e3pOyO8jhZQ.png" /><figcaption><em>Figure 3: Manipulating and connecting nodes in a Journey Platform workflow</em></figcaption></figure><p>When crafting the UI for the workflow automation system, we aimed to create a familiar and intuitive experience. Drawing inspiration from flow charts, productivity tools with “inspector panels,” and incorporating drag and drop functionality, we wanted a platform where users could start immediately without consulting the manual.</p><p>We also had a goal of using<strong> </strong><a href="https://www.nngroup.com/articles/progressive-disclosure/">progressive disclosure</a> to incrementally enable the full depth of the platform capabilities, while keeping it simple for users who only need a small subset of the features. By using sensible defaults, and moving more complex features into tabs and sub-screens, our advanced users could create unique solutions, going beyond the pre-planned use cases.</p><p>To edit the graph, we leveraged <a href="https://reactflow.dev/">React Flow</a>, an open-source library. This enabled us to display the graph, as well as provide basic operations like zooming, panning, moving, and connecting nodes. On top of this foundation, we added our custom node and edge components, along with drag and drop functionality for adding new nodes and an inspector panel for editing existing ones.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*qL-7OUZWAmAlj3pnhv3JMw.png" /><figcaption><em>Figure 4: The “node inspector” panel can show a variety of form inputs depending on the type of node.</em></figcaption></figure><p>To create the forms displayed in the inspector panel, we implemented a schema-based form system. This system provides a high level of flexibility, allowing us to declaratively specify the UI for specific node input/output fields as part of their type definitions. The system is built in a type-safe manner, making use of Thrift annotations and Java reflection. Based on the schema information and UI-specific annotations, the interface displays the appropriate form fields, help text, and validation, ensuring our UI is automatically up-to-date with the platform’s capabilities.</p><h3>Backend Design</h3><h4>Domain-specific language</h4><p>DSL provides a high degree of flexibility and customization, allowing us to define the structure and behavior of the workflow. Instead of having to hardcode a workflow in the workflow engine, we instead have a generic workflow defined that can execute any DSL-based workflow. Nodes and edges make up a workflow, with nodes representing individual actions or tasks and edges defining the dependencies and relationships between them.</p><p>The nodes and edges include all the necessary information to define a workflow such as inputs, outputs, and parameters passed between nodes. The DSL generated by the UI is passed to the workflow orchestrator, where the DSL parser executes it.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*nSPRCIm5XLHCSXrem6SQiA.png" /><figcaption><em>Figure 5: Workflow with the translated DSL</em></figcaption></figure><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/f463cc81d674bab88ed62f63cb785f95/href">https://medium.com/media/f463cc81d674bab88ed62f63cb785f95/href</a></iframe><h4>Journey Stores</h4><p>The events, attributes, and actions stores are an integral part of the backend, as they allow listening to events to start workflow executions, filter users, and execute tasks in the journey. All these components work together seamlessly to create a flexible and customizable backend that can be tailored to the specific needs of the platform.</p><h4>Event Store</h4><p>Journey Platform supports listening to different Kafka events and using them to trigger new executions of a workflow, or use the event to pass signals to a running execution. For example, start a new execution when a guest books a stay, pass a signal to a running execution when a user receives a push notification, etc. Similar to the action store, once an event is on-boarded, all the teams at Airbnb can use it.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dwYeU6ZSSe4giRFxvxvHGA.png" /><figcaption><em>Figure 6: Start node with event trigger</em></figcaption></figure><h4>Attribute Store</h4><p>The attribute store functions as a central repository for fetching all necessary data, such as contextual data, user preferences, and device information, which can be used to enrich the workflow branching process and improve decision-making capabilities. These stores are supported by a data storage system that manages various attributes or characteristics of entities.</p><p>Imagine you have a new user who just signed up for Airbnb, and you’re interested in determining whether they’ve conducted any listing searches on the platform. If the answer is yes, you’ll send a personalized message based on their search history, and if it’s no, you’ll send a static message.</p><p>This is a concrete example of how the Airbnb Journey Platform leverages attributes, such as “listing search history,” to enhance the user experience. These attributes are extracted and defined as parameters, which can be used for various purposes. Each workflow execution has its own parameter data collection, which can be accessed in the parameter manager. More information about parameters will be discussed in the parameter manager.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*HC7MXUBiPnPrN5RJShKQiw.png" /><figcaption><em>Figure 7: Setting filter condition using the attribute store</em></figcaption></figure><h4>Action Store</h4><p>The action store is used to execute various tasks, such as sending an email or updating a database record, when a user reaches a specific point in the journey. It is a common library where each function can be shared and reused by different users in their workflow.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/288/1*WwynLKUSwKomtgTI1BCqkg.png" /><figcaption><em>Figure 8: Example Actions supported in Journey platform.</em></figcaption></figure><p>Each action implements a common interface, including its metadata required for the UI schema-based forms mentioned above, and its behavior during the actual workflow execution.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/19e90453917bfbda2d93d2bdbc813e19/href">https://medium.com/media/19e90453917bfbda2d93d2bdbc813e19/href</a></iframe><h4>Parameter Manager</h4><p>Managing a complex workflow that involves multiple steps with varying inputs and outputs can be a challenging task, especially if the input and output parameters change frequently or are different for each user. For instance, you might need conditional branching in your workflow or personalized communication content based on user search. This is where parameterized workflows and parameter managers can prove to be invaluable components.</p><p>By specifying inputs and outputs (of attribute node / event node / custom node) as parameters, you can reuse them throughout the entire workflow execution. A parameter manager is a critical component that can store and manage your workflow parameters, streamlining the process of creating, storing, retrieving, and modifying them.</p><p>In addition to providing an efficient parameter management system, a parameter manager also provides a range of features such as parameter creation, storage, retrieval, modification, versioning, access control, and auditing. These features ensure that your workflow is executed reliably and consistently while also properly managing and storing your parameters throughout the entire workflow.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*yHHuWwktN2QKODdCikDdfg.png" /><figcaption><em>Figure 9: Adding a param from the parameter library</em></figcaption></figure><h3>Workflow Orchestrator</h3><p>The Workflow Orchestrator executes workflows by interpreting the meaning of each DSL node and performing the corresponding actions. It manages low-level functions such as storing state, interacting with the action store to perform an action, listening for callbacks through the event store, and allowing developers to concentrate on workflow logic rather than technical details. Journey Platform utilizes <a href="https://temporal.io/">Temporal</a> as the underlying workflow engine for state maintenance and orchestration. Temporal helps orchestrate workflows through <a href="https://docs.temporal.io/workers">Temporal Workers.</a></p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/c11d9da913e56545a771659b6576f44c/href">https://medium.com/media/c11d9da913e56545a771659b6576f44c/href</a></iframe><p>Developers can incorporate custom functionality such as new nodes or edges to broaden platform capabilities, making it simpler to create workflows that fulfill the platform’s and users’ unique requirements. Additionally, it supports advanced features like parallel execution and automatic retries and enhancing platform reliability and performance.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ED557IlGXfUIUbpxbT7i8w.png" /><figcaption><em>Figure 10: Workflow Orchestrator</em></figcaption></figure><h3>Scaling the system</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*jkld7BHFg8hA-LcubiUjHQ.png" /><figcaption><em>Figure 11: Multi-tenant system with dedicated processing lanes</em></figcaption></figure><p>Ensuring SLA for processing different types of workflows (i.e. transactional and promotional) is critical at scale. Transactional notifications initiated by user action (e.g. booking confirmation, guest/Host messaging, etc.) have a strict SLA and require higher priority when compared to promotional notifications. To achieve this, we have implemented the following at different parts of the system:</p><p><strong>Event pre-processing:</strong></p><ul><li><strong>Pre-filter:</strong> Instead of passing all the events directly to the Workflow Handler, the event processor filters out events that don’t match the criteria. e.g. only pass if the event type is reservation_complete and filter out for all other reservation events. This greatly reduces the QPS feeding into the system.</li><li><strong>Aggregate high QPS events:</strong> Events like searches have a high QPS. Instead of directly processing, we batch and aggregate them over a time window. This reduces the QPS by at least a few orders of magnitude.</li></ul><p><strong>Dedicated lanes:</strong></p><ul><li>We have dedicated lanes for different categories of workflows through the system. The event listener has different consumer groups with built-in throttling. The workflow handler has dedicated <a href="https://docs.temporal.io/namespaces">Temporal namespaces</a> for each category and strict limits on the processing QPS, max QPS to the database, etc.</li></ul><h3>Conclusion</h3><p>The Journey Platform empowers non-technical and technical users to create complex stateful workflows through a simple drag and drop interface. By leveraging a generic workflow definition DSL, along with action store, event store, and attribute store, the platform facilitates the creation of workflows that respond to real-time events, streamlining communication, and enhancing user experiences.</p><p><em>Interested in working at Airbnb? Check out </em><a href="https://careers.airbnb.com/"><em>these open roles</em></a><em>.</em></p><h3>Acknowledgments</h3><p>Thanks to Balaji Kalaimani, Davis Wamola, Iris Feng, Jesse Garrison, John Bernardo, Kumar Arjunan, Michael Endelman, Priyank Singhal, Steve Krulewitz, Tej Sudha, Victoria Gryn, Xin Tu, and Zhentao Sun for their contributions in building Journey Platform.</p><p>Thanks to Sagar Naik and Michael Kinoti for their leadership and supporting us in this <em>Journey</em>.</p><h3>****************</h3><p><em>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=9954f51fa3f8" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/journey-platform-a-low-code-tool-for-creating-interactive-user-workflows-9954f51fa3f8">Journey Platform: A low-code tool for creating interactive user workflows</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Flexible Continuous Integration for iOS]]></title>
            <link>https://medium.com/airbnb-engineering/flexible-continuous-integration-for-ios-4ab33ea4072f?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/4ab33ea4072f</guid>
            <category><![CDATA[ios]]></category>
            <category><![CDATA[mobile]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[continuous-integration]]></category>
            <category><![CDATA[ios-app-development]]></category>
            <dc:creator><![CDATA[Michael Bachand]]></dc:creator>
            <pubDate>Wed, 10 May 2023 17:01:55 GMT</pubDate>
            <atom:updated>2023-05-11T23:03:24.610Z</atom:updated>
            <content:encoded><![CDATA[<p><em>How Airbnb leverages AWS, Packer, and Terraform to update macOS on hundreds of CI machines in hours instead of days</em></p><figure><img alt="A person leans over the edge of a balcony. In the background are trees." src="https://cdn-images-1.medium.com/max/1024/1*mGebUVa4KQWzQvo_YDSffQ.jpeg" /></figure><p><strong>By:</strong> <a href="https://www.linkedin.com/in/mbachand">Michael Bachand</a>, <a href="https://www.linkedin.com/in/xianwen1014">Xianwen Chen</a></p><p>At Airbnb, we run a comprehensive suite of continuous integration (CI) jobs before each iOS code change is merged. These jobs ensure that the main branch remains stable by executing critical developer workflows like building the iOS application and running tests. We also schedule jobs that perform periodic tasks like reporting metrics and uploading artifacts.</p><p>Many of our iOS CI jobs execute on Macs, which enables running developer tools provided by Apple. CI jobs for all other platforms at Airbnb execute in containers on Amazon EC2 Linux instances. To fulfill the macOS requirement of iOS CI jobs we have historically maintained alternate CI infrastructure outside of AWS specifically for iOS development. The <a href="https://aws.amazon.com/about-aws/whats-new/2020/11/announcing-amazon-ec2-mac-instances-for-macos/">introduction of Macs</a> to AWS provided an opportunity for us to rethink our approach to iOS CI.</p><p>We designed the next iteration of our iOS CI system in late 2021, finished the migration to the new system in mid 2022, and polished the system through the end of 2022. CI for iOS and all other platforms at Airbnb already leveraged Buildkite for dispatching jobs. Now, we deploy iOS CI infrastructure to AWS using Terraform, which helps align CI for iOS with CI for other platforms at Airbnb.</p><p>In this article, we are excited to share with you details of the flexible and easy-to-maintain iOS CI system that we’ve implemented with Amazon EC2 Mac instances.</p><h3>The Challenges with Running CI on Physical Macs</h3><p>Historically we ran Airbnb iOS CI on physical Macs. We enjoyed the speed of running CI without virtualization but we paid a substantial maintenance cost to run CI jobs directly on physical hardware. An iOS infrastructure engineer individually logged into over 300 machines to perform administrative tasks like enrolling the Mac in our MDM (Mobile Device Management) tool and upgrading macOS. Manual maintenance requirements limited the scalability of the fleet and consumed engineer time that could be better spent on higher-value projects.</p><figure><img alt="A screenshot of a macOS desktop with many open VNC sessions to remote Mac machines." src="https://cdn-images-1.medium.com/max/1024/1*AO63aVJt71J41hqxfoWu2Q.png" /><figcaption>An engineer remotely updates multiple physical Macs to macOS Big Sur. EC2 macOS AMIs have eliminated this manual work.</figcaption></figure><p>Our old CI machines were rarely restarted and too often drifted into a bad state. When this occurred, the best-case scenario was that an engineer could log into the machine, diagnose what configuration drift was causing issues, and manually bring the machine back to a good state. More commonly, we shut down the corrupted machine so that it could no longer accept new CI jobs. Periodically, we asked the vendor who managed our physical Macs to restore the corrupted machines to a clean installation of macOS. When the machines eventually came back online, we manually re-enrolled each machine in MDM to bring our fleet back to its full capacity.</p><p>Updating to a new version of Xcode was quite error-prone as well. We strive to roll out new Xcode versions regularly since many iOS engineers at Airbnb follow Swift and Xcode releases closely and are eager to adopt new language features and IDE improvements. However, the fixed capacity of our Mac fleet made it difficult for us to verify iOS CI jobs thoroughly against new versions; any machine allocated to testing a new version of Xcode could no longer accept CI jobs from the previous Xcode version. The risk of tackling each Xcode update was increased by the fact that rolling back to a previous version of Xcode across our fleet was not practical.</p><h3>Upgrading CI with Custom macOS AMIs</h3><p>When evaluating AWS, we were excited by the possibility of launching instances from Amazon Machine Images (AMIs). An <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html">AMI</a> is a snapshot of an instance’s state, including its file system contents and other metadata. Amazon provides base AMIs for each macOS version and allows customers to create their own AMIs from running instances.</p><p>AMIs allow us to add new instances to our fleet without human intervention. An EC2 Mac bare-metal instance launched from a properly configured AMI is immediately ready to accept new work after initialization. When updating macOS, we no longer need to log into every machine in our fleet. Instead, we log into a single instance launched from the Amazon base AMI for the new macOS version. After performing a handful of manual configuration steps, like enabling <a href="https://support.apple.com/en-us/HT201476">automatic login</a>, we create an Airbnb base AMI from that instance.</p><p>Initially, we powered our EC2 Mac fleet with manually created AMIs. An engineer would configure a single instance and create an AMI from that instance’s state. Then we could launch any number of additional instances from that AMI. This was a major improvement over managing physical machines since we could spin up an entire fleet of identical instances after configuring only a single instance successfully.</p><p>Now, we <a href="https://aws.amazon.com/blogs/compute/building-amazon-machine-images-amis-for-ec2-mac-instances-with-packer/">build AMIs using Packer</a>. Packer programmatically launches and configures an EC2 instance using a template defined in the HashiCorp configuration language (HCL). Packer then creates an AMI from the configured EC2 instance. A Ruby wrapper script invokes Packer consistently and performs helpful validations like checking that the user has assumed the proper AWS role. We check the HCL template code into source control and all changes to our Packer template and companion scripts are made via GitHub pull requests.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/9a7e7156ed43dd4c13caecec5b9eb003/href">https://medium.com/media/9a7e7156ed43dd4c13caecec5b9eb003/href</a></iframe><p>We initially ran Packer from developer laptops, but the laptop needed to be awake and online for the duration of the Packer build. Eventually, we created a dedicated pipeline to build AMIs in the cloud. A developer can trigger a new build on this pipeline with a couple of clicks. A successful build will produce freshly baked and verified AMIs for both the x86 and Arm (Apple Silicon) CPU architectures within a few hours.</p><h3>Defining CI Environments in Terraform</h3><p>Our new CI system leveraging these AMIs consists of many environments, each of which can be managed independently. The central AWS component of each CI environment is an <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html">Auto Scaling group</a>, which is responsible for launching the EC2 Mac instances. The number of instances in the Auto Scaling group is determined by the <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group#desired_capacity">desired capacity</a> property on the group and is bounded by <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group#min_size">min</a> and <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/autoscaling_group#max_size">max</a> size properties.</p><p>An Auto Scaling group creates new instances using a <a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/launch-templates.html">launch template</a>. The launch template specifies the configuration of each instance, including the AMI, and allows a “user data” script to run when the instance is launched. Launch templates can be versioned, and each Auto Scaling group is configured to launch instances from a specific version of its launch template.</p><p>Although the introduction of environments has made our CI topology more complex, we find that complexity manageable when our infrastructure is defined in code. All of our AWS infrastructure for iOS CI is specified in <a href="https://developer.hashicorp.com/terraform/language">Terraform</a> code that we check into source control. Each time we merge a pull request related to iOS CI, Terraform Enterprise will automatically apply our changes to our AWS account. We have defined a Terraform module that we can call whenever we want to instantiate a new CI environment.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/83f558d48b5ae1feeb14fa09aec06aea/href">https://medium.com/media/83f558d48b5ae1feeb14fa09aec06aea/href</a></iframe><p>An internal scaling service manages the desired capacity of each environment’s Auto Scaling group. This service, a modified fork of <a href="https://github.com/buildkite/buildkite-agent-scaler">buildkite-agent-scaler</a>, increases the desired capacity of an environment’s Auto Scaling group as CI job volume for that environment increases. We specify a maximum number of instances for each CI environment in part because On-Demand EC2 Mac Dedicated Hosts currently have a minimum host allocation and billing duration of 24 hours.</p><figure><img alt="A diagram showing the relationship between CI environments, the scaling service, and Buildkite." src="https://cdn-images-1.medium.com/max/1013/1*bWLs_qh9hxGEX5O5X1XLVg.png" /><figcaption>A sketch of Airbnb’s new iOS CI system.</figcaption></figure><p>Each CI environment has a unique Buildkite queue name. Individual CI jobs can target instances in a specific environment by specifying the corresponding queue name. Jobs will fall back to the default CI environment when no queue name is explicitly specified.</p><h3>Benefits of Our New iOS CI System</h3><h4>CI Environments Are Highly Flexible</h4><p>With this new Terraform setup we are able to support an arbitrary number of CI environments with minimal overhead. We create a new CI environment per CPU architecture and version of Xcode. We can even duplicate these environments across multiple versions of macOS when performing an operating system update across our fleet. We use dedicated staging environments to test CI jobs on instances launched from a new AMI before we roll out that AMI broadly.</p><p>When we are no longer regularly using a CI environment, we can specify a minimum capacity of zero when calling the Terraform module, which will set the same value on the underlying Auto Scaling group. Then the Auto Scaling group will only launch instances when its desired capacity is increased by the scaling service. In practice, we tend to delete older environments from our Terraform code. However, even once an environment has been wound down, reinstating that environment is as simple as reverting a couple of commits in Git and redeploying the scaling service.</p><h4>Rotation of Instances Increases CI Consistency</h4><p>To minimize the opportunity for EC2 instances to drift, we terminate all instances each night and replace them daily. This way, we can be confident that our CI fleet is in a known good state at the start of each day.</p><p>When an instance is terminated, the underlying Dedicated Host is <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-stop">scrubbed</a> before a new instance can be launched on that host. We terminate instances at a time when CI demand is low to allow for the EC2 Mac scrubbing process to complete before we need to launch fresh instances on the same hosts. When an instance terminates itself overnight, it will decrement the desired capacity of the Auto Scaling group to which it belongs. As engineers start pushing commits the next day, the scaling service will increment the desired capacity on the appropriate Auto Scaling groups, causing new instances to be launched.</p><figure><img alt="A chart showing CI capacity relative to job volume over more than one week." src="https://cdn-images-1.medium.com/max/927/1*bTP7aqoiX4V2yh2ozK9E4Q.png" /><figcaption>Instances terminate themselves overnight. We reduce our maximum capacity over weekends. The spikes in job volume that increased capacity on the 2nd, 6th, and 7th have been hidden by smoothing in the chart.</figcaption></figure><p>When an instance does experience configuration drift, we can disconnect that instance from Buildkite with one click. The instance will remain running but will no longer accept new CI jobs. An engineer can log into the instance to investigate its state until the instance is eventually terminated at the end of the day. To keep overall CI capacity stable, we can manually add an additional instance to our fleet, or a replacement will be launched automatically if we terminate the instance early.</p><h4>We Ship Xcode Versions More Quickly</h4><p>We appreciate the new capabilities of our upgraded CI system. We can lease additional Dedicated Hosts from Amazon on demand to weather unexpected spikes in CI usage and to test software updates thoroughly. We roll out new AMIs gradually and can roll back painlessly if we encounter unexpected issues.</p><figure><img alt="A chart showing CI capacity relative to job volume for two simultaneous versions of Xcode." src="https://cdn-images-1.medium.com/max/927/1*lfVyjLXuLcNX9i3oWL-g8Q.png" /><figcaption>CI jobs shift from Xcode 14.1 to 14.2. On the 24th, we temporarily increased 14.2 capacity to accommodate a spike in jobs.</figcaption></figure><p>Together, these capabilities get Airbnb iOS developers access to Swift language features and Xcode IDE improvements more quickly. In fact, with the tailwind of our new CI system, we have seen the pace at which we update Xcode increase by over 20%. As of the time of writing, we have internally rolled out all available major and minor versions of Xcode 14 (14.0–14.3) as they have been released.</p><h3>The Migration is Complete</h3><p>Our new CI system ran over 10 million minutes of CI jobs in the last three months of 2022. After upgrading to EC2, we spend meaningfully fewer hours on maintenance despite a growing codebase and consistently high job volume. Our newfound ability to scale CI to meet the evolving needs of the Airbnb iOS community justifies the increased complexity of the rebuilt system.</p><p>After the migration to AWS, iOS CI benefits more from shared infrastructure that is already being used successfully within Airbnb. For example, the new iOS CI architecture enabled us to avoid implementing an iOS-specific solution for automatically scaling capacity. Instead, we leverage the aforementioned fork of <a href="https://github.com/buildkite/buildkite-agent-scaler">buildkite-agent-scaler</a> that Airbnb engineers had already converted to an internal Airbnb service complete with a dedicated deployment pipeline. Additionally, we used existing Terraform modules that are maintained by other teams to integrate with <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html">IAM</a> and <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html">SSM</a>.</p><p>We have found that EC2 Mac instances launched from custom AMIs provide many of the benefits of virtualization without the performance penalty of executing within a virtual machine. We consider AWS, Packer, and Terraform to be essential technologies for building a flexible CI system for large-scale iOS development in 2023.</p><p>Xianwen Chen, the technical lead of this project, designed the topology of the iOS CI system, implemented the design with Terraform, and later enabled creation of AMIs in the cloud. Michael Bachand built the initial version of our Packer tooling and used this tooling to create the first programmatically built AMIs capable of completing iOS CI jobs. Steven Hepting productionized our Packer tooling by adding support for Arm AMIs and evolving the Packer template so that all of Airbnb’s iOS CI jobs could run successfully on both CPU architectures.</p><p>We received invaluable support from numerous subject-matter experts at Airbnb who were very generous with their time. Many thanks to Brandon Kurtz for advising on content and voice through multiple revisions of this article.</p><p>If you are interested in joining us on our quest to make the best iOS app in the App Store, please see our <a href="https://careers.airbnb.com/">careers</a> page for open iOS roles.</p><p><em>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=4ab33ea4072f" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/flexible-continuous-integration-for-ios-4ab33ea4072f">Flexible Continuous Integration for iOS</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[My Journey to Airbnb — Michael Kinoti]]></title>
            <link>https://medium.com/airbnb-engineering/my-journey-to-airbnb-michael-kinoti-645d4c228d06?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/645d4c228d06</guid>
            <category><![CDATA[technology]]></category>
            <category><![CDATA[people]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[leadership]]></category>
            <dc:creator><![CDATA[Lauren Mackevich]]></dc:creator>
            <pubDate>Wed, 26 Apr 2023 20:26:57 GMT</pubDate>
            <atom:updated>2023-04-26T20:26:57.714Z</atom:updated>
            <content:encoded><![CDATA[<h3>My Journey to Airbnb — Michael Kinoti</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*X0-h_g8Qrt3TWzbOuBzzMw.jpeg" /></figure><p>Saying no to med school and following a dream all the way to Silicon Valley</p><p><em>Becoming a doctor and trying to make it as a DJ have both crossed </em><a href="https://www.linkedin.com/in/michael-kinoti-7a309215/"><em>Michael Kinoti’s</em></a><em> mind at one time or another. Instead, we’re lucky to have Michael (who goes by Kinoti) as Airbnb’s Director of Engineering for the Marketing Technology team. He brings with him over 15 years of industry experience at Microsoft and Uber, as well as a global perspective from his childhood in Kenya. Kinoti is passionate about travel and having a large-scale social impact, qualities that align nicely with Airbnb’s mission and vision. Here’s Kinoti’s story in his own words.</em></p><h3>Doctor, lawyer, or engineer?</h3><p>Anybody who grew up in Kenya around when I did is probably aware that medicine, law, and engineering were the <em>only </em>options for an ambitious student. And at least in my family, while all three careers were highly regarded, nothing was quite as prized as becoming a doctor.</p><p>Needless to say, I made my parents very proud when I was accepted to medical school. This is the story of the more than 20 years since, during which I’ve learned so much and have found my niche — as a software engineering leader.</p><h3>Choosing my own adventure</h3><p>It may help to describe how I arrived at that medical school acceptance in the first place, and how by that time, I had already started developing an interest in computers. As the child of an entrepreneur father and an engineer mother, I am grateful to have had two amazing role models from a young age. My mother’s grit has been particularly inspiring. She was the only female in her university cohort, and time and time again she has had to work harder than everybody else to prove herself. She became a leader at Kenya’s major telecom company and directly contributed to bringing the country high-speed Internet, giving my generation and ones after access to a world of information.</p><p>Always proponents of education, my parents sent me to one of the country’s premier institutions, the Starehe Boys’ Centre and School. The school’s mission is to develop youth into better human beings and leaders, with an emphasis on a holistic education beyond just academics. To this day, I live by the school’s values: integrity, leadership, and service.</p><p>I was lucky to be one of the first students in Kenya to take a computer studies course in school. While most students used the computer lab to play video games, myself included, I spent a lot of my time learning how to code. Seeing my deep interest in programming, my classmates would joke that I was going to be the next Bill Gates. I think those formative experiences instilled in me a dream to one day work at Microsoft, one of the biggest technology companies in the world. I wanted to make an impact through technology, which I saw and continue to see as an engine for leveling the global playing field. At the time, however, that was all just a dream and Redmond, Washington couldn’t have felt further away.</p><p>For a while, I put chasing that dream on hold as I applied to medical school and was later accepted. Everything was set for me to matriculate in six months’ time, and during that gap I took the opportunity to get some more hands-on coding experience. I realized that medicine wasn’t for me and that not only did I want to study software engineering, but I wanted to come to the United States to be as close as possible to Silicon Valley.</p><p>It took a lot of courage to admit this change of heart to my parents, and their initial reaction was a pragmatic one — it was too expensive, too far, and just not feasible to go abroad. Still, I was motivated to give it a try, so I took the SAT on my own and did everything else needed to apply to American colleges. I received some acceptance letters and, by showing my initiative, convinced my parents that my dream might be within reach after all.</p><h3>Dreams do come true, but then what?</h3><p>I remember being extremely excited leading up to my move to the US, until about halfway through the plane journey when it hit me that I was leaving my family and everything I knew behind. I had to overcome that fear and the imposter syndrome that came from doubting whether I picked the right path. To add to that, there’s a lot of culture shock that accompanies moving continents. For the first time in my life I was an ethnic minority and had to grapple with what that meant.</p><p>For me, the culture shock extended into the classroom, too. I enrolled at the Florida Institute of Technology to study software engineering. It was my first time seeing students challenging teachers and engaging in open discussions. Putting myself in a new environment exposed me to an entirely new outlook.</p><p>The amount of effort I put into adjusting to my new home paid off more than I could have ever imagined. I used to be a kid in Kenya with a vague sense that coming to America was the right move for me. With a lot of hard work, I got a job at my dream company: Microsoft!</p><p>Microsoft had so much support and mentorship, along with growth and learning opportunities that kept me busy for 11 years. To an extent, I was still following the mindset I grew up with that values loyalty. The path was clear: I could have stayed at the company indefinitely, then gotten married, and soon after started a family. What I learned from all the friends I made over those years, however, is that Microsoft is just one of many companies doing amazing things. Once you get to a point in your career where you’re not growing the same way, you’re not learning the same way, or you just want a different challenge, <em>it’s okay to change</em>.</p><p>I had focused on infrastructure during my time at Microsoft, and as much as I enjoyed it, I wanted to keep exploring. I joined Uber to lead the team building the company’s customer support platform. This is where I discovered my niche for building platforms at the sweet spot between product and infrastructure. I love being able to shape systems that directly affect millions of people and translate into features that people can see and feel.</p><h3>Why I picked Airbnb</h3><p>After a bit over three years at Uber, I made the switch to Airbnb, which felt right for so many reasons. Airbnb’s mission around building belonging and connection really resonated with me. The company has an ambitious vision, and I believe promoting belonging and connection are fundamental to solving so many other societal problems. This, in addition to travel being a passion of mine (I’ve been to 55 countries across 6 continents!) made me very excited about Airbnb.</p><p>The way Airbnb works toward its mission is unique. We have a creative touch when it comes to technology, something our CEO, Brian, encourages a lot. We care deeply about the details and chasing perfection in a healthy way. Of course, there’s no such thing as actual perfection, but to strive for that the way we do at Airbnb produces great results, something our users see every time they interact with the product.</p><p>Arguably the biggest factor in my decision, though, was Airbnb’s culture. This can be hard to fully put into words; what I love about Airbnb’s culture comes through in all the little things you experience day to day. There’s a genuine warmness between people who seek to build belonging and connection everywhere they go. People are welcoming, particularly to new hires. Even the interview process at Airbnb feels more human and conversational, which is different from so many other companies. Culture starts with the details and adds up into bigger things too: I think Airbnb truly excels at work-life integration and as somebody who recently started a family, I’m very glad I came here.</p><h3>Integrity, leadership, and service at Airbnb</h3><p>At Airbnb, I lead the Marketing Technology (Growth Platform) team responsible for Canvas, an internal platform that enables marketing and product teams to effectively engage with customers. Our overarching goal is to drive business growth and product engagement. Canvas has tools for creating, managing, and measuring content that gets published both to Airbnb and offsite channels such as emails, notifications, and ads. I’ve reaffirmed how much I enjoy my role as a platform owner since I get to be at the nexus of so many areas that are important to the overall business. I get to think about everything from notifications, to personalization using machine learning, to the underlying infrastructure powering it all.</p><p>On a daily basis, I put into practice the three values I’ve lived by since my days in school: integrity, leadership, and service. My philosophy around leadership is that it’s not about power or being in charge. Rather, leadership is a form of service. I make a point to be empathetic, and my mission as a leader is to unlock the best in others through coaching and mentorship. My own mentors and coaches have played a large part in getting me to where I am, and I seek to pay that forward.</p><p>Of course, integrity also remains at the heart of every decision I make as a leader. Privacy and compliance are key focus areas for my team right now, which I enjoy because of the strong alignment those goals have with my value of integrity. To me, integrity means handling user data with the same care I’d want for my own data.</p><p>Currently, we’re also doing cutting-edge work on personalizing our marketing. Instead of blasting out the same email campaign to every user, we want to identify the journey a particular user is on and customize the content they see to be more relevant. Not only is this an interesting technical problem, it’s a nuanced issue of respecting user privacy while offering a more tailored experience.</p><p>In the last couple years, Airbnb has been undergoing an incredible transformation from a startup into a mature company. There’s a huge modernization effort within the company to scale our tech stack to match the scale at which we have a global impact. If that’s interesting to you, I encourage you to <a href="https://careers.airbnb.com/">check out openings at Airbnb</a>. If there’s one thing I’ve learned from the wild ride I’ve had so far is that there’s no set path you need to follow — take a chance, and you’ll be amazed by what you might achieve.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=645d4c228d06" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/my-journey-to-airbnb-michael-kinoti-645d4c228d06">My Journey to Airbnb — Michael Kinoti</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Improving Istio Propagation Delay]]></title>
            <link>https://medium.com/airbnb-engineering/improving-istio-propagation-delay-d4da9b5b9f90?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/d4da9b5b9f90</guid>
            <category><![CDATA[infrastructure]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[istio]]></category>
            <category><![CDATA[service-mesh]]></category>
            <dc:creator><![CDATA[Ying Zhu]]></dc:creator>
            <pubDate>Thu, 23 Mar 2023 18:20:38 GMT</pubDate>
            <atom:updated>2023-03-23T18:20:38.120Z</atom:updated>
            <content:encoded><![CDATA[<h4>A case study in service mesh performance optimization</h4><p>by: <a href="https://www.linkedin.com/in/ying-zhu-763a3879/">Ying Zhu</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*tvfIu34QvOy1IBNTNGXoAQ.jpeg" /></figure><h3>Introduction</h3><p>In this article, we’ll showcase how we identified and addressed a service mesh performance problem at Airbnb, providing insights into the process of troubleshooting service mesh issues.</p><h4>Background</h4><p>At Airbnb, we use a microservices architecture, which requires efficient communication between services. Initially, we developed a homegrown service discovery system called Smartstack exactly for this purpose. As the company grew, however, we encountered scalability issues¹. To address this, in 2019, we invested in a modern service mesh solution called AirMesh, built on the open-source <a href="https://istio.io/latest/">Istio</a> software. Currently, over 90% of our production traffic has been migrated to AirMesh, with plans to complete the migration by 2023.</p><h4>The Symptom: Increased Propagation Delay</h4><p>After we upgraded Istio from 1.11 to 1.12, we noticed a puzzling increase in the propagation delay — the time between when the Istio control plane gets notified of a change event and when the change is processed and pushed to a workload. This delay is important for our service owners because they depend on it to make critical routing decisions. For example, servers need to have a graceful shutdown period longer than the propagation delay, otherwise clients can send requests to already-shut-down server workloads and get 503 errors.</p><h4>Data Gathering: Propagation Delay Metrics</h4><p>Here’s how we discovered the condition: we had been monitoring the Istio metric <em>pilot_proxy_convergence_time</em> for propagation delay when we noticed an increase from 1.5 seconds (p90 in Istio 1.11) to 4.5 seconds (p90 in Istio 1.12). <em>Pilot_proxy_convergence_time</em> is one of several metrics Istio records for propagation delay. The complete list of metrics is:</p><ul><li><em>pilot_proxy_convergence_time</em> — measures the time from when a push request is added to the push queue to when it is processed and pushed to a workload proxy. (Note that change events are converted into push requests and are batched through a process called <em>debounce</em> before being added to the queue, which we will go into details later.)</li><li><em>pilot_proxy_queue_time</em> — measures the time between a push request enqueue and dequeue.</li><li><em>pilot_xds_push_time</em> — measures the time for building and sending the xDS resources. Istio leverages Envoy as its data plane. Istiod, the control plane of Istio, configures Envoy through the xDS API (where x can be viewed as a variable, and DS stands for discovery service).</li><li><em>pilot_xds_send_time</em> — measures the time for actually sending the xDS resources.</li></ul><p>The diagram below shows how each of these metrics maps to the life of a push request.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Itxhfr6I8TygnWQwQgghhA.png" /><figcaption>A high level graph to help understand the metrics related to propagation delay.</figcaption></figure><h3>Investigation</h3><h4>xDS Lock Contention</h4><p>CPU profiling showed no noticeable changes between 1.11 and 1.12, but handling push requests took longer, indicating time was spent on some waiting events. This led to the suspicion of lock contention issues.</p><p>Istio uses four types of xDS resources to configure Envoy:</p><ul><li>Endpoint Discovery Service (EDS) — describes how to discover members of an upstream cluster.</li><li>Cluster Discovery Service (CDS) — describes how to discover upstream clusters used during routing.</li><li>Route Discovery Service (RDS) –describes how to discover the route configuration for an HTTP connection manager filter at runtime.</li><li>Listener Discovery Service (LDS) –describes how to discover the listeners at runtime.</li></ul><p>Analysis of the metric <em>pilot_xds_push_time</em> showed that only three types of pushes (EDS, CDS, RDS) increased after the upgrade to 1.12. The Istio changelog revealed that <a href="https://github.com/istio/istio/pull/33338">CDS</a> and<a href="https://github.com/istio/istio/pull/34243"> RDS</a> caching was added in 1.12.</p><p>To verify that these changes were indeed the culprits, we tried turning off the caches by setting PILOT_ENABLE_CDS_CACHE and PILOT_ENABLE_RDS_CACHE to “False”. When we did this, <em>pilot_xds_push_time</em> for CDS reverted back to the 1.11 level, but not RDS or EDS. This improved the <em>pilot_proxy_convergence_time</em>, but not enough to return it to the previous level. We believed that there was something else affecting the results.</p><p>Further investigation into the xDS cache revealed that all xDS computations shared one cache. The tricky thing is that Istio used an LRU Cache under the hood. The cache is locked not only on <a href="https://github.com/istio/istio/blob/1.12.9/pilot/pkg/model/xds_cache.go#L229">write</a>s, but also on <a href="https://github.com/istio/istio/blob/1.12.9/pilot/pkg/model/xds_cache.go#L266">read</a>s, because when you read from the cache, you need to promote the item to most recently used. This caused lock contention and slow processing due to multiple threads trying to access the same lock at the same time.</p><p>The hypothesis formed was that xDS cache lock contention caused slowdowns for CDS and RDS because caching was turned on for those two resources, and also impacted EDS due to the shared cache, but not LDS as it did not have caching implemented.</p><p>But why turning off both CDS and RDS cache does not solve the problem? By looking at where the cache was used when building RDS, we found out that the flag PILOT_ENABLE_RDS_CACHE was not respected. We fixed that <a href="https://github.com/istio/istio/pull/40719">bug</a> and conducted performance testing in our test mesh to verify our hypothesis with the following setup:</p><ul><li>Control plane:<br>- 1 Istiod pod (memory 26 G, cpu 10 cores)</li><li>Data plane:<br>- 50 services and 500 pods<br>- We mimicked changes by restarting deployments randomly every 10 seconds and changing virtual service routings randomly every 5 seconds</li></ul><p>Here were the results:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*pRyD4EoUCmo_2WazdJoFnA.png" /><figcaption>A table of results² for the perfomance testing.</figcaption></figure><p>Because our Istiod pods were not CPU intensive, we decided to disable the CDS and RDS caches for the moment. As a result, propagation delays returned to the previous level. Here is the Istio <a href="https://github.com/istio/istio/issues/40744">issue</a> for this problem and potential future improvement of the xDS cache.</p><h4>Debounce</h4><p>Here’s a twist in our diagnosis: during the deep dive of Istio code base, we realized that <em>pilot_proxy_convergence_time</em> does not actually fully capture propagation delay. We observed in our production that 503 errors happen during server deployment even when we set graceful shutdown time longer than <em>pilot_proxy_convergence_time</em>. This metric does not accurately reflect what we want it to reflect and we need to redefine it. Let’s revisit our network diagram, zoomed out to include the debounce process to capture the full life of a change event.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*vfzfyE92hlutqOFJbUcQqw.png" /><figcaption><em>A high level diagram of the life of a change event.</em></figcaption></figure><p>The process starts when a change notifies an Istiod controller³. This triggers a push which is sent to the push channel. Istiod then groups these changes together into one combined push request through a process called debouncing. Next, Istiod calculates the push context which contains all the necessary information for generating xDS. The push request together with the context are then added to the push queue. Here’s the problem: <em>pilot_proxy_convergence_time</em> only measures the time from when the combined push is added to the push queue, to when a proxy receives the calculated xDS.</p><p>From Istiod logs we found out that the debounce time was almost 110 seconds, even though we set PILOT_DEBOUNCE_MAX to 30 seconds. From reading the code, we realized that the <a href="https://github.com/istio/istio/blob/1.15.3/pilot/pkg/xds/discovery.go#L532">initPushContext</a> step was blocking the next debounce to ensure that older changes are processed first.</p><p>To debug and test changes, we needed a testing environment. However, it was difficult to generate the same load on our test environment. Fortunately, the debounce and init push context are not affected by the number of Istio proxies. We set up a development box in production with no connected proxies and ran custom images to triage and test out fixes.</p><p>We performed CPU profiling and took a closer look into functions that were taking a long time:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*DKQZMY6fHpNmUOExjvvBSg.png" /><figcaption><em>A CPU profile of Istiod.</em></figcaption></figure><p>A significant amount of time was spent on the Service DeepCopy function. This was due to the use of the <a href="https://github.com/mitchellh/copystructure">copystructure</a> library that used <a href="https://go.dev/blog/laws-of-reflection">go reflection</a> to do deep copy, which has expensive performance. Removing the library⁴ was both easy and very effective at reducing our debounce time from 110 seconds to 50 seconds.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*0XoORAP6XTCQDwKNVNzmog.png" /><figcaption><em>A CPU profile of Istiod after DeepCopy improvement.</em></figcaption></figure><p>After the DeepCopy improvement, the next big chunk from the cpu profile was the ConvertToSidecarScope function. This function took a long time to determine which virtual services were imported by each Istio proxy. For each proxy egress host, Istiod first computed all the virtual services exported to the proxy’s namespace, then selected the virtual services by matching proxy egress host name to the virtual services’ hosts.</p><p>All our virtual services were public as we did not specify the <em>exportTo</em> parameter, which is a list of namespaces to which this virtual service is exported. If this parameter is not configured, the virtual service is automatically exported to all namespaces. Therefore, <a href="https://github.com/istio/istio/blob/1.12.9/pilot/pkg/model/push_context.go#L829-L833">VirtualServicesForGateway</a> function created and copied all virtual services each time. This deep-copy of slice elements was very expensive when we had many proxies with multiple egress hosts.</p><p>We <a href="https://github.com/istio/istio/pull/41101">reduced</a> the unnecessary copy of virtual services: instead of passing a copied version of the virtual services, we passed the virtualServiceIndex directly into the select function, further reducing the debounce time from 50 seconds to around 30 seconds.</p><p>Another improvement that we are currently rolling out is to limit where virtual services are exported by setting the exportTo field, based on which clients are allowed to access the services. This should reduce debounce time by about 10 seconds.</p><p>The Istio community is also actively working on improving the push context calculation. Some ideas include <a href="https://github.com/istio/istio/issues/41453">adding multiple workers to compute the sidecar scope</a>, <a href="https://github.com/istio/istio/pull/41647">processing changed sidecars only instead of rebuilding the entire sidecar scope</a>. We also added <a href="https://github.com/istio/istio/pull/40523">metrics for the debounce time</a> so that we can monitor this together with the proxy convergence time to track accurate propagation delay.</p><h3>Conclusion</h3><p>To conclude our diagnosis, we learned that:</p><ul><li>We should use both <em>pilot_debounce_time</em> and <em>pilot_proxy_convergence_time</em> to track propagation delay.</li><li>xDS cache can help with CPU usage but can impact propagation delay due to lock contention, tune PILOT_ENABLE_CDS_CACHE &amp; PILOT_ENABLE_RDS_CACHE to see what’s best for your system.</li><li>Restrict the visibility of your Istio manifests by setting the <em>exportTo</em> field.</li></ul><p>If this type of work interests you, check out some of our related <a href="https://careers.airbnb.com/">roles</a>!</p><h3>Acknowledgments</h3><p>Thanks to the Istio community for creating a great open source project and for collaborating with us to make it even better. Also call out to the whole AirMesh team for building, maintaining and improving the service mesh layer at Airbnb. Thanks to Lauren Mackevich, Mark Giangreco and Surashree Kulkarni for editing the post.</p><p>[1]: Checkout our presentation <a href="https://events.istio.io/istiocon-2021/sessions/airbnb-on-istio/">Airbnb on Istio</a> for details.</p><p>[2]: Note that some CPU throttling occurred for the last two cases, so if we were to allocate more CPU we would expect propagation delay (especially P99) to improve further.</p><p>[3]: Istiod service controller monitors changes to registered services from different sources including kubernetes service, ServiceEntry created service, etc., Istiod config controller monitors changes to the Istio resources used to manage those services.</p><p>[4]: <a href="https://github.com/istio/istio/pull/40966/files">PR1</a>, <a href="https://github.com/istio/istio/pull/37932/files">PR2</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=d4da9b5b9f90" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/improving-istio-propagation-delay-d4da9b5b9f90">Improving Istio Propagation Delay</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Building Airbnb Categories with ML & Human in the Loop]]></title>
            <link>https://medium.com/airbnb-engineering/building-airbnb-categories-with-ml-human-in-the-loop-35b78a837725?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/35b78a837725</guid>
            <category><![CDATA[data-science]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[technology]]></category>
            <category><![CDATA[machine-learning]]></category>
            <dc:creator><![CDATA[Mihajlo Grbovic]]></dc:creator>
            <pubDate>Wed, 22 Mar 2023 22:03:24 GMT</pubDate>
            <atom:updated>2023-03-24T16:18:37.928Z</atom:updated>
            <content:encoded><![CDATA[<p>Airbnb Categories Blog Series — Part II : ML Categorization</p><p>by: <strong>Mihajlo Grbovic, Pei Xiong, Pratiksha Kadam, Ying Xiao, Sherry Chen, Weiping Peng, Shukun Yang, Chen Qian, Haowei Zhang, Sebastien Dubois, Nate Ney, James Furnary, Mark Giangreco, Nate Rosenthal, Cole Baker, Aaron Yin, Bill Ulammandakh, Shankar Shetty</strong>, <strong>Sid Reddy, Egor Pakhomov</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*QYv0Kr3gpdWJFtzPgqkwJA.jpeg" /></figure><p><a href="https://news.airbnb.com/2022-summer-release/">Airbnb 2022 release</a> introduced Categories, a browse focused product that allows the user to seek inspiration by browsing collections of homes revolving around a common theme, such as <em>Lakefront, Countryside, Golf, Desert, National Parks</em>, <em>Surfing</em>, etc. In <a href="https://medium.com/airbnb-engineering/building-airbnb-categories-with-ml-and-human-in-the-loop-e97988e70ebb">Part I</a> of our Categories Blog Series we covered the high level approach to creating Categories and showcasing them in the product. In this Part II we will describe the ML Categorization work in more detail.</p><p>Throughout the post we use the <strong><em>Lakefront</em> category</strong> as a running example to showcase the ML-powered category development process. Similar process was applied for other categories, with category specific nuances. For example, some categories rely more on points of interests, while others more on structured listing signals, image data, etc.</p><h4><strong>Category Definition</strong></h4><p>Category development starts with a product-driven category definition: “<em>Lakefront category should include listings that are less than 100 meters from the lake</em>”. While this may sound like an easy task at first, it is very delicate and complex as it involves leveraging multiple structured and unstructured listing attributes, points of interest (POIs), etc. It also involves training ML models that combine them, since none of the signals captures the entire space of possible candidates on their own.</p><h4>Listing Understanding Signals</h4><p>As part of various past projects multiple teams at Airbnb spent time on processing different types of raw data to extract useful information in structured form. Our goal was to leverage these signals for cold-start rule-based category candidate generation and later use them as features of the ML model that could find category candidates with higher precision:</p><ul><li><strong>Host provided listing information</strong>, such as <strong><em>property type</em></strong> (e.g. castle, houseboat), <strong><em>amenities &amp; attributes</em></strong><em> </em>(pool, fire pit, forest view, etc.). <strong><em>listing</em></strong> <strong><em>location</em></strong>, <strong><em>title, description, image captions</em></strong> that can be scanned for keywords (we gathered exhaustive sets of keywords in different languages per category).</li><li><a href="https://www.airbnb.com/resources/hosting-homes/a/create-a-guidebook-to-share-your-local-tips-23"><strong>Host guidebooks</strong></a>, where hosts recommend nearby places for guests to visit (e.g. a Vineyard, Surf beach, Golf course) which hold locations data that was useful for extracting <strong><em>POIs</em></strong></li><li><a href="https://www.airbnb.com/s/experiences"><strong>Airbnb experiences</strong></a>, such as <em>Surfing</em>, <em>Golfing, Scuba</em>, etc. <strong><em>Locations of these activities</em></strong> proved useful in identifying listing candidates for certain activity-related categories.</li><li><strong>Guest reviews<em> </em></strong>which is another source that can be scanned for <strong><em>keywords</em></strong>. We also collect supplemental guest reviews where guests provide<strong><em> feedback on listings quality, amenities and attributes.</em></strong></li><li><a href="https://www.airbnb.com/wishlists/popular"><strong>Wishlists</strong></a> that guests create when browsing, such as “Golf trip 2022”, “Beachfront”, “Yosemite trip”, are often related to one of the categories, which proved useful for candidate generation.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ZK5ffGuT8bWNFXqE" /><figcaption>Figure 1. Popular wishlists created by airbnb users</figcaption></figure><p>The listing understanding knowledge base was further enriched using external data, such as <strong>Satellite data</strong> (tell us if a listing is close to an ocean, river or lake), <strong>Climate, Geospatial data</strong>, <strong>Population data</strong> (tells us if listing is in rural, urban or metropolitan area) and <strong>POI data </strong>that contains names and locations of places of interest from host guidebooks or collected by us via open source datasets and further improved, enriched and adjusted by in-house human review.</p><p>Finally, we leveraged our in-house ML models for additional knowledge extraction from raw listing data. These included <strong>ML models for</strong><a href="https://medium.com/airbnb-engineering/amenity-detection-and-beyond-new-frontiers-of-computer-vision-at-airbnb-144a4441b72e"><strong> Detecting amenities and objects in listing images</strong></a>, <a href="https://medium.com/airbnb-engineering/categorizing-listing-photos-at-airbnb-f9483f3ab7e3"><strong>Categorizing room types and outdoor spaces in listing images</strong></a>,, <a href="https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e"><strong>Computing embedding similarities between listings</strong></a> and <a href="https://medium.com/airbnb-engineering/when-a-picture-is-worth-more-than-words-17718860dcc2"><strong>Assessing property aesthetics</strong></a>. Each of these were useful in different stages of category development, candidate generation, expansion and quality prediction, respectively.</p><h4><strong>Rule-based candidate generation</strong></h4><p>Once a category is defined, we first leverage pre-computed listing understanding signals and ML model outputs described in the previous section to codify the definition with a set of rules. Our candidate generation engine then applies them to produce a set of rule-based candidates and prioritizes them for human review based on a category confidence score.</p><p>This confidence score is computed based on how many signals qualified the listing to the category and the weights associated with each rule. For example, considering <em>Lakefront</em> category, vicinity to a Lake POIs carried the most weight, host provided signals on direct lake access were next more important, lakefront keywords found in listing title, description, wishlists, reviews carried less weight, while lake and water detection in listing images carried the least weight. A listing that would have all these attributes would have a very high confidence score, while a listing that would have only one would have a lower score.</p><h4><strong>Human review process</strong></h4><p>Candidates were sent for human review daily, by selecting a certain number of listings from each category with the highest category confidence score. Human agents then judged if listing belongs to the category, choose the best cover photo and assessed the quality of the listing (Figure 3)</p><p>As human reviews started rolling in and there were enough listings with confirmed and rejected category tags it unlocked new candidate generation techniques that started contributing their own candidates:</p><ul><li><strong>Proximity based: </strong>leveraging distance to the confirmed listing in a given category, e.g. neighbor of a confirmed <em>Lakefront</em> listing it may also be <em>Lakefront</em></li><li><strong>Embedding similarity</strong>: leveraging listing embeddings to find listings that are most similar to confirmed listing in a given category.</li><li><strong>Training ML categorization</strong> <strong>models</strong>: once the agents reviewed 20% of rule-based candidates we started training ML models.</li></ul><p>In the beginning, only agent vetted listings were sent to production and featured on the homepage. Over time, as our candidate generation techniques produced more candidates and the feedback loop repeated, it allowed us to train better and better ML models with more labeled data. Finally, at some point, when ML models were good enough, we started sending listings with high enough model scores to production (Figure 2).</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*EwmASLm1l4gOGftsg40vSg.png" /><figcaption>Figure 2. Number of listings in production per category and fractions vetted by humans</figcaption></figure><h3>Aligning ML Models with Human review tasks</h3><p>In order to scale the review process we trained ML models that mimic each of the three human agent tasks (Figure 3). In the following sections we will demonstrate the training and evaluation process involved with each model</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*R6OBIRV-1C78xU89" /><figcaption>Figure 3. ML models setup for mimicking human review</figcaption></figure><h4><strong>ML Categorization Model</strong></h4><p>ML Categorization Model task was to confidently place listings in a category. These models were trained using Bighead (Airbnb’s ML platform) as XGBoost binary<em> per category </em>classification models. They used agent category assignments as labels and signals described in the Listing Understanding section as features. As opposed to a rule-based setting, ML models allowed us to have better control of the precision of candidates via model score threshold.</p><p>Although many features are shared across categories and one could train a single multiclass model, due to the high imbalance in category sizes and dominance of category-specific features we found it better to train dedicated ML per category models. Another big reason for this was that a major change to a single category, such as change in definition, large addition of new POIs or labels, did not require us to retrain, launch and measure impact on all the categories, but instead conveniently work on a single category in isolation.</p><p><strong>Lakefront ML model</strong></p><p><strong>Features</strong>: the first step was to build features, with the most important one being distance to Lake POI. We started with collecting Lake POIs represented as a single point and later added lake boundaries that trace the lake, which greatly improved the accuracy of being able to pull listings near the boundary. However, as shown in Figure 4, even then there were many edge cases that lead to mistakes in rule-based listing assignment.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/344/0*6Nx7UjAUaqzjECuG" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/534/0*dqWLL502IAax6Z2G" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/864/0*GLKr66XZFXCOU2Jx" /><figcaption>Figure 4. Examples of imperfect POI (left) and complex geography: highway between lake and home (middle), long backyards (right)</figcaption></figure><p>These include imperfect lake boundaries that can be inside the water or outside on land, highways in between lake and houses, houses on cliffs, imperfect listing location, missing POIs, and POIs that are not actual lakes, like reservoirs, ponds etc. For this reason, it proved beneficial to combine POI data with other listing signals as ML model features and then use the model to proactively improve the Lake POI database.</p><p>One modeling maneuver that proved to be useful here was <strong>feature dropout</strong>. Since most of the features were also used for generating rule-based candidates that were graded by agents, resulting in labels that are used by the ML model, there was a risk of overfitting and limited pattern discovery beyond the rules.</p><p>To address this problem, during training we would randomly drop some feature signals, such as distance from Lake POI, from some listings. As a result, the model did not over rely on the dominant POI feature, which allowed listings to have a high ML score even if they are not close to any known Lake POI. This allowed us to find missing POIs and add them to our database.</p><p><strong>Labels</strong>: <strong>Positive labels </strong>were assigned to listings agents tagged as <em>Lakefront</em>, <strong>Negative labels </strong>were assigned to listings sent for review as <em>Lakefront</em> candidates but rejected (<strong>Hard negatives </strong>from modeling perspective). We also sampled negatives from related <em>Lake House </em>category<em> </em>that allows greater distance to lake (<strong>Easier negatives</strong>) and listings tagged in other categories (<strong>Easiest negatives</strong>)</p><p><strong>Train / Test split:</strong> 70:30 random split, where we had special handling of distance and embedding similarity features not to leak the label.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*TWLK6uKR-pQuMjms" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/720/0*YZfAoBLNtWzn-2wa" /><figcaption>Figure 5. Lakefront ML model feature importance and performance evaluation</figcaption></figure><p>We trained several models using different feature subsets. We were interested in how well POI data can do on its own and what improvements can additional signals provide. As it can be observed in Figure 5, the POI distance is the most important feature by far. However, when used on its own it cannot approach the ML model performance. Specifically, the ML model improves Average Precision by 23%, from 0.74 to 0.91, which confirmed our hypothesis.</p><p>Since the POI feature is the most important feature we invested in improving it by adding new POIs and refining existing POIs. This proved to be beneficial as the ML model using <em>improved</em> POI features greatly outperforms the model that used <em>initial</em> POI features (Figure 5).</p><p>The process of Lake POI refinement included leveraging trained ML model to<strong> find missing or imperfect POIs</strong> by inspecting listings that have a high model score but are far from existing Lake POIs (Figure 6 left) and <strong>removing wrong POIs</strong> by inspecting listings that have a low model score but are very close to an existing Lake POI (Figure 6 right)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*6zlNgooTq5VZuw1d" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*GuREMpTIxhzDPbMO" /><figcaption>Figure 6. Process of finding missing POIs (Left) and wrong POIs (Right)</figcaption></figure><p><strong>Sending confident listings to production: </strong>using the test set Precision-Recall curve we found a threshold that achieves 90% Precision. We used this threshold to make a decision on which candidates can go directly to production and which need to be sent for human review first.</p><h4><strong>Cover Image ML model</strong></h4><p>To carry out the second agent task with ML, we needed to train a different type of ML model. One whose task would be to choose the most appropriate listing cover photo given the category context. For example, choosing a listing photo with a lake view for the Lakefront category.</p><p>We tested several out of the box object detection models as well as several in-house solutions trained using human review data, i.e. (listing id, category, cover photo id) tuples. We found that the best cover photo selection accuracy was achieved by fine-tuning a <a href="https://huggingface.co/google/vit-base-patch16-224-in21k">Vision Transformer model</a> (VT) using our human review data. Once trained, the model can score all listing photos and decide which one is the best cover photo for a given category.</p><p>To evaluate the model we used a hold out dataset and tested if the agent selected listing photo for a particular category was within the top 3 highest scoring VT model photos for the same category. The average Top 3 precision on all categories was 70%, which we found satisfactory.</p><p>To further test the model we judged if the VT selected photo represented the category better than the Host selected cover photo (Figure 7). It was found that the VT model can select a better photo in 77% of the cases. It should be noted that the Host selected cover photo is typically chosen without taking any category into account, as the one that best represents the listing in the search feed.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*iavt2RDI2GWF1aME" /><figcaption>Figure 7. Vision Transformer vs. Host selected cover photo selection for the same listing for Lakefront category</figcaption></figure><p>In addition to selecting the best cover photo for candidates that are sent to production by the ML categorization model, the VT model was also used to speed up the human review process. By ordering the candidate listing photos in descending order of the VT score we were able to improve the time it takes the agents to make a decision on a category and cover photo by 18%.</p><p>Finally, for some highly visual categories, such as <em>Design</em>, <em>Creative spaces</em>, the VT model proved to be useful for direct candidate generation.</p><h4>Quality ML Model</h4><p>The final human review task is to judge the quality of the listing by selecting one of the four tiers: Most Inspiring, High Quality, Acceptable, Low Quality. As we will discuss in Part III of the blog series, the quality plays a role in ranking of listings in the search feed.</p><p>To train an ML model that can predict quality of a listing we used a combination of engagement, quality and visual signals to create a feature set and agent quality tags to create labels. The features included review ratings, wishlists, image quality, embedding signals and listing amenities and attributes, such as price, number of guests, etc.</p><p>Given the multi-class setup with four quality tiers, we experimented with different loss functions (pairwise loss, one-vs-all, one-vs-one, multi label, etc.). We then compared the ROC curves of different strategies on a hold-out set and the binary one-vs-all models performed the best.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*CwdBkRcZn_r96Sh6" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/720/0*Of2jGUxhGbm5QFDn" /><figcaption>Figure 8: Quality ML model feature importance and ROC curve</figcaption></figure><p>In addition to playing a role in search ranking, the Quality ML score also played a role in the human review prioritization logic. With all three ML models functional for all three human review tasks, we could now streamline the review process and send more candidates directly to production, while also prioritizing some for human review. This prioritization plays an important role in the system because listings that are vetted by humans may rank higher in the category feed.</p><p>There were several factors to consider when prioritizing listings for human review, including listing category confidence score, listing quality, bookability and popularity of the region. The best strategy proved to be a combination of those factors. In Figure 9 we show the top candidates for human review for several categories at the time of writing this post.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*H4pV-jJu1XWSu7lI" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*RQGEp-CfzSwegbvQ" /><figcaption>Figure 9: Listing prioritized for review in 4 different categories</figcaption></figure><p>Once graded, those labels are then used for periodical model re-training in an active feedback loop that continuously improves the category accuracy and coverage.</p><h3>Future work</h3><p>Our future work involves iterating on the three ML models in several directions, including generating a larger set of labels using generative vision models and potentially combining them into a single multi-task model. We are also exploring ways of using Large Language Models (LLMs) for conducting category review tasks</p><p>If this type of work interests you, check out some of our related <a href="https://careers.airbnb.com/">roles</a>!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=35b78a837725" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/building-airbnb-categories-with-ml-human-in-the-loop-35b78a837725">Building Airbnb Categories with ML &amp; Human in the Loop</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Prioritizing Home Attributes Based on Guest Interest]]></title>
            <link>https://medium.com/airbnb-engineering/prioritizing-home-attributes-based-on-guest-interest-3c49b827e51a?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/3c49b827e51a</guid>
            <category><![CDATA[ai]]></category>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[scalability]]></category>
            <category><![CDATA[named-entity-recognition]]></category>
            <category><![CDATA[prioritization]]></category>
            <dc:creator><![CDATA[Joy Jing]]></dc:creator>
            <pubDate>Thu, 16 Feb 2023 17:05:39 GMT</pubDate>
            <atom:updated>2023-02-16T17:05:38.931Z</atom:updated>
            <content:encoded><![CDATA[<p><strong>How Airbnb leverages ML to derive guest interest from unstructured text data and provide personalized recommendations to Hosts</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*yoNhrvu8spSI6SuHSCbSkQ.jpeg" /></figure><p><strong>By: </strong><a href="https://www.linkedin.com/in/joyjing1/"><strong>Joy Jing</strong></a><strong> and </strong><a href="https://www.linkedin.com/in/jing-julia-xia-029b3a123/"><strong>Jing Xia</strong></a></p><p>At Airbnb, we endeavor to build a world where anyone can belong anywhere. We strive to understand what our guests care about and match them with Hosts who can provide what they are looking for. What better source for guest preferences than the guests themselves?</p><p>We built a system called the <strong>Attribute Prioritization System</strong> (APS) to listen to our guests’ needs in a home: What are they requesting in messages to Hosts? What are they commenting on in reviews? What are common requests when calling customer support? And how does it differ by the home’s location, property type, price, as well as guests’ travel needs?</p><p>With this personalized understanding of what home amenities, facilities, and location features (i.e. “home attributes”) matter most to our guests, we advise Hosts on which home attributes to acquire, merchandize, and verify. We can also display to guests the home attributes that are most relevant to their destination and needs.</p><p>We do this through a scalable, platformized, and data-driven engineering system. This blog post describes the science and engineering behind the system.</p><p><strong>What do guests care about?</strong></p><p>First, to determine what matters most to our guests in a home, we look at what guests request, comment on, and contact customer support about the most. Are they asking a Host whether they have wifi, free parking, a private hot tub, or access to the beach?</p><p>To parse this unstructured data at scale, Airbnb built <strong>LATEX</strong> (<strong>L</strong>isting <strong>AT</strong>tribute <strong>EX</strong>traction), a machine learning system that can extract home attributes from unstructured text data like guest messages and reviews, customer support tickets, and listing descriptions. LATEX accomplishes this in two steps:</p><ol><li>A <strong>named entity recognition (NER) module</strong> extracts key phrases from unstructured text data</li><li>An <strong>entity mapping module</strong> then maps these key phrases to home attributes</li></ol><p>The <a href="https://spacy.io/usage/linguistic-features#named-entities">named entity recognition (NER)</a> module uses <a href="https://arxiv.org/pdf/1408.5882.pdf">textCNN (convolutional neural network for text)</a> and is trained and fine tuned on human labeled text data from various data sources within Airbnb. In the training dataset, we label each phrase that falls into the following five categories: Amenity, Activity, Event, Specific POI (i.e. “Lake Tahoe”), or generic POI (i.e. “post office”).</p><p>The entity mapping module uses an unsupervised learning approach to map these phrases to home attributes. To achieve this, we compute the cosine distance between the candidate phrase and the attribute label in the fine-tuned word embedding space. We consider the closest mapping to be the referenced attribute, and can calculate a confidence score for the mapping.</p><p>We then calculate how frequently an entity is referenced in each text source (i.e. messages, reviews, customer service tickets), and aggregate the normalized frequency across text sources. Home attributes with many mentions are considered more important.</p><p>With this system, we are able to gain insight into what guests are interested in, even highlighting new entities that we may not yet support. The scalable engineering system also allows us to improve the model by onboarding additional data sources and languages.</p><figure><img alt="An example of a listing’s description with keywords highlighted and labeled by the Latex NER model." src="https://cdn-images-1.medium.com/max/1024/1*4dJVVVQqLcv_kN6bWUtmJw.png" /><figcaption>An example of a listing’s description with keywords highlighted and labeled by the Latex NER model.</figcaption></figure><p><strong>What do guests care about for different types of homes?</strong></p><p>What guests look for in a mountain cabin is different from an urban apartment. Gaining a more complete understanding of guests’ needs in an Airbnb home enables us to provide more personalized guidance to Hosts.</p><p>To achieve this, we calculate a unique ranking of attributes for each home. Based on the characteristics of a home–location, property type, capacity, luxury level, etc–we predict how frequently each attribute will be mentioned in messages, reviews, and customer service tickets. We then use these predicted frequencies to calculate a customized importance score that is used to rank all possible attributes of a home.</p><p>For example, let us consider a mountain cabin that can host six people with an average daily price of $50. In determining what is most important for potential guests, we learn from what is most talked about for other homes that share these same characteristics. The result: hot tub, fire pit, lake view, mountain view, grill, and kayak. In contrast, what’s important for an urban apartment are: parking, restaurants, grocery stores, and subway stations.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*nxdxj3lB48CeTvalc4Bn_A.jpeg" /><figcaption><strong>Image:</strong> An example image of a mountain cabin home</figcaption></figure><figure><img alt="An example of home attributes ranked for a mountain cabin vs an urban apartment." src="https://cdn-images-1.medium.com/max/369/1*kO7ePY4VQxE1lSPhHJ50pA.png" /><figcaption>An example of home attributes ranked for a mountain cabin vs an urban apartment.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*s_rEFw4LE1BQkHnVsU1-Ig.jpeg" /><figcaption><strong>Image:</strong> An example of an urban apartment home</figcaption></figure><p>We could directly aggregate the frequency of keyword usage amongst similar homes. But this approach would run into issues at scale; the cardinality of our home segments could grow exponentially large, with sparse data in very unique segments. Instead, we built an inference model that uses the raw keyword frequency data to infer the expected frequency for a segment. This inference approach is scalable as we use finer and more dimensions to characterize our homes. This allows us to support our Hosts to best highlight their unique and diverse collection of homes.</p><p><strong>How can guests’ preferences help Hosts improve?</strong></p><p>Now that we have a granular understanding of what guests want, we can help Hosts showcase what guests are looking for by:</p><ul><li>Recommending that Hosts acquire an amenity guests often request (i.e. coffee maker)</li><li>Merchandizing an existing home attribute that guests tend to comment favorably on in reviews (i.e. patio)</li><li>Clarifying popular facilities that may end up in requests to customer support (i.e. the privacy and ability to access a pool)</li></ul><p>But to make these recommendations relevant, it’s not enough to know what guests want. We also need to be sure about what’s already in the home. This turns out to be trickier than asking the Host due to the 800+ home attributes we collect. Most Hosts aren’t able to immediately and accurately add all of the attributes their home has, especially since amenities like a crib mean different things to different people. To fill in some of the gaps, we leverage guests feedback for amenities and facilities they have seen or used. In addition, some home attributes are available from trustworthy third parties, such as real estate or geolocation databases that can provide square footage, bedroom count, or if the home is overlooking a lake or beach. We’re able to build a truly complete picture of a home by leveraging data from our Hosts, guests, and trustworthy third parties.</p><p>We utilize several different models, including a Bayesian inference model that increases in confidence as more guests confirm that the home has an attribute. We also leverage a supervised neural network WiDeText machine learning model that uses features about the home to predict the likelihood that the next guest will confirm the attribute’s existence.</p><p>Together with our estimate of how important certain home attributes are for a home, and the likelihood that the home attribute already exists or needs clarification, we are able to give personalized and relevant recommendations to Hosts on what to acquire, merchandize, and clarify when promoting their home on Airbnb.</p><figure><img alt="Cards shown to Hosts to better promote their listings." src="https://cdn-images-1.medium.com/max/1024/1*vtzF4NTBo3XDhVdiXKWl1Q.png" /><figcaption>Cards shown to Hosts to better promote their listings.</figcaption></figure><p><strong>What’s next?</strong></p><p>This is the first time we’ve known what attributes our guests want down to the home level. What’s important varies greatly based on home location and trip type.</p><p>This full-stack prioritization system has allowed us to give more relevant and personalized advice to Hosts, to merchandize what guests are looking for, and to accurately represent popular and contentious attributes. When Hosts accurately describe their homes and highlight what guests care about, guests can find their perfect vacation home more easily.</p><p>We are currently experimenting with highlighting amenities that are most important for each type of home (i.e. kayak for mountain cabin, parking for urban apartment) on the home’s product description page. We believe we can leverage the knowledge gained to improve search and to determine which home attributes are most important for different categories of homes.</p><p>On the Host side, we’re expanding this prioritization methodology to encompass additional tips and insights into how Hosts can make their listings even more desirable. This includes actions like freeing up popular nights, offering discounts, and adjusting settings. By leveraging unstructured text data to help guests connect with their perfect Host and home, we hope to foster a world where anyone can belong anywhere.</p><p>If this type of work interests you, check out some of our related positions at <a href="https://careers.airbnb.com/">Careers at Airbnb</a>!</p><h3>Acknowledgments</h3><p>It takes a village to build such a robust full-stack platform. Special thanks to (alphabetical by last name) <a href="https://www.linkedin.com/in/uabbasi/">Usman Abbasi</a>, <a href="https://www.linkedin.com/in/deanchen1/">Dean Chen</a>, <a href="https://www.linkedin.com/in/guillaumeguy/">Guillaume Guy</a>, <a href="https://www.linkedin.com/in/noah-hendrix-2b148366/">Noah Hendrix</a>, <a href="https://www.linkedin.com/in/hwlical/">Hongwei Li</a>, <a href="https://www.linkedin.com/in/xiao-l-593679194/">Xiao Li</a>, <a href="https://www.linkedin.com/in/saraxliu/">Sara Liu</a>, <a href="https://www.linkedin.com/in/qianru-ma-91850749/">Qianru Ma</a>, <a href="https://www.linkedin.com/in/dan-nguyen-b8817a34/">Dan Nguyen</a>, <a href="https://www.linkedin.com/in/nguyenmartin/">Martin Nguyen</a>, <a href="https://www.linkedin.com/in/brennanpolley/">Brennan Polley</a>, <a href="https://www.linkedin.com/in/pontefederico/">Federico Ponte</a>, <a href="https://www.linkedin.com/in/jose-toti-rodriguez-0b840463/">Jose Rodriguez</a>, <a href="https://www.linkedin.com/in/peng-wang-13117371/">Peng Wang</a>, <a href="https://www.linkedin.com/in/rongru-yan-7077a036/">Rongru Yan</a>, <a href="https://www.linkedin.com/in/meng-yu-b013011/">Meng Yu</a>, <a href="https://www.linkedin.com/in/luzhangtracy/">Lu Zhang</a> for their contributions, dedication, expertise, and thoughtfulness!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=3c49b827e51a" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/prioritizing-home-attributes-based-on-guest-interest-3c49b827e51a">Prioritizing Home Attributes Based on Guest Interest</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Learning To Rank Diversely]]></title>
            <link>https://medium.com/airbnb-engineering/learning-to-rank-diversely-add6b1929621?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/add6b1929621</guid>
            <category><![CDATA[deep-learning]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[ai]]></category>
            <category><![CDATA[airbnb]]></category>
            <dc:creator><![CDATA[Malay Haldar]]></dc:creator>
            <pubDate>Mon, 30 Jan 2023 20:54:33 GMT</pubDate>
            <atom:updated>2023-01-30T22:33:57.097Z</atom:updated>
            <content:encoded><![CDATA[<p>by <a href="https://medium.com/@malay.haldar">Malay Haldar</a>, <a href="https://medium.com/@liweihe">Liwei He</a> &amp; <a href="https://medium.com/@mooseabdool">Moose Abdool</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*f7AlRXdrhZog2gONttd3TA.jpeg" /></figure><p>Airbnb connects millions of guests and Hosts everyday. Most of these connections are forged through search, the results of which are determined by a neural network–based ranking algorithm. While this neural network is adept at selecting <em>individual listings</em> for guests, we recently improved the neural network to better select the overall <em>collection of listings</em> that make up a search result. In this post, we dive deeper into this recent breakthrough that enhances the diversity of listings in search results.</p><h3>How Does Ranking Work?</h3><p>The ranking neural network finds the best listings to surface for a given query by comparing two listings at a time and predicting which one has the higher probability of getting booked. To generate this probability estimate, the neural network places different weights on various listing attributes such as price, location and reviews. These weights are then refined by comparing booked listings against not-booked listings from search logs, with the objective of assigning higher probabilities to booked listings over the not-booked ones.</p><p>What does the ranking neural network learn in the process? As an example, a concept the neural network picks up is that lower prices are preferred. This is illustrated in the figure below, which plots increasing price on the x-axis and its corresponding effect on normalized model scores on the y-axis. Increasing price makes model scores go down, which makes intuitive sense since the majority of bookings at Airbnb skew towards the economical range.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ZTOExPdRXDdibtff" /><figcaption><em>Relation between model scores and percent price increase</em></figcaption></figure><p>But price is not the only feature for which the model learns such concepts. Other features such as the listing’s distance from the query location, number of reviews, number of bedrooms, and photo quality can all exhibit such trends. Much of the complexity of the neural network is in balancing all these various factors, tuning them to the best possible tradeoffs that fit all cities and all seasons.</p><h3>Can One Size Fit All?</h3><p>The way the ranking neural network is constructed, its booking probability estimate for a listing is determined by how many guests in the past have booked listings with similar combinations of price, location, reviews, etc. The notion of higher booking probability essentially translates to what the majority of guests have preferred in the past. For instance, there is a strong correlation between high booking probabilities and low listing prices. The booking probabilities are tailored to location, guest count and trip length, among other factors. However, within that context, the ranking algorithm up-ranks listings that the largest fraction of the guest population would have preferred. This logic is repeated for each position in the search result, so the entire search result is constructed to favor the majority preference of guests. We refer to this as the <em>Majority principle</em> in ranking — the overwhelming tendency of the ranking algorithm to follow the majority at every position.</p><p>But majority preference isn’t the best way to represent the preferences of the entire guest population. Continuing with our discussion of listing prices, we look at the distribution of booked prices for a popular destination — Rome — and specifically focus on two night trips for two guests. This allows us to focus on price variations due to listing quality alone, and eliminate most of other variabilities. Figure below plots the distribution.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*-_xIFlwmpe3tQ-w4" /><figcaption><em>Pareto principle: 50/50 split of booking value corresponds to roughly 80/20 split of bookings</em></figcaption></figure><p>The x-axis corresponds to booking values in USD, log-scale. Left y-axis is the number of bookings corresponding to each price point on the x-axis. The orange shape confirms the log-normal distribution of booking value. The red line plots the percentage of total bookings in Rome that have booking value less than or equal to the corresponding point on x-axis, and the green line plots the percentage of total booking value for Rome covered by those bookings. Splitting total booking value 50/50 splits bookings into two unequal groups of ~80/20. In other words, 20% of bookings account for 50% of booking value. For this 20% minority, cheaper is not necessarily better, and their preference leans more towards quality. This demonstrates the <em>Pareto principle</em>, a coarse view of the heterogeneity of preference among guests.</p><p>While the Pareto principle suggests the need to accommodate a wider range of preferences, the Majority principle summarizes what happens in practice. When it comes to search ranking, the Majority principle is at odds with the Pareto principle.</p><h3>Diversifying by Reducing Similarity</h3><p>The lack of diversity of listings in search results can alternatively be viewed as listings being too similar to each other. Reducing inter-listing similarity, therefore, can remove some of the listings from search results that are redundant choices to begin with. For instance, instead of dedicating every position in the search result to economical listings, we can use some of the positions for quality listings. The challenge here is how to quantify this inter-listing similarity, and how to balance it against the base booking probabilities estimated by the ranking neural network.</p><p>To solve this problem, we build another neural network, a companion to the ranking neural network. The task of this companion neural network is to estimate the similarity of a given listing to previously placed listings in a search result.</p><p>To train the similarity neural network, we construct the training data from logged search results. All search results where the booked listing appears as the top result are discarded. For the remaining search results, we set aside the top result as a special listing, called the antecedent listing. Using listings from the second position onwards, we create pairs of booked and not-booked listings. This is summarized in the figure below.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*6JpNCFVTujDdEZzQ" /><figcaption><em>Construction of training examples from logged search results</em></figcaption></figure><p>We then train a ranking neural network to assign a higher booking probability to the booked listing compared to the not-booked listing, but with a modification — we subtract the output of the similarity neural network that supplies a similarity estimate between the given listing vs the antecedent listing. The reasoning here is that guests who skipped the antecedent listing and then went on to book a listing from results down below must have picked something that is dissimilar to the antecedent listing. Otherwise, they would have booked the antecedent listing itself.</p><p>Once trained, we are ready to use the similarity network for ranking listings online. During ranking, we start by filling the top-most result with the listing that has the highest booking probability. For subsequent positions, we select the listing that has the highest booking probability amongst the remaining listings, after discounting its similarity to the listings already placed above. The search result is constructed iteratively, with each position trying to be diverse from all the positions above it. Listings too similar to the ones already placed effectively get down-ranked as illustrated below.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*4zCEcB5KZ56pFMD2" /><figcaption><em>Reranking of listings based on similarity to top results</em></figcaption></figure><p>Following this strategy led to one of the most impactful changes to ranking in recent times. We observed an increase of 0.29% in uncancelled bookings, along with a 0.8% increase in booking value. The increase in booking value is far greater than the increase in bookings because the increase is dominated by high-quality listings which correlate with higher value. Increase in booking value provides us with a reliable proxy to measure increase in quality, although increase in booking value is not the target. We also observed some direct evidence of increase in quality of bookings — a 0.4% increase in 5-star ratings, indicating higher guest satisfaction for the entire trip.</p><h3>Further Reading</h3><p>We discussed reducing similarity between listings to improve the overall utility of search results and cater to diverse guest preferences. While intuitive, to put the idea in practice we need a rigorous foundation in machine learning, which is described in <a href="https://arxiv.org/pdf/2210.07774.pdf">our technical paper</a>. Up next, we are looking deeper into the location diversity of results. We welcome all comments and suggestions for the technical paper and the blog post.</p><p><em>Interested in working at Airbnb? Check out </em><a href="https://careers.airbnb.com/positions/"><em>these open roles</em></a><em>.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=add6b1929621" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/learning-to-rank-diversely-add6b1929621">Learning To Rank Diversely</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Making Airbnb’s Android app more accessible]]></title>
            <link>https://medium.com/airbnb-engineering/making-airbnbs-android-app-more-accessible-75618172be6?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/75618172be6</guid>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[mobile]]></category>
            <category><![CDATA[front-end-development]]></category>
            <category><![CDATA[android]]></category>
            <category><![CDATA[accessibility]]></category>
            <dc:creator><![CDATA[Julia Fu]]></dc:creator>
            <pubDate>Wed, 11 Jan 2023 19:09:48 GMT</pubDate>
            <atom:updated>2023-01-11T19:09:48.164Z</atom:updated>
            <content:encoded><![CDATA[<p><strong>By:</strong> <a href="https://www.linkedin.com/in/julia-fu-3844b712/">Julia Fu</a>, <a href="https://www.linkedin.com/in/peter-elliott-777125144/">Peter Elliott</a></p><figure><img alt="Decorative image for the blog post." src="https://cdn-images-1.medium.com/max/1024/0*3kx7B-Au3UoHoMon" /></figure><p>At Airbnb, we have been consciously designing and building products to be equally usable by all users. Making our mobile apps and websites more accessible not only aligns with our company’s mission of creating a world where people can belong anywhere, but also supports the civil rights of people with disabilities and complies with the law.</p><p>In this article, we highlight some of the efforts we have made to make the app more accessible, for example, labeling UI elements, grouping related content, supporting large font scale, providing heading and page names. The Airbnb app is one of the most popular travel apps with millions of users and supports many features. Making such a complex app more accessible is a huge endeavor that we are continuously working on.</p><h3>Part I: Build for all: best practices we apply</h3><p>At Airbnb, we follow industry best practices to make the Android app accessible. If you are interested, you can find all best practices we follow from the <a href="https://developer.android.com/guide/topics/ui/accessibility/principles">official Android documentation</a> for platform specific guidelines and the <a href="https://www.w3.org/WAI/standards-guidelines/wcag/">Web Content Accessibility Guidelines</a> as an industry standard. Here we want to highlight a few examples where we apply the best practices:</p><h4>Best Practice: content descriptions</h4><p>Everything shall have accurate content descriptions unless they should be ignored by assistive technology. In these examples, the share button has a content description that TalkBack reads aloud. TalkBack skips the house icon.</p><figure><img alt="Share button highlighted on a listing page. TalkBack output says ‘Share, Button’." src="https://cdn-images-1.medium.com/max/720/0*rl6obaypyKaN2bZ8" /></figure><figure><img alt="Row highlighted with a star icon, bolded and underlined text, another icon with text, and subtitle text on a listing page. TalkBack output omits content for the icons and says ‘Rated 4.88 out of 5 from 203 reviews. Superhost Willington, Connecticut, United States’." src="https://cdn-images-1.medium.com/max/720/0*rYFpxuiMfj2wfJ5X" /></figure><h4>Best practice: grouping</h4><p>Elements of a natural group can be announced together with focusable containers for better usability and accuracy. For instance, Talkback reads all listing content on the card together.</p><figure><img alt="Listing card with a photo, rating, title, and price highlighted on a listing collections page. TalkBack output reads all the information together." src="https://cdn-images-1.medium.com/max/346/1*fMMUt2GVUIjcgw4nn6CY8w.png" /></figure><h4>Best practice: font scale</h4><p>UI shall be usable when the user increases the system font scale.</p><p>Default vs enlarged font scale:</p><figure><img alt="A listing search page with a search bar, tabs with category names, two listing cards, a floating Map button, and a navigation bar at the bottom" src="https://cdn-images-1.medium.com/max/800/0*pZh9ZmVQHUO5EQTV" /></figure><figure><img alt="Same page in a larger font, with only the first listing card visible" src="https://cdn-images-1.medium.com/max/800/0*ybfVcm1W02sTqpOo" /><figcaption>Default font scale on the left. Enlarged font scale on the right.</figcaption></figure><h4>Scaling best practices</h4><p>The Airbnb Android app is a large app with many screens. It would be exhausting and not scalable if we needed to add accessibility code everywhere. Fortunately, our <a href="https://airbnb.design/the-way-we-build/">Design Language System</a> enables us to broadly apply these best practices across product surfaces in a highly efficient way. Every screen is built with a collection of reusable UI components. When we improve the accessibility for one component, the change applies to all the pages with this component as part of the view. This has a long-lasting positive effect on our app’s accessibility improvements. Here’s an example:</p><figure><img alt="The accessibility filters screen for a stay includes a large icon, a heading, subheadings, multiple checkbox options for various features (such as “no stairs or steps to enter”), and a footer.." src="https://cdn-images-1.medium.com/max/800/0*PSzu5IzbOodIuoe4" /></figure><figure><img alt="The same screen with component names overlaid on top, such as DocumentMarquee for the heading, LeadingIconRow and CheckboxRows." src="https://cdn-images-1.medium.com/max/800/0*AsHDrHk6XYKmsrx_" /></figure><p>Take <em>SectionHeader</em> as an example. This UI component is used to communicate the structure on the page and group content together. We mark this component to be an accessibility heading in the component code so it is accessible in all screens that contain this component.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/e09b44464bde190976231f18cf4b5653/href">https://medium.com/media/e09b44464bde190976231f18cf4b5653/href</a></iframe><h3>Part II: Empower engineers with automated checks</h3><p>We invested in automated accessibility testing and linting to run with every code commit, which creates a quick feedback loop for engineers and empowers them to make the app accessible at code writing time. The checks are fast, reliable, and scale well with our fast-growing features in the Android app.</p><h4>Automated testing</h4><p>We set up Espresso-based automated testing to check for accessibility issues. <a href="https://developer.android.com/guide/topics/ui/accessibility/testing#espresso">Espresso</a> is a popular testing library for Android UI with built-in accessibility checks. It supports a comprehensive set of accessibility rules and is easy to set up:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/4b79832fa5516244fd0a65f3f9cc3eaa/href">https://medium.com/media/4b79832fa5516244fd0a65f3f9cc3eaa/href</a></iframe><p>If accessibility checks fail, the test outputs an error stack trace that engineers can use to debug the issue. For example:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/0174ce8368a7f727459bd9821d20aa35/href">https://medium.com/media/0174ce8368a7f727459bd9821d20aa35/href</a></iframe><p>In this example, engineers can provide a content description to the image view to satisfy accessibility requirements.</p><p>We also screenshot test our components with a larger font size to ensure the behavior is correct using <a href="https://medium.com/airbnb-engineering/better-android-testing-at-airbnb-a77ac9531cab">Happo</a>.</p><figure><img alt="A screenshot test of the marquee component using a larger system font. The marquee component contains a vertical stack with an icon, smaller kicker text, larger title text, and smaller subtitle text." src="https://cdn-images-1.medium.com/max/346/1*2uy1-e-ZTJHMtE2ckTALxQ.png" /></figure><h4>Linting</h4><p>In addition to automated testing, we also enabled linting, including <a href="https://developer.android.com/studio/write/lint">Android Lint</a> rules for accessibility and custom lint rules built with <a href="https://github.com/pinterest/ktlint">Ktlint</a>.</p><p>Here is an example of an Android accessibility lint rule:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/1b1b4a919b19bc68033e0a72e1071863/href">https://medium.com/media/1b1b4a919b19bc68033e0a72e1071863/href</a></iframe><p>Besides the built-in Android Lint, we also use Ktlint to build custom lint rules. For instance, when a user navigates to a new screen, we provide a page name for a screen reader to announce. We use the following rule to make sure that the page name is localized.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/5fb8b7641ffa3f5b714a872bd46f55c9/href">https://medium.com/media/5fb8b7641ffa3f5b714a872bd46f55c9/href</a></iframe><p>Lint rules are straightforward to set up and provide timely feedback, but linting has limitations — it can only perform static code analysis.</p><p>Today, these automated checks run as part of CI (Continuous Integration) checks for every code commit. If a pull request does not pass the checks, it will be blocked from being merged into the primary code branch. We still use manual testing to cover the areas that automated checks do not cover, such as the traversal order of UI elements on a page. Automated and manual checks complement each other well.</p><h3>Part III: Looking into the future: Accessibility with Compose</h3><p>Over the past year, we have been integrating Jetpack Compose into our app. Google’s <a href="https://developer.android.com/jetpack/compose/accessibility">Accessibility in Compose documentation</a> has been a great resource to ensure our Compose components and screens remain accessible. While there are some notable things missing that existed with Views (e.g. focus order modification), Compose is still a young library and we look forward to future improvements. Here are a couple of things worth mentioning about our Compose-specific accessibility tooling:</p><h4>Proactively encourage content descriptions in the API</h4><p>One of our guidelines for UI components is that content descriptions exposed via a function parameter should not use a default value. This brings accessibility to the top of mind when an engineer uses the component as they need to consider what value to pass. A null value is still acceptable in cases where that UI element is not important for accessibility.</p><figure><img alt="A screenshot of an IconRow component that shows an icon beside two lines of text." src="https://cdn-images-1.medium.com/max/346/1*IeCWV4mFIJfWHe7lUJKdQg.png" /></figure><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/89979317838408078250e7e3e940a6f0/href">https://medium.com/media/89979317838408078250e7e3e940a6f0/href</a></iframe><h4>Page name announcements</h4><figure><img alt="A screenshot of several photos of a listing with the up button focused in the toolbar. The TalkBack output says “Photo tour of the listing”. We allow hosts to add captions for photos. If captions are provided, they are announced by Talkback when a user clicks on the photo. If no captions are provided, we do not generate them." src="https://cdn-images-1.medium.com/max/346/1*zZ6NlICykhaRaVG_hkbVBg.png" /></figure><p>When using Fragments and Views, we use the <em>View.setAccessibilityPaneTitle()</em> and <em>View.announceForAccessibility()</em> APIs when navigating to a new screen to announce a descriptive page name to the user. These APIs do not exist in Compose but we wanted to keep the functionality since it helps to provide more context as to what the new screen displays. Our current workaround sets certain semantics on the screen’s outer composable:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/d81a055b12947d2895a8d7f6e5b89cfb/href">https://medium.com/media/d81a055b12947d2895a8d7f6e5b89cfb/href</a></iframe><p>We use the <em>liveRegion</em> property so changes can be announced when the content description changes. This is useful for pages whose entire content is determined by a response from the server. In this case, TalkBack would announce “Content Loading” while the network request is pending, followed by “Content Loaded” when it completes, and finally the page description defined in the server response. One downside of this approach is that it requires the outer container to be focusable, which requires an additional navigation action to get to the content.</p><h3>Closing thoughts</h3><p>Making our Android app more accessible has been an impactful journey. Improving app accessibility involves following best practices, adding rigorous enforcements, continually learning from mistakes, and putting in the work. All of these are worthy efforts to make sure an app works for all users.</p><p>If you are excited about building highly accessible products and the framework to support them, check out some of our related open positions:</p><p><a href="https://careers.airbnb.com/positions/4590099/">Staff Android Software Engineer, Guest</a></p><p><a href="https://careers.airbnb.com/positions/4648432/">Senior iOS Software Engineer, Infrastructure</a></p><h3>Acknowledgments</h3><p>It is a huge endeavor to make a complex app like the Airbnb Android app more accessible. This work wouldn’t be possible without the enormous efforts from the digital accessibility team and the close-knit Android community at Airbnb. Every engineer has contributed to making the features they own accessible. Making the Android app more accessible is an ongoing effort and it could not succeed without all of them.</p><h3>****************</h3><p><em>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</em></p><p><em>All bookings included in this blog post are intended to illustrate. Airbnb does not endorse or promote these listings or any other accommodations or experiences on the platform.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=75618172be6" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/making-airbnbs-android-app-more-accessible-75618172be6">Making Airbnb’s Android app more accessible</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[When a Picture Is Worth More Than Words]]></title>
            <link>https://medium.com/airbnb-engineering/when-a-picture-is-worth-more-than-words-17718860dcc2?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/17718860dcc2</guid>
            <category><![CDATA[similarity-search]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[deep-learning]]></category>
            <category><![CDATA[aesthetics]]></category>
            <category><![CDATA[computer-vision]]></category>
            <dc:creator><![CDATA[Yuanpei Cao]]></dc:creator>
            <pubDate>Thu, 08 Dec 2022 18:03:50 GMT</pubDate>
            <atom:updated>2022-12-08T18:03:50.795Z</atom:updated>
            <content:encoded><![CDATA[<p>How Airbnb uses visual attributes to enhance the Guest and Host experience</p><p><em>By </em><a href="https://www.linkedin.com/in/yuanpei-cao-792b103b/"><em>Yuanpei Cao</em></a><em>, </em><a href="https://www.linkedin.com/in/bulam/"><em>Bill Ulammandakh</em></a><em>, </em><a href="https://www.linkedin.com/in/hao-wang-2661553/"><em>Hao Wang</em></a><em>, and </em><a href="https://www.linkedin.com/in/hwangtt/"><em>Tony Hwang</em></a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*qlUYnDrTVDAYZfqE" /></figure><h3><strong>Introduction</strong></h3><p>On Airbnb, our hosts share unique listings all over the world. There are hundreds of millions of accompanying listing photos on Airbnb. Listing photos contain crucial information about style and design aesthetics that are difficult to convey in words or a fixed list of amenities. Accordingly, multiple teams at Airbnb are now leveraging computer vision to extract and incorporate intangibles from our rich visual data to help guests easily find listings that suit their preferences.</p><p>In previous blog posts titled <a href="https://medium.com/airbnb-engineering/widetext-a-multimodal-deep-learning-framework-31ce2565880c"><em>WIDeText: A Multimodal Deep Learning Framework</em></a>,<em> </em><a href="https://medium.com/airbnb-engineering/categorizing-listing-photos-at-airbnb-f9483f3ab7e3"><em>Categorizing Listing Photos at Airbnb</em></a> and <a href="https://medium.com/airbnb-engineering/amenity-detection-and-beyond-new-frontiers-of-computer-vision-at-airbnb-144a4441b72e"><em>Amenity Detection and Beyond — New Frontiers of Computer Vision at Airbnb</em></a>, we explored how we utilize computer vision for room categorization and amenity detection to map listing photos to a taxonomy of discrete concepts. This post goes beyond discrete categories into how Airbnb leverages image aesthetics and embeddings to optimize across various product surfaces including ad content, listing presentation, and listing recommendations.</p><h3>Image aesthetics</h3><p>Attractive photos are as vital as price, reviews, and description during a guest’s Airbnb search journey. To quantify “attractiveness” of photos, we developed a deep learning-based image aesthetics assessment pipeline. The underlying model is a deep convolutional neural network (<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">CNN</a>) trained on human-labeled image aesthetic rating distributions. Each photo was rated on a scale from 1 to 5 by hundreds of photographers based on their personal aesthetic measurements (the higher the rating, the better the aesthetic). Unlike traditional classification tasks that classify the photo into low, medium and high-quality categories, the model was built upon the Earth Mover’s Distance (<a href="https://en.wikipedia.org/wiki/Earth_mover%27s_distance">EMD</a>) as the loss function to predict photographers’ rating distributions.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*9uDKRsxap29D2jTg" /><figcaption><em>Figure 1. The model that predicts image aesthetics distribution is CNN-based and trained with the EMD loss function. Suppose the ground truth label of a photo is: 10% of users give ratings 1 and 2, respectively, 20% give rating 3, and 30% give ratings 4 and 5, respectively. The corresponding prediction is [0.1, 0.1, 0.2, 0.3, 0.3]</em></figcaption></figure><p>The predicted mean rating is highly correlated with image resolution and listing booking probability, as well as high-end Airbnb listing photo distribution. Rating thresholds are set based on use cases, such as ad photo recommendation on social media and photo order suggestion in the listing onboarding process.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*oX4zLXa1xuW5dZ1u" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*kPzH6oeThUYOm-Lu" /><figcaption><em>Figure 2. Examples of Airbnb listing photos with aesthetics scores higher than the 90% percentile</em></figcaption></figure><h3>Image aesthetic-based ads quality improvement</h3><p>Airbnb uses advertising on social media to attract new customers and inspire our community. The social media platform chooses which ads to run based on millions of Airbnb-provided listing photos.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/750/0*Cs_Sp9Db3uebMDQA" /><figcaption><em>Figure 3. Airbnb Ads displayed on Facebook</em></figcaption></figure><p>Since a visually appealing Airbnb photo can effectively attract users to the platform and considerably increase the ad’s click-through rate (CTR), we utilized the image aesthetic score and room categorization to select the most attractive Airbnb photos of the living room, bedroom, kitchen, and exterior view. The criterion for “good quality” listing photos was set based on the top 50th percentile of the aesthetic score and tuned based on an internal manual aesthetic evaluation of 1K randomly selected listing cover photos. We performed A/B testing for this use case and found that the ad candidates with a higher aesthetic score generated a substantially higher CTR and booking rate.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*qkiOeZNUrFiQ9hp0" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*3wAi8A6I4pgZh2ti" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*EAZedvb_PXHZT4j0" /><figcaption><em>Figure 4. Pre-selected Airbnb Creative Ads through image aesthetics and room type filters</em></figcaption></figure><h3>Automated photo ranking based on home design and room type</h3><p>When posting a new listing on Airbnb, hosts upload numerous photos. Optimally arranging these photos to highlight a home can be time-consuming and challenging. A host may also be uncertain about the ideal arrangement for their images because the work requires making trade-offs between photo attractiveness, photo diversity, and content relevance to guests. More specifically, the first five photos are the most important for listing success as they are the most frequently viewed and crucial to forming the initial guest impression. Accordingly, we developed an automated photo ranking algorithm that selects and orders the first five photos of a home leveraging two visual signals: home design evaluation and room categorization.</p><p>Home design evaluation estimates how well a home is designed from an interior design and architecture perspective. The CNN-based home design evaluation model is trained on Airbnb<em> Plus </em>and<em> Luxe</em> qualification data that assess the aesthetic appeal of each photo’s home design. Airbnb <em>Plus</em> and <em>Luxe</em> listings have passed strict home design evaluation criteria and so the data from their qualification process is well-suited to be used as training labels for a home design evaluation model. The photos are then classified into different room types, such as living room, bedroom, bathroom etc, through the room categorization model. Finally, an algorithm makes trade-offs between photo home design attractiveness, photo relevance, and photo diversity to maximize the booking probability of a home. Below is an example of how a new photo order is suggested. The photo auto-rank feature was launched in Host’s listing onboarding product in 2021, leading to significant lifts in new listing creation and booking success.</p><p><strong>Original ordering</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*pnBb2R9FSRaKolwe" /></figure><p><strong>Auto-suggested ordering</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Ycy7KI2DK_dhX98a" /><figcaption><em>Figure 5. The example of original photo order (top) uploaded by Airbnb Host and auto-suggested order (bottom) calculated by the proposed algorithm</em></figcaption></figure><h3>Image similarity</h3><p>Beyond aesthetics, photos also capture the general appearance and content. To efficiently represent this information, we encode and compress photos into image embeddings using computer vision models. Image embeddings are compact vector representations of images that represent visual features. These embeddings can be compared against each other with a distance metric that represents similarity in that feature space.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*qJaLeY5a3rvkR87m" /><figcaption><em>Figure 6. Image embeddings can be compared by distance metrics like cosine similarity to represent their similarity in the encoded latent space</em></figcaption></figure><p>The features learned by the encoder are directly influenced by the training image data distribution and training objectives. Our labeled room type and amenity classification data allows us to train models on this data distribution to produce semantically meaningful embeddings for listing photo similarity use cases. However, as the quantity and diversity of images on Airbnb grow, it becomes increasingly untenable to rely solely on manually labeled data and supervised training techniques. Consequently, we are currently exploring self-supervised contrastive training to improve our image embedding models. This form of training does not require image labels; instead, it bootstraps contrastive learning with synthetically generated positive and negative pairs. Our image embedding models can then learn key visual features from listing photos without manual supervision.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*hU4Ij4D2PUCVyN0V" /><figcaption><em>Figure 7. Introducing random image transformations to synthetically create positive and negative pairs helps refine our image encoders without additional labeling.</em></figcaption></figure><h3>Scalable embedding search</h3><p>It is often impractical to compute exhaustive pairwise embedding similarity, even within focused subsets of millions of items. To support real-time search use cases, such as (near) duplicate photo detection and visual similarity search, we instead perform an approximate nearest neighbor (<a href="https://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximate_nearest_neighbor">ANN</a>) search. This functionality is largely enabled by an efficient embedding index preprocessing and construction algorithm called Hierarchical Navigable Small World (<a href="https://arxiv.org/abs/1603.09320">HNSW</a>). HNSW builds a hierarchical proximity graph structure that greatly constrains the search space at query time. We scale this horizontally with AWS OpenSearch, where each node contains its own HNSW embedding graphs and Lucene-backed indices that are hydrated periodically and can be queried in parallel. To add real-time embedding ANN search, we have implemented the following index hydration and index search design patterns enabled by existing Airbnb internal platforms.</p><p>To hydrate an embedding index on a periodic basis, all relevant embeddings computed by <a href="https://ieeexplore.ieee.org/document/8964147">Bighead</a>, Airbnb’s end-to-end machine learning platform, are aggregated and persisted into a Hive table. The encoder models producing the embeddings are deployed for both online inference and offline batch processing. Then, the incremental embedding update is synced to the embedding index on AWS OpenSearch through Airflow, our data pipeline orchestration service.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*701twLpGC7cAqooo" /><figcaption><em>Figure 8. Index hydration data pathway</em></figcaption></figure><p>To perform image search, a client service will first verify whether the image’s embedding exists in the OpenSearch index cache to avoid recomputing embeddings unnecessarily. If the embedding is already there, the OpenSearch cluster can return approximate nearest neighbor results to the client without further processing. If there is a cache miss, Bighead is called to compute the image embedding, followed by a request to query the OpenSearch cluster for approximate nearest neighbors.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*gPnnwDRV1gU6VJ9g" /><figcaption><em>Figure 9. Image similarity search for a previously unseen image</em></figcaption></figure><p>Following this embedding search framework, we are scaling real-time visual search in current production flows and upcoming releases.</p><h3>Expanding Airbnb categories</h3><p><a href="https://www.airbnb.com/2022-summer">Airbnb Categories</a> help our guests discover unique getaways. Some examples are “Amazing views”, “Historical homes”, and “Creative spaces”. These categories do not always share common amenities or discrete attributes, as they often represent an inspirational concept. We are exploring automatic category expansion by identifying similar listings based on their photos, which do capture design aesthetics.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*_m9Kv0hZdqYRDAZL" /><figcaption><em>Figure 10. Listing photos from the “Creative spaces” category</em></figcaption></figure><h3>Similar listing recommendations in rebooking assistance</h3><p>In the 2022 Summer Release, Airbnb introduced rebooking assistance to offer guests a smooth experience from Community Support ambassadors when a Host cancels on short notice. For the purpose of recommending comparable listings throughout the rebooking process, a two-tower reservation and listing embedding model ranks candidate listings, updated on a daily basis. As future work, we can consider augmenting the listing representation with image embeddings and enabling real-time search.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*at3MPM2B3Mj-etNu" /><figcaption><em>Figure 11. The example of a landing page that recommends similar listings to guests and Community Support ambassadors in the Rebooking assistance.</em></figcaption></figure><h3>Conclusion</h3><p>Photos contain aesthetic and style-related signals that are difficult to express in words or map to discrete attributes. Airbnb is increasingly leveraging these visual attributes to help our hosts highlight the unique character of their listings and to assist our guests in discovering listings that match their preferences.</p><p>Interested in working at Airbnb? Check out our <a href="https://careers.airbnb.com/">open roles</a>.</p><h3>Acknowledgements</h3><p>Thanks to Teng Wang, Regina Wu, Nan Li, Do-kyum Kim, Tiantian Zhang, Xiaohan Zeng, Mia Zhao, Wayne Zhang, Elaine Liu, Floria Wan, David Staub, Tong Jiang, Cheng Wan, Guillaume Guy, Wei Luo, Hanchen Su, Fan Wu, Pei Xiong, Aaron Yin, Jie Tang, Lifan Yang, Lu Zhang, Mihajlo Grbovic, Alejandro Virrueta, Brennan Polley, Jing Xia, Fanchen Kong, William Zhao, Caroline Leung, Meng Yu, Shijing Yao, Reid Andersen, Xianjun Zhang, Yuqi Zheng, Dapeng Li, and Juchuan Ma for the product collaborations. Also thanks Jenny Chen, Surashree Kulkarni, and Lauren Mackevich for editing.</p><p>Thanks to Ari Balogh, Tina Su, Andy Yasutake, Joy Zhang, Kelvin Xiong, Raj Rajagopal, and Zhong Ren’s leadership support on building computer vision products at Airbnb.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=17718860dcc2" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/when-a-picture-is-worth-more-than-words-17718860dcc2">When a Picture Is Worth More Than Words</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
    </channel>
</rss>