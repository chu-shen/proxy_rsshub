<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[The Airbnb Tech Blog - Medium]]></title>
        <description><![CDATA[Creative engineers and data scientists building a world where you can belong anywhere. http://airbnb.io - Medium]]></description>
        <link>https://medium.com/airbnb-engineering?source=rss----53c7c27702d5---4</link>
        <image>
            <url>https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png</url>
            <title>The Airbnb Tech Blog - Medium</title>
            <link>https://medium.com/airbnb-engineering?source=rss----53c7c27702d5---4</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Thu, 07 Oct 2021 00:48:16 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/airbnb-engineering" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Designing for Productivity in a Large-Scale iOS Application]]></title>
            <link>https://medium.com/airbnb-engineering/designing-for-productivity-in-a-large-scale-ios-application-9376a430a0bf?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/9376a430a0bf</guid>
            <category><![CDATA[ios-app-development]]></category>
            <category><![CDATA[mobile-app-development]]></category>
            <category><![CDATA[xcode]]></category>
            <category><![CDATA[ios]]></category>
            <category><![CDATA[swift]]></category>
            <dc:creator><![CDATA[Michael Bachand]]></dc:creator>
            <pubDate>Tue, 05 Oct 2021 17:29:02 GMT</pubDate>
            <atom:updated>2021-10-05T17:33:19.984Z</atom:updated>
            <content:encoded><![CDATA[<p><em>How innovation in technology and people processes have enabled iOS developers to remain productive in a large codebase.</em></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*YoPXkM2HntwCXznpl96Ouw.png" /></figure><p>Every iOS engineer remembers the joy of seeing their first application running on an iOS device. The human-centric interface of the iPhone brings the program to life. When you choose iOS development as a career, that joy grows as your application touches more people’s lives.</p><p>Affecting more users often involves new iOS features, flows, and functionality. But as an application grows to serve more users, new features and functionality can introduce additional weight and complexity, which slows product iteration and precludes atomic refactors.</p><p>We have undergone this journey as an iOS team at Airbnb. There is a profound joy knowing that the code we ship every week enables unforgettable vacations for guests and new revenue streams for host entrepreneurs. A focus on design is in our DNA and we take immense pride in perfecting every detail of what we show to our users. At the same time we have not been immune to the challenges of developing at scale.</p><p>In this article, we will walk through difficulties that we have encountered in accommodating the growing business needs of Airbnb. We will outline how investments in technology, ownership, and processes have allowed the Airbnb iOS team to have the best of both worlds: working in a globally impactful codebase without feeling its weight.</p><h3>Challenges of developing a large-scale iOS app</h3><p>An Airbnb intern made the first commit to our iOS application on June 16th, 2010. Since then, that same Xcode project has evolved into a codebase with 1.5 million lines of first-party code. About 75 iOS engineers work on our application today. We ship the app weekly in 62 languages supporting a community of guests and hosts in nearly every country on the planet.</p><p>At Airbnb’s scale, code organization becomes a challenge. We welcome and encourage experimentation and new ideas. Then, once we’ve sufficiently explored a solution space, we value the consistency of an “Airbnb way.” Until recently, most of our code was organized into modules within a flat directory called lib/. Without any hierarchy or categorization of our code, it became hard for engineers to find the existing implementations of general-purpose capabilities. We began to notice many ways to accomplish the same task in our application code, which bloated the binary that we shipped to users. Moreover, we found that each competing implementation of the same capability tended to be of lower quality than one implementation that received more investment and attention.</p><p>While Xcode is the tool in which iOS engineers feel most comfortable working, we found that Xcode does not scale gracefully to a codebase of our size and complexity. Not only are Xcode project files challenging to review in pull requests, but the incidence of merge conflicts and race conditions in these project files increased with a larger team of engineers moving at a high velocity. Even opening Xcode can become a chore with a large codebase. Over a year ago, we measured that Xcode would take between one and two minutes to become interactive when loading a workspace with all of our source code.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*bbD6oAGQtHcVKz0XXU6SCw.png" /><figcaption><em>A pull request circa 2018 adding one new module. Over half of the changes to the pbxproj Xcode project file are not shown in this screenshot.</em></figcaption></figure><p>Most iOS engineers became frustrated with long build times and slow iteration loops. At one point, a particularly creative engineer found that his laptop would compile code faster if he unplugged his external monitor. Many engineers have trained themselves to plug the USB-C charging cable into the <a href="https://www.imore.com/heres-why-you-should-probably-charge-your-macbook-using-ports-its-right-side">right side</a> of their MacBook Pro to avoid the productivity loss of thermal throttling. When Airbnb’s codebase was less than 500k lines of first-party code, some of these problems could be rectified with more powerful hardware, though we identified a practical limit to that solution as well. It became hard to feel like you were doing your best work when large amounts of your day were spent waiting for builds to complete.</p><p>These challenges grew organically. Feedback from new hires provided valuable input for how we should prioritize infrastructure needs, as iOS engineers who came from companies with smaller projects had not yet become used to the sluggishness and workarounds of an overgrown codebase. We knew that something had to change to ensure that Airbnb continued to ship a world-class iOS application.</p><h3>Solutions we’ve implemented</h3><p>We investigated and implemented many solutions over the years to solve the problems stated above. In this post we will discuss the three biggest levers that have allowed us to operate efficiently at scale. We expect that these high-level themes will be applicable to other small- to medium-sized iOS teams undergoing rapid growth.</p><h4>Adopting a modern build system</h4><p>Xcode remains the preferred IDE for iOS engineers at Airbnb. At the same time, we’ve seen features in other build systems that we knew could improve the productivity of iOS developers. A few stood out: network caches of build artifacts, a query interface for the build graph, and a seamless way to add custom steps as dependencies. We believe that these capabilities are table stakes for a modern build system.</p><p>Facebook’s <a href="https://buck.build/">Buck</a> build system met these requirements. We began discussing Buck seriously in late 2016 and began explorations in earnest in 2017. In 2019, we fully transitioned to Buck’s declarative build system. We have benefited greatly from Buck though we found that public documentation left much to be desired. Accordingly, we have shared our Buck setup in a <a href="https://github.com/airbnb/BuckSample">public GitHub repository</a>.</p><p>As part of this transition, we removed our manually managed Xcode projects in favor of declarative BUCK files, which live adjacent to each module’s code. BUCK files are defined using the <a href="https://github.com/bazelbuild/starlark">Starlark</a> language, which is interoperable with Bazel, another popular modern build system. Below is the structure of an existing Airbnb module.</p><pre>~/apps/ios/features/WifiSpeedFeature&gt; tree -L 1<br>.<br>├── BUCK<br>├── Sources<br>├── Tests<br>└── _infra</pre><pre>3 directories, 1 file</pre><p>Our infrastructure teams have taken the approach that we should meet engineers where they’re at while supercharging their development experience under the hood. Accordingly, iOS engineers continue to develop in an Xcode workspace that is generated from the build graph defined in Buck.</p><p>Initially, only our command line Buck builds of the Airbnb iOS application could benefit from the Buck HTTP cache. This alone was a great improvement since it enabled us to validate that an App Store build would succeed on every pull request without slowing down engineers. Local Xcode builds, however, could not pull artifacts from the cache as the generated Xcode workspace continued to use the standard Xcode build system.</p><p>We have continued to leverage the modern build system at the foundation of our application to tighten the iteration loop for engineers. We <a href="https://github.com/airbnb/BuckSample/pull/134">made it possible</a> to generate an Xcode workspace that internally builds the application using the Buck build system. All of the standard Xcode tools (breakpoints, console, errors) that iOS engineers use every day work as expected.</p><p>The Buck-based Xcode workspace improved local build speeds as it can participate in Buck’s cache. To improve the launch time of Xcode, we also made it possible to generate an Xcode workspace with only a subset of our entire codebase. The entire application continues to be built with Buck, and Xcode becomes interactive in a fraction of the time.</p><h4>Designing module types</h4><p>To address the lack of hierarchy in our code, and therefore lack of discoverability, we have designed an organizational structure for our first-party code. Modules are organized into semantically meaningful groups, called <em>module types</em>.</p><p>We have written precise documentation for our module types. Since the concept of module types is so fundamental to the way iOS developers work at Airbnb, this documentation is hosted on our internal developer portal and managed in source control. We summarize each module type in just a few paragraphs, explaining the purpose of the module type and the types of code it was designed to support.</p><p>We considered both application programming and build system best practices when designing this architecture. Each module type has a strict set of <a href="https://buck.build/concept/visibility.html">visibility rules</a>. These visibility rules define the allowed dependencies between modules of that type. An individual module may tighten its visibility, a technique used by some larger teams who enjoy the benefits of modularity and want to avoid unexpected inbound dependencies on their modules. An individual module cannot expand its visibility beyond the limits imposed by its module type.</p><blockquote><strong>Let’s look at an example…</strong></blockquote><blockquote>A <em>feature</em> is one of our core module types. At Airbnb, features are user-facing destinations. In our iOS code, a user-facing destination is a UIViewController that will be presented modally or installed into a UINavigationController. A feature module should be scoped to a single user-facing destination when possible, though it may contain multiple UIViewControllers that implement the destination.</blockquote><blockquote>Feature modules are not visible to other feature modules (i.e. a feature module cannot depend on a feature module); however, they share lightweight types via a sibling module type called a <em>feature interface</em>.</blockquote><blockquote>Each feature has a corresponding feature interface, which has broader visibility. A feature can depend on any number of feature interface modules and always depends on its own interface module. The interface functions similarly to how header files function in Clang programs.</blockquote><blockquote>The visibility rules of the feature module type ensure that all feature modules are independent of each other. The interface module type allows features to share simple types (protocols, enumerations, value types), enabling capabilities like strongly typed <a href="https://youtu.be/ray2vMjg2ug?t=661s">routing</a> between features.</blockquote><blockquote>In addition to the feature module type, the <em>service</em> module type is home to non-UI objects that are responsible for managing state that is shared between features. Any service module may optionally have an interface sibling module as well.</blockquote><blockquote>We have twelve iOS module types at Airbnb today.</blockquote><p>Our semantically meaningful module types act as a table of contents for our very large codebase. Engineers immediately have a reasonably accurate mental model for a module based on its type. 90% of our first-party code has been migrated from lib/ to module types. A great <a href="https://www.youtube.com/watch?v=KhZcSRXJHFs&amp;t=190s">talk</a> by my colleague Francisco describes in greater detail how our code organization strategy evolved from folders to module types and also sheds light on how we operationalized this large migration.</p><h4>Creating Dev Apps</h4><p>Our investments in build systems and iOS application architecture enabled a third innovation: Dev Apps. A <em>Dev App</em> is an on-demand, ephemeral Xcode workspace for a single module and its dependencies.</p><p>Dev Apps originated in the Airbnb Android ecosystem. The popularity and success of both Android and iOS Dev Apps derive from a simple axiom: minimizing your IDE scope to only the files that you are editing tightens the development loop. When there is less code in your Xcode workspace, Xcode can index and compile that code more quickly.</p><p>Adopting module types in our codebase broke costly dependencies between functional units. Now modules have minimal dependencies. For example, building any feature module and all of its dependencies is always much cheaper than building the entire Airbnb application. Since feature modules cannot depend on other feature modules, we have defined away the possibility of mega features that transitively build the entire application.</p><p>iOS engineers create Dev Apps using a robust and user-friendly command line interface. The command to generate a Dev App follows Unix best practices with a focus on being accessible to engineers who may not be comfortable in Terminal. Under the hood the tool uses Buck’s query interface to assemble the full list of source files.</p><p>The Dev App command line tool generates a container iOS application to host the feature and opens a generated Xcode workspace. Developers define variants of their feature in non-production code. These variants enable one-tap access to any possible UI state. The Dev App container application provides conveniences for common workflows, like attaching an OAuth token to HTTP requests.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Q_-p6QlfNnCINf_2PdBYOQ.png" /><figcaption><em>A Dev App for an existing Airbnb module. Developers can test all states of their feature by defining variants (left). Developer settings support live network requests (right).</em></figcaption></figure><p>A Dev App allows a product developer to iterate on their feature’s UI and much of its business logic while building a fraction of the overall Airbnb application. Although Dev Apps were designed for feature and UI modules, we now support creating a Dev App for any module type. We have found that many iOS developers also prefer to work on non-UI modules in this minimal Xcode environment.</p><p>It remains critical to build and run the entire Airbnb application in many situations, especially for testing how features interact with each other. However, when you are working on code that is sufficiently isolated and well-tested, it can be possible to ship that change confidently with a Dev App alone.</p><h3>Breaking through to the other side</h3><p>Our efforts have created an ecosystem where teams can operate independently on their surface areas. Coding in a Dev App recalls the joy of coding in a simpler, smaller project with all of the benefits of being supported by mature first-party tools and frameworks.</p><p>Dev Apps now drive over 50% of local builds. The 75th percentile of Dev App build times is under two minutes, with the 50th percentile well under one minute. We encourage Dev Apps to use mocked dependencies as much as possible to reduce the code required to be built.</p><p>Our application architecture has ushered in an era of 100% code ownership. We have maintained 100% ownership through team reorganizations due in part to our highly modularized codebase, which allows the ownership to be transferred and repartitioned with minimal refactoring. Today, our first-party code is divided into nearly 1,500 modules.</p><p>We see over 50% test coverage for code in our modern module structure while code that remains in the legacy module structure has 23% coverage. This is in part due to interface modules, which strongly push developers to write services using the protocol-oriented programming technique. When code interacts primarily with protocols, it is easy to create test doubles for dependencies.</p><p>By retaining strict visibility rules between module types, we have achieved a highly parallelized build graph. When examining the trace for a build of the full Airbnb app on a 8-core, 16-inch 2019 MacBook Pro we see full utilization of the available CPU resources for nearly 80% of the compilation phase.</p><p>Our modern build system has enabled a healthy ecosystem of command line tools which greatly simplify common tasks. Creating a module previously involved following a long checklist of error-prone steps. Now engineers create modules with an interactive Rake command. We even leveraged our Buck query interface to build a command line tool which guides engineers through the steps necessary to migrate their lib/ modules to the new module structure.</p><p>And last, but certainly not least, by no longer managing Xcode projects in source control, it is now trivial to add and remove module dependencies with an easy path to resolving any merge conflicts.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dsA7iuafUp4j47gd6IdELA.png" /><figcaption><em>A portion of a recent PR that adds a dependency to a feature module. Starlark build files make the code easy to write and review.</em></figcaption></figure><h3>Pushing the edge of the envelope together</h3><p>At Airbnb, we are passionate about advancing the state of iOS development in the industry at large. We believe in the power of native applications running on mobile devices and want other companies to leverage the work that we’ve done so that they can focus more energy on building experiences that users love.</p><p>We know that we are not the only company whose application has grown organically from a small project to something larger than what the original author may have conceived to be possible. We know that many of our peer companies have undergone similar transformations to our own. Each of our aforementioned solutions are specific to our circumstances and culture, though we have seen the themes to be evergreen. We are excited to continue this work in the public domain with our peer companies as part of the <a href="https://mobilenativefoundation.org/">Mobile Native Foundation</a>.</p><p>Our journey of improving productivity is not done yet. As we look to the future we see a massive opportunity to use <a href="https://github.com/apple/swift-syntax">Swift static analysis</a> to generate boilerplate code and increase code portability of features and services. We will continue to tighten the build/test/run iteration loop of iOS product development so that the weight of a mega iOS application does not stifle the joy of indie iOS development. And we yearn for a modern build system blessed by Apple.</p><p>We believe that we’ve only scratched the surface of mobile computing. We will continue to improve upon the tools, technologies, and people processes necessary to innovate at scale.</p><p>Many thanks to <a href="https://www.linkedin.com/in/fdiazmeza">Francisco Díaz</a> for advising on content and voice through multiple revisions of this article. The work described in this article is the product of many talented Airbnb iOS engineers.</p><p>If you are interested in joining us on our continuing quest to make the best iOS apps in the App Store, please see our <a href="https://careers.airbnb.com/">careers</a> page for open iOS roles.</p><p><em>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=9376a430a0bf" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/designing-for-productivity-in-a-large-scale-ios-application-9376a430a0bf">Designing for Productivity in a Large-Scale iOS Application</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How Airbnb Tech Fosters a Culture of Learning]]></title>
            <link>https://medium.com/airbnb-engineering/how-airbnb-tech-fosters-a-culture-of-learning-854be0f9fe9d?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/854be0f9fe9d</guid>
            <category><![CDATA[learning]]></category>
            <category><![CDATA[tech-education]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[education]]></category>
            <category><![CDATA[data-science]]></category>
            <dc:creator><![CDATA[Tamera Scholz]]></dc:creator>
            <pubDate>Thu, 30 Sep 2021 20:11:24 GMT</pubDate>
            <atom:updated>2021-09-30T20:24:23.633Z</atom:updated>
            <content:encoded><![CDATA[<p>Leveraging technical learning and development to enable engineers to do their best work.</p><p>Authors: Hanna Dooley, Jennifer Rice, Tamera Scholz</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*2MJ-_TsCSo4MvyD_" /></figure><h3>Introduction</h3><p>The Airbnb TechED team believes each individual’s success is critical to the health of our technical teams. This fundamental belief in the power of human potential drives us to bring high quality, relevant educational content to our technical teams to meet both their needs and the needs of Airbnb. We work with our technical leaders and subject matter experts (SMEs) to build and deliver unique, interactive, multimodal learning experiences at scale.</p><p>We have three principles for approaching technical learning:</p><ul><li>Embrace the adventure</li><li>Share what you know</li><li>Enable the success of technical priorities</li></ul><p>At Airbnb, one of our <a href="https://careers.airbnb.com/">core values</a> is <em>Embrace the Adventure</em> which from a behavioral perspective, means being curious, asking for help, and demonstrating an ability to grow. Another core value is to <em>Be a Host</em>, which in the context of enabling our technical team’s best work, means not only sharing knowledge, but doing so sustainably. Relying on institutional knowledge of more tenured team members is not inclusive, accessible, or sustainable; whereas systematically encapsulating and disseminating the right knowledge can enable more positive outcomes. On TechED, we build educational programs that provide opportunities for our technical teams to embody these values while also reinforcing the direction set by our Airbnb Tech Priorities.</p><h3>How We Started</h3><p>Prior to 2017, technical education was driven by a few invested individuals working outside of their core responsibilities to ensure new hires were onboarded effectively. As an early start-up this approach worked, but it was not sustainable as Airbnb grew. Thus, the TechED team was formed. Much of the initial effort at the time focused on building onboarding programs. More recently, TechED has expanded its focus to develop a shared understanding of technical quality and best practices across our community and deliver them through a variety of programs which reinforce <a href="https://medium.com/airbnb-engineering/commitment-to-craft-e36d5a8efe2a">technical mastery and quality</a> throughout individual’s careers, regardless of tenure or role.</p><h3>Importance of Organizational Support</h3><p>The TechED team’s <a href="https://careers.airbnb.com/">core values</a> are closely tied to the mission of our company. We rely primarily on employees to <em>Be a Host</em> and share their technical knowledge through varying levels of commitment. We have team members contribute by developing technical curriculum — anything from codelabs to lectures. In cases where (<em>pre-covid)</em> an in-person lecture is preferred, we rely on SMEs to present the material. We also offer more informal means of sharing knowledge through serving as a “new hire buddy”, hosting a summer intern, or being the onboarding host for an entire cohort of new hires. This volunteer based strategy is only successful if people are motivated to participate. To incentivize participation, knowledge sharing is built into the tech career ladder competencies. Both ICs and managers are expected to share what they know, and help when they can through the opportunities offered. Participants are recognized for these efforts during the performance review cycle.</p><h3>Our Programs</h3><p>Knowledge must be shared in systematic and clearly defined ways. We do this though the following TechED programs:</p><ul><li><strong>Tech Bootcamp:</strong> an onboarding program ensuring all new hires successfully integrate into our global tech community and are prepared to approach their first code contributions</li><li><strong>Tech Manager Bootcamp:</strong> an onboarding program for managers designed to enable new tech managers to build an effective and healthy team</li><li><a href="https://medium.com/airbnb-engineering/how-airbnb-is-boosting-data-literacy-with-data-u-intensive-training-a6399dd741a2#:~:text=Data%20University%20is%20Airbnb%E2%80%99s%20dynamic%20data%20education%20program%2C,teach%20over%2020%20unique%20curriculums%20globally%20each%20year."><strong>Data University (DataU)</strong></a><strong>:</strong> a program to empower every Airbnb employee to make data-informed decisions</li><li><strong>Eng University (EngU):</strong> a continuing education program for engineers on areas of our tech priorities</li><li><strong>Food on Nerds:</strong> our internal tech talk series</li><li><a href="https://medium.com/airbnb-engineering/how-we-enable-airbnb-team-members-to-code-like-a-mobile-engineer-d7181a20399f"><strong>Code Like a Mobile Engineer</strong></a><strong>:</strong> a certification program designed to grow native engineering knowledge</li><li><a href="https://medium.com/airbnb-engineering/inside-connect-airbnbs-engineering-apprenticeship-program-c26d6eb2768c#:~:text=Inside%20Connect%3A%20Airbnb%E2%80%99s%20Engineering%20Apprenticeship%20Program%201%20About,The%20Program%20Structure.%20...%203%20Moving%20Forward.%20"><strong>Connect Program</strong></a><strong>:</strong> a six-month apprenticeship program for individuals from non-traditional backgrounds. If you’re curious, you can read about this program from both a <a href="https://medium.com/airbnb-engineering/inside-connect-supporting-apprentices-as-an-engineering-leader-the-third-of-a-three-part-blog-ef2e631b4899">manager perspective</a> and an <a href="https://medium.com/airbnb-engineering/inside-connect-an-apprentice-perspective-c9f299e11e51">apprentice perspective</a>.</li></ul><h3>Content Creation and Governance</h3><p>The TechED team, in partnership with SMEs, leverages the <a href="https://www.instructionaldesign.org/models/addie/">Addie Model</a>. This instructional systems design framework illustrates the flow through which all new training materials are built: analysis &gt; design &gt; development &gt; implementation &gt; evaluation. Our TechED Program Managers work closely with SMEs to embed sound learning methodology into each course during the early stages. This includes clearly stating and reinforcing learning objectives, promoting participant engagement with the material, and enforcing best practices for delivering content. Throughout design and development, TechED relies on curriculum advisory groups for each program to consult and course correct. Comprised of senior ICs and/or managers, these groups are responsible for sharing insights that influence our program roadmaps and amplifying opportunities for involvement across Airbnb’s technical teams.</p><p>While TechED programs benefit from the support of the organization and its incentive structure, we are accountable for supporting our organization in areas of need. One program that demonstrates how TechED responds to urgent organizational needs is the <a href="https://medium.com/airbnb-engineering/how-we-enable-airbnb-team-members-to-code-like-a-mobile-engineer-d7181a20399f"><strong>Code Like a Mobile Engineer</strong></a> program. In 2019, a substantial number of daily active hosts were using their mobile devices to visit Airbnb. As this continued to increase, so did the demand for new features. With only around 100 mobile engineers across our product teams, there was more work than we had engineers. To accelerate mobile development, we designed and launched Code Like a Mobile Engineer. This full-time, 12-day program utilizes our model of combining lectures, codelabs, buddy support, and a capstone project to quickly train mobile engineers. Since this program’s inception, we have seen 360+ merged PRs to our mobile codebase from 30 participants and have had one engineer move into a full-time native engineering role.</p><h3>Building Flexible and High Impact Onboarding Programs</h3><p>The COVID-19 pandemic created enormous challenges and opportunities for all learning organizations. For the TechED team, one of the more urgent shifts was pivoting our in-person, 2.5-week <strong>Tech Bootcamp</strong> onboarding program to be consumed virtually. While meeting the virtual needs of our new hires, we also took the opportunity to incorporate prior program feedback implementing a hybrid of both synchronous learning (lectures) and asynchronous learning (past recordings, codelabs, etc.).</p><p>In early 2021, TechED expanded the program from two general tracks (Engineering and Data Science) to five function-specific tracks (Backend, Frontend, Native, Data Engineering, and Data Science). With the help of SMEs from these critical functions, TechED developed flows for each track that equip new hires with highly relevant training. Through the ongoing retrospectives, we found that new hires appreciated the balance and autonomy that comes with consuming both live lectures and recordings.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/969/0*PId0F1paics4Yxt9" /></figure><p>The TechEd team also supports onboarding people new to a management role with our Tech Manager Bootcamp. In partnership with our HR and Central Learning teams we offer a holistic training journey over the course of a tech manager’s tenure. The <strong>Tech Manager Bootcamp</strong> program is offered quarterly, and the goal is to onboard new tech managers to the fundamentals of effective team and people development at Airbnb. It is offered alongside complementary programs developed by our cross-functional partners. The success of these complementary programs is gauged through shared objectives and key results.</p><h3>Continuing Education</h3><p>The TechED team strives to enable Engineers and Data Scientists to continuously grow in their careers, regardless of tenure or role. To this effect, the TechED team has several offerings.</p><p>For frequent, informational knowledge exchanges, we host a one-hour, bi-weekly webinar called <strong>Food on Nerds (FON)</strong>. Started in 2015 as a grassroots lunch-hour tech talk with pizza and snacks, Food on Nerds is now the primary way for technical teams to broadly share their work with their peers. FON offers all engineers and data scientists the opportunity to amplify their work within our internal tech community, build their personal brand at Airbnb, and, in some cases, test drive their presentation for an external audience. Talks are recorded and available at any time through our internal AirTV channel.</p><p>These Food on Nerds tech talks fuel our ongoing <strong>EngU</strong> program. <strong>EngU</strong>, our more formal continuing education program for engineers, is a catalog of courses available to engineers to further their technical growth. This is one of the main levers through which TechED is able to disseminate critical training on tech priorities. These sessions are hosted live on a regular basis, with recordings available to employees on demand.</p><p>Lastly, unlike TechED’s other programs, which are built specifically for a technical audience, <a href="https://medium.com/airbnb-engineering/how-airbnb-democratizes-data-science-with-data-university-3eccc71e073a"><strong>DataU</strong></a> is an educational program available to all Airbnb employees. We have intro level courses designed to empower every employee to make data-informed decisions. The advanced courses are tailored to more experienced users in modeling and experimentation. The continued learning doesn’t stop there. We also offer access to <strong>O’Reilly Safari Online</strong> and <strong>LinkedIn Learning</strong> to augment any additional topics of interest for our tech community.</p><h3>Measuring Our Impact</h3><p>Our goal is to ensure essential information moves quickly and efficiently into the heads of those who need it. We maintain a dashboard to measure both engagement with our programs from participants as well as contributions from SMEs. These reports are used by both managers and ICs to inform performance reviews. We share monthly, team-wide impact reports with tech leaders, as well as more granular impact reports with stakeholders for each individual course. Agility is more important than polished presentations, however. It’s most important to ensure our tech community has the information and knowledge needed to do their job.</p><h3>Conclusion</h3><p>In May of 2020, Airbnb felt the turbulence of the pandemic first hand. As a response to this, we <a href="https://www.forbes.com/sites/deniselyohn/2020/11/10/how-airbnb-survived-the-pandemic--and-how-you-can-too/?sh=2e7614b49384">refocused our roadmap on the core business of home rentals</a>. While we have been pleasantly surprised by the rebound of our business in the later months of the pandemic, we remember the challenges that came with losing a significant portion of our workforce. People are our biggest asset at Airbnb, and on TechED, we strive to keep people growing and learning. Since the onset of the pandemic, over 50% of our tech community has engaged with one or more TechED offerings, and with strong organizational support and core values that prioritize community participation, we remain excited to continue bringing unique and engaging learning experiences to the Airbnb tech community.</p><h3>Acknowledgements</h3><p>The Airbnb TechED team depends on the knowledge and expertise of our technical community. We would like to thank all who have contributed to our programs, dedicated time to being a buddy, developed new courses, and delivered meaningful content. We would like to express our gratitude for those past employees who worked with Airbnb TechED and paved the way for our success.</p><p><em>— —</em></p><p><em>This work, and many other exciting initiatives, are always happening at Airbnb. If you want to join us, check out our </em><a href="https://careers.airbnb.com/"><em>career page</em></a><em>.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=854be0f9fe9d" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/how-airbnb-tech-fosters-a-culture-of-learning-854be0f9fe9d">How Airbnb Tech Fosters a Culture of Learning</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Airflow Smart Sensor Service]]></title>
            <link>https://medium.com/airbnb-engineering/the-airflow-smart-sensor-service-221f96227bcb?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/221f96227bcb</guid>
            <category><![CDATA[data]]></category>
            <category><![CDATA[data-engineering]]></category>
            <category><![CDATA[data-quality]]></category>
            <category><![CDATA[engineering]]></category>
            <dc:creator><![CDATA[Yingbo Wang]]></dc:creator>
            <pubDate>Tue, 28 Sep 2021 17:24:05 GMT</pubDate>
            <atom:updated>2021-09-28T18:29:09.737Z</atom:updated>
            <content:encoded><![CDATA[<p>Consolidating long-running, lightweight tasks for improved resource utilization</p><p><strong>By:</strong> <a href="https://www.linkedin.com/in/yingbo-wang-86aa3027/">Yingbo Wang</a>, <a href="https://www.linkedin.com/in/ruiqinyang/">Kevin Yang</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*3r30u7rnBhR7BJSc" /></figure><h3>Introduction</h3><p>Airflow is a platform to programmatically author, schedule, and monitor data pipelines. A typical Airflow cluster supports thousands of workflows, called DAGs (directed acyclic graphs), and there could be tens of thousands of concurrently running tasks at peak hours. Back in 2018, Airbnb’s Airflow cluster had several thousand DAGs and more than 30 thousand tasks running at the same time. This amount of workload would often result in Airflow’s database being overloaded. It also made the cluster quite expensive since it required a lot of resources to support those concurrent tasks.</p><p>In order to make the system more stable, and to reduce the cost of the cluster, we looked to optimize the Airflow system. We soon found that the long-running lightweight (LRLW) tasks waste a lot of resources, so we proposed a Smart Sensor to consolidate them and address the waste.</p><h3>Long-Running Lightweight Tasks</h3><p>When we investigated the Airflow performance issues, we found that a few kinds of tasks shared the same LRLW patterns. They are the sensor tasks, the subDAGs, and the SparkSubmitOperator.</p><p><strong>Sensors</strong>, or sensor tasks, are a special kind of operator that will keep running until a certain criterion is met. The criterion can be a file landing in HDFS or S3, a partition appearing in Hive, whether some other external task succeeded, or even if it is a specific time of the day.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*HPMY9cRlDg7_Y7zj" /><figcaption><strong>Figure 1. The lifespan of a sensor task</strong></figcaption></figure><p>When a sensor task is running, it calls its “poke” function to check the criterion periodically, usually every 3 minutes, and marks the sensor tasks with ‘success’ if their “poke” functions return true or ‘fail’ if sensor timeout. The execution of a “poke” is very fast, mostly less than 100ms, so most of the time sensors are idle, waiting for the next “poke” time to come. The lifespan of a sensor task is from the checking time to the time when the condition is met, which can range from a few minutes to several days.</p><p><strong>SubDAGs</strong> are another example of long-running lightweight tasks. They are used to encapsulate a set of tasks in a DAG and make a complicated DAG’s structure cleaner and more readable. The DAG run is created for a subDAG in the pre_execute function and then subDAG task “poke” the DAG run status in the execute function.</p><p>The <strong>SparkSubmitOperator</strong> is also an example of a long-running lightweight task. The Spark client in Airflow submits the job and polls until completion. All these tasks, after some initialization work, fall into a lightweight and, at times, a long-running status.</p><p>From the previous examples, we can see that these tasks fall into the same “long-running, lightweight” pattern, characterized by the following:</p><ul><li><strong>The resource utilization is very low.</strong> Worker processes for these tasks remain idle 99% of the time.</li><li><strong>These tasks often account for a very large portion of the concurrent running tasks in a large scale cluster.</strong> At Airbnb, more than 70% of running tasks are sensors. At peak hour, they take more than 20Kworker slots.</li><li><strong>There are a lot of duplicate sensor tasks.</strong> More than 40% of sensor jobs are duplicates because many downstream DAGs usually wait for the same partitions from just a few important upstream DAGs.</li></ul><h3>Smart Sensor</h3><p>We proposed the Smart Sensor to consolidate these LRLW tasks. Though originally created to consolidate long-running sensor tasks, it was later expanded to consolidate all LRLW tasks. We kept the name Smart Sensor for this service.</p><h3>How It Works</h3><p>The main idea of the Smart Sensor service is to use centralized processes to execute long-running tasks in batches, instead of using one process for each task.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*H6QTUtYBpgbn2ijm" /><figcaption><strong>Figure 2. Sensors before and after enabling smart sensor</strong></figcaption></figure><p>With the Smart Sensor service, a sensor task is executed in two steps:</p><ol><li>First, each task parses the DAG, gets the task object, runs the pre_execute function, and then registers itself to the Smart Sensor service. In the registration, it persists information required to poll external resources to the Airflow metaDB. After registration succeeds, the task exits and frees up the worker slots.</li><li>Then, a few centralized processes (the Smart Sensor tasks from a built-in DAG) keep checking the database for the latest records of all registered tasks and execute the “poke” function for these tasks in batches. Normally, one Smart Sensor task is able to handle several hundred sensor tasks easily. The Smart Sensor can also combine duplicate sensor tasks into a single instance to save even more resources.</li></ol><p><strong>The Smart Sensor deduplicates tasks and balances workloads by defining the sensor task shards.</strong> The number of concurrently running sensors could be large and there will be multiple Smart Sensor tasks to execute all these jobs in a short period. How to assign sensor tasks to Smart Sensors was one of our key challenges when designing this system. We sought to balance the workload of all Smart Sensor tasks. At the same time, the `duplicated` sensor tasks have to be assigned to the same Smart Sensor so that we can avoid multiple pokes for the same target.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*fM_bvm_cykKVz7qd" /><figcaption><strong>Figure 3. Deduplicating tasks by shardcode</strong></figcaption></figure><p>In the Smart Sensor service, the `poke_context` is the signature of a sensor job. It is a dictionary of arguments needed to execute the sensor’s poke function. Two sensors with the same operator class and same `poke_context` are running the same `poke` function and are considered duplicated tasks. By using the hashcode of `poke_context` to do the sharding and make each Smart Sensor task take care of tasks whose hashcode is in a specific range, it should be able to assign `duplicated` sensors to the same smart sensor. Since hashcodes are long, we optimized by using the mod of the hashcode, which can be indexed in the database. We refer to this key as the `shardcode`.</p><p>Figure 3 shows how the sharding works in the Smart Sensor service. Sensor1 and sensor2 have the same `poke_context` and so they have the same `hashcode` and `shardcode`. At runtime, they will be picked up by the same Smart Sensor — e.g., `SmartSensor1`. All duplicated sensors will be poked only once in one poking loop.</p><p><strong>Smart Sensor is a general service for all sensor classes.</strong> The centralized Smart Sensor task is a general framework. It is designed to support various classes. As long as the class has a poke function and the argument for this poke function can be serialized, the Smart Sensor tasks can support them.</p><p><strong>Logs are handled similarly to unconsolidated processes.</strong> Although task execution is consolidated into fewer processes, the Smart Sensor service supports the same ability to read or download logs from the Airflow UI. Users can read logs from the original sensor task’s URL.</p><p><strong>Smart Sensor can be easily applied to an Airflow cluster.</strong> Enabling and disabling the Smart Sensor service is simple, we only need to do a system level configuration change on the `smart_sensor` session in airflow.cfg. The change is transparent to the individual users and there is no need to change existing DAGs. Also, rotating centralized smart sensor tasks will not cause any user’s sensor task to fail.</p><h3>The Efficiency Improvement</h3><p>Upon deploying the first version of Smart Sensor, Airbnb was able to reduce the number of peak-hour, concurrently running tasks by more than 60%. We also reduced the running sensor tasks by 80%. The process slots needed for sensors were reduced from 20,000 to 80. The database load is also greatly reduced due to much fewer running tasks.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*lkiBWjq8_ezvYC-e" /><figcaption><strong>Figure 4. Number of running tasks after Smart Sensor deployed</strong></figcaption></figure><p>In Smart Sensor, the deduplicate mechanism reduced about 40% of requests to the Hive metastore and hence reduced both the absolute sensor traffic and the load on the underlying data warehouse.</p><h3>Conclusion</h3><p>Smart Sensor is a service which consolidates small, lightweight task traffic into bigger centralized tasks. It can reduce Airflow’s infrastructure cost and improve cluster stability. This is especially true for large clusters with a considerable amount of sensor tasks. For Airbnb’s gigantic Airflow clusters, Smart Sensor reduced a significant amount of cost and greatly improved the overall cluster stability.</p><p>The smart sensor service was released as one of the majority new features in <a href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/smart-sensors.html">Apache Airflow 2.0</a>, since which it has been used to improve the resource utilization for more airflow users. Because the smart sensor service introduced the idea of splitting task lifespan into multiple processes and unlocked the `async` mode for task execution, the open source community has started to invest in more generic use cases for `async` solutions, among which the <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=177050929">deferrable (“Async”) operator</a> is an operator aiming to extend the async mode to more tasks.</p><h3>****************</h3><p><em>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=221f96227bcb" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/the-airflow-smart-sensor-service-221f96227bcb">The Airflow Smart Sensor Service</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[My Journey to Airbnb — Rachel Zhao]]></title>
            <link>https://medium.com/airbnb-engineering/my-journey-to-airbnb-rachel-zhao-3302e70c5a54?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/3302e70c5a54</guid>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[search]]></category>
            <category><![CDATA[hiring]]></category>
            <dc:creator><![CDATA[AirbnbEng]]></dc:creator>
            <pubDate>Mon, 27 Sep 2021 22:49:28 GMT</pubDate>
            <atom:updated>2021-09-23T20:45:51.761Z</atom:updated>
            <content:encoded><![CDATA[<h3>My Journey to Airbnb — Rachel Zhao</h3><p>From an uncertain software engineering student to Head of Search Engineering.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*D5ycTIwTPF9Oo6Onbgrc9w.jpeg" /></figure><p><em>If there’s one thing travel teaches us, it’s that the journey is just as important as the destination. With this in mind, we’re launching a new series of blog posts to bring you the personal stories of our amazing Airfam! How did they initially connect with their passion, what brought them to Airbnb, and what’s fueling them every day?</em></p><p><em>We could think of no one better to kick off this series than </em><a href="https://www.linkedin.com/in/rachelzhao/"><em>Rachel Zhao,</em></a><em> the head of engineering for our Search product group, which contributed to the set of </em><a href="https://news.airbnb.com/2021-release/"><em>incredible features</em></a><em> this year to respond to the changing world of travel. In addition to major initiatives in search and mobile, Rachel’s team is expanding to our new Atlanta hub, which goes hand-in-hand with her personal passion to improve representation in tech. As an immigrant and a woman, Rachel knows the importance of community building and how hard and intimidating it can be to find your place in an engineering career path. Read on for Rachel’s own words on seeing code as a way to communicate, working at the crossroads of UX and data, the tech talent in Atlanta, and more.</em></p><h3>From Beijing to Waterloo</h3><p>I grew up in Beijing and then went to Canada to study engineering at the University of Waterloo. It felt like my classmates all knew that they wanted to do computer science from a very early age. On the other hand, I was a complete newbie. Growing up, I’d been more interested in the arts and communication media professions. But my family decided to immigrate to Canada, and as I knew very little English, I needed to find a major that was more practical for me. It was very random — I just Googled for the top schools and programs in Canada. And that’s how I got into software engineering.</p><p>It was really stressful because it seemed like everyone knew how to program already. I struggled a lot in the first years and felt so behind compared to everyone in the class (learning English and Java at the same time was rough!). But I quickly realized that everyone has strengths and weaknesses. While I was weaker in computer science, I was stronger in other subjects. I could offer help on calculus and physics thanks to my advanced high school curriculum, and in return they would share their programming experience. I was lucky that I had classmates who supported each other, and that got me through the years of uncertainty.</p><h3>Finding my niche in software engineering</h3><p>As a visual person, the typical perception of programming (dark screen with green text, “Matrix”-style) was daunting to me. However, things changed when I took an introduction to user interface class. It made me realize that a big part of software engineering is to create a way to communicate effectively. I could bring my interest in art and media into my career path as an engineer by working on user experience.</p><p>Through many internships during the undergrad years, I also learned that when writing code, making it functional is not the only goal — we’re writing for other developers, current and future, who share the same codebase. They need to understand what you’re trying to achieve and your code needs to be maintainable. It’s not just about the algorithms, but also about organization and communication. And those skills you have as a person also apply to engineering.</p><h3>Discovering my place and my people at Airbnb</h3><p>Throughout my career, I’ve found that I’m motivated to solve user problems: working with research to understand the needs, and prioritizing work that brings value to customers. Therefore the opportunity to come to Airbnb and lead the search group was very exciting to me. Teams in this org are responsible for a crucial path of a guest’s journey: helping people discover and onboard to Airbnb (SEO), showcasing what Airbnb has to offer (Storefronts), capturing what guests are looking for (Search Input) and finding the best matches for them (Search Feed).</p><p>The space we work on is both a product surface and a platform. It’s also the crossroad of user experience and data. As a result, we get to work on many different types of projects, from new user facing features, systems that power product pages, platforms that enhance developer productivity, to work that enhances product experience such as performance improvements… The possibilities are endless.</p><p>Not only is this area a great fit for my passions, but Airbnb is a product that I’ve admired for a long time (ever since discovering the platform as a host back in 2012, when I literally had guests staying on an air mattress in my flat in San Francisco!). One thing I love about Airbnb as a product is that it’s really good at storytelling. You land on the homepage and you see there’s a narrative here, rather than a lot of components.</p><p><strong>“I think that how you deal with a crisis — how you deal with the lows of a company — shows more character of the company than the highs, when everything is going smoothly.”</strong></p><p>What really confirmed my desire to join was seeing how Airbnb handled the challenges of 2020. While seeing layoffs happening all over the tech industry during the pandemic, I was impressed by Airbnb’s response. The communication was very clear from leadership, and the company was generous and considerate in helping people find and land their next job and get through this period financially. There was also <a href="https://news.airbnb.com/a-message-from-co-founder-and-ceo-brian-chesky/">a widely-shared blog post by Brian</a> which I felt set the bar for how to communicate with empathy and compassion while making a difficult decision.</p><p>I think that how you deal with a crisis — how you deal with the lows of a company — shows more character of the company than the highs, when everything is going smoothly. I felt like how Airbnb handled things was a really good sign of the company’s culture and the leadership. And that’s what ultimately inspired me to join the team.</p><h3>Expanding our team in Atlanta</h3><p>I put a lot of value on community building, inclusive communication, and representation. When there’s a lack of diversity at the table, we don’t get to hear different perspectives, and those perspectives are not considered in decision making. That could lead to biased technical decisions, or a product direction with many blindspots.</p><p>That’s why I’m so excited about the team we’re starting in Atlanta. It’s a very important tech hub. Atlanta has great schools and great talent. And the office there will help us operate in a way that’s less Silicon Valley-centric. I think it’s very important to bring different ways of thinking into the company and strengthen the culture instead of simply fitting in the culture.</p><p>I’m also feeling confident that we’ve built up the “muscle” of working remotely and learned how to make everyone feel supported over that past year and half. We’re making sure to integrate new engineers in Atlanta with our existing teams first, so they can learn how Airbnb works, what our tech stack is like, and so on — we’re being very careful about how we equip everyone with that domain knowledge so they’re set up for success.</p><p>At Airbnb, we have a healthy engineering culture of collaboration and knowledge sharing. People are willing to help each other out. We’re here to build products with a mission that everyone can belong anywhere, and there are so many ways to contribute to a team where everyone is sharing their strengths.</p><p>Our team is dedicated to perfecting our new features that help travelers to embrace more flexibility in <a href="https://techcrunch.com/2021/05/24/airbnb-doubles-down-on-flexible-search-improves-the-host-flow-in-preparation-for-summer-2021/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAACTqKJxxNCEClv9r2IB9uYeSHOeH_XMduLIman-CPW8aQtcgupj8ioXo2ZeXXaCEjW2uzTG-JF2fPuRuyLWz5IDZZd4QpXpS-DLrlMyDgtCc2H6mm7raLLBhTRI3Mpo3Dj8MfPSGqeETUld2Cc9JIKIl6I8PF8yGenT4ocEWbhaB">date</a> and <a href="https://news.airbnb.com/unique-stays-hosts-earn-more-than-300-million-since-start-of-pandemic/">destination</a>, as well as improving core functionalities all over the onboarding and search flow. On the platform side, we continue to invest in mobile, to scale and evolve our tech stack and set a new standard for app development. We’re hiring in Atlanta, the Bay Area, and a number of other locations and we’d love to hear from you!</p><p>Check out these related roles:</p><ul><li><a href="https://careers.airbnb.com/positions/2607507/">Senior iOS Engineer, Guest Experience</a></li><li><a href="https://careers.airbnb.com/positions/2756046/">Senior Android Software Engineer, Guest Experience</a></li><li><a href="https://careers.airbnb.com/positions/3178314/">Senior Software Engineer, Guest Experience</a></li><li><a href="https://careers.airbnb.com/positions/3206883/">Staff Fullstack Engineer, Guest Experience</a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=3302e70c5a54" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/my-journey-to-airbnb-rachel-zhao-3302e70c5a54">My Journey to Airbnb — Rachel Zhao</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How Airbnb Enables Consistent Data Consumption at Scale]]></title>
            <link>https://medium.com/airbnb-engineering/how-airbnb-enables-consistent-data-consumption-at-scale-1c0b6a8b9206?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/1c0b6a8b9206</guid>
            <category><![CDATA[analytics]]></category>
            <category><![CDATA[metrics]]></category>
            <category><![CDATA[data]]></category>
            <dc:creator><![CDATA[Shao Xie]]></dc:creator>
            <pubDate>Tue, 21 Sep 2021 17:00:25 GMT</pubDate>
            <atom:updated>2021-09-21T17:00:25.435Z</atom:updated>
            <content:encoded><![CDATA[<h4>Part-III: Building a coherent consumption experience</h4><p><strong>By: </strong><a href="https://www.linkedin.com/in/apahwa/">Amit Pahwa</a>, <a href="https://www.linkedin.com/in/cristianrfr/">Cristian Figueroa</a>, <a href="https://www.linkedin.com/in/donghan-zhang-670990135/">Donghan Zhang</a>, <a href="https://www.linkedin.com/in/haimgrosman/">Haim Grosman</a>, <a href="https://www.linkedin.com/in/john-bodley-a13327133/">John Bodley</a>, <a href="https://www.linkedin.com/in/jonathan-parks-15617820/">Jonathan Parks</a>, <a href="https://www.linkedin.com/in/jialingliu1020/">Jenny Liu</a>, <a href="https://www.linkedin.com/in/krishna-bhupatiraju-1ba1a524/">Krishna Bhupatiraju</a>, <a href="https://www.linkedin.com/in/shengnan-zhu-89403124/">Maggie Zhu</a>, <a href="https://www.linkedin.com/in/michaelcl/">Mike Lin</a>, <a href="https://www.linkedin.com/in/philip-weiss-391021b1/">Philip Weiss</a>, <a href="https://www.linkedin.com/in/robert-ih-chang/">Robert Chang</a>, <a href="https://www.linkedin.com/in/shao-xie-0b84b64/">Shao Xie</a>, <a href="https://www.linkedin.com/in/sylviatomiyama/">Sylvia Tomiyama</a>, <a href="https://www.linkedin.com/in/toby-mao/">Toby Mao</a>, <a href="https://www.linkedin.com/in/xiaohui-sun-24bb3017/">Xiaohui Sun</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*4n3siF32QWxo31_6okaE9g.jpeg" /></figure><h3>Introduction</h3><p>In the <a href="https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70">first post</a> of this series, we highlighted the role Minerva plays in transforming how Analytics works at Airbnb. In the <a href="https://medium.com/airbnb-engineering/airbnb-metric-computation-with-minerva-part-2-9afe6695b486">second post</a>, we dove into Minerva’s core compute infrastructure and explained how we enforce data consistency across datasets and teams. In this third and final post, we will focus our story on how Minerva drastically simplifies and improves the data consumption experience for our users. Specifically, we will showcase how a unified metric layer, which we call the Minerva API, helps us build versatile data consumption experiences tailored to users with a wide range of backgrounds and varying levels of data expertise.</p><h3>A Metric-Centric Approach</h3><p>When data consumers use data to frame a business question, they typically think in terms of metrics and dimensions. For example, a business leader may wonder what percentage of bookings (a metric) is made up of long-term stays (a dimension). To answer this question, she needs to find the right set of tables from which to query (where), apply the necessary joins or filters (how), and then finally aggregate the events (how) to arrive at an answer that is, hopefully, correct.</p><p>While many traditional BI tools attempt to abstract this work on behalf of their users, most of their data-serving logic still relies heavily on the users to figure out the “where” and the “how”. At Airbnb, we aspired to build a better user experience — one in which users simply ask for metrics and dimension cuts, and receive the answers without having to worry about the “where” or the “how”. This vision, what we call a “metric-centric approach”, turned out to be a difficult engineering challenge.</p><h4>Challenge One: The “Where”</h4><p>In most traditional data warehouses, data is organized in tables. This means that to answer an inquiry, a BI tool needs to associate the metrics and dimensions in question to the physical tables that contain the relevant answers. However, for a given metric and dimension combination, there might be many datasets from which to source the answers. These tables often have varying degrees of data quality and correctness guarantees, so picking the right tables to serve the data is nontrivial.</p><h4>Challenge Two: The “How”</h4><p>Moving beyond the “where”, the data-serving logic responsible for the “how” also has many nuances. To start, there are different metric types: <em>simple metrics</em> are composed of single materialized events (e.g., bookings); <em>filtered metrics</em> are composed of simple metrics filtered on a dimension value (e.g., bookings in China); and <em>derived metrics</em> are composed of one or more non-derived metrics (e.g. search-to-book rate). Furthermore, while many metrics are additive (e.g., bookings), many other metrics are not: count distincts, percentiles, and point-in-time snapshots cannot simply be calculated by summing individual events. Consistently calculating these various metric types correctly, across all scenarios, is a big challenge.</p><h4>Challenge Three: Integration With Downstream Applications</h4><p>Finally, to make data-informed decisions, data must be used in a wide variety of contexts, applications, and tools. The more prevalent and important the metric is, the more likely it is to be used in a wide variety of settings. For example, gross booking value (GBV), nights booked, and revenue are among the most frequently used metrics at Airbnb. They are used to track business performance, calculate guardrail metrics for randomized controlled experiments, and leveraged as features for machine learning models. Serving these metrics in different use cases, while providing contextual information for users to use them the right way is yet another core challenge for us.</p><h4>Our Solution</h4><p>We have addressed these challenges by building the Minerva API, a metric-serving layer that acts as an interface between upstream data models and downstream applications. With Minerva API, any downstream application is able to serve data consistently and correctly without knowing where the data is stored or how metrics should be computed. In essence, the Minerva API serves as the “how” by connecting the “what” with the “where”.</p><h3>Minerva API</h3><p>The Minerva API consists of the API web server, a metadata fetcher application, and several clients that integrate with <a href="https://superset.apache.org/">Apache Superset</a>, <a href="https://www.tableau.com/">Tableau</a>, <a href="https://www.python.org/">Python</a>, and <a href="https://www.r-project.org/">R</a>. These components serve native NoSQL and SQL metric queries to the downstream applications.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*FUP1m7DFm8B6XmaF" /><figcaption>Minerva API serves as the interface between the consumers and the underlying datasets</figcaption></figure><h4>Metadata Fetcher: Abstracting the “Where”</h4><p>We mentioned previously that users simply ask Minerva for metrics and dimension cuts without having to figure out the “where”. When a data request is issued, Minerva spends a great deal of effort figuring out which of its datasets should be used to honor that request.</p><p>Under the hood, Minerva takes into account several factors before picking an optimal data source — one of the most important factors being data completeness. This means that any data source chosen to serve the query should contain all the columns needed for a given user’s query request and must cover the time range required from the query request.</p><p>To accomplish this, we built a service called Metadata Fetcher that periodically fetches data source metadata and caches it in a MySQL database every 15 minutes. Specifically, we periodically fetch the latest copy of the Minerva configuration (stored in Thrift binary) from S3 to get the list of every valid Minerva data source in Druid. For each data source, we query the Druid broker to get its name and a list of associated metrics and dimensions. Furthermore, we can also get the min date, max date, and count of distinct dates from the broker to figure out if there is any missing data. Every time new information is fetched, we update the MySQL database to maintain the source of truth. With this metadata fetcher, we are able to serve the data request using the best data source at any given time.</p><h4>Data API: Abstracting the “How”</h4><p>Imagine a scenario in which a user is interested in knowing the trend of average daily price (ADR), cut by destination region, excluding private rooms for the past 4 weeks in the month of August 2021. The full spec of the example query might look like the following:</p><pre>{</pre><pre>      metric: ‘price_per_night’,</pre><pre>      groupby_dimension: ‘destination_region’,</pre><pre>      global_filter: ‘dim_room_type!=”private-room”’,</pre><pre>      aggregation_granularity: ‘W-SAT’,</pre><pre>      start_date: ‘2021–08–01’,</pre><pre>      end_date: ‘2021–09–01’,</pre><pre>      truncate_incomplete_leading_data: ‘true’,</pre><pre>      truncate_incomplete_trailing_data: ‘true’,</pre><pre>}</pre><p>When Minerva receives such a request, it needs not only to figure out where to fetch the data, but also how to filter, combine, and aggregate the data to create the final result. It employs a strategy for achieving this via the <a href="https://www.jstatsoft.org/article/view/v040i01">Split-Apply-Combine paradigm</a>, commonly used in data analysis.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ZBoswC0q8u0DvM82" /><figcaption>Split-Apply-Combine in action for `price_per_night` metric</figcaption></figure><h4>Step 1: Split the Request into Atomic Metric Requests</h4><p>When Minerva API receives a query request such as the one above, the first thing it does is to break up any derived metrics into what we call a Minerva “atomic” metric by creating a set of associated subqueries. If a user query only specifies an atomic Minerva metric, then this first step is essentially a no-op.</p><p>In the example above, given that the `price_per_night` metric is a ratio metric (a special case of derived metric) that contains a numerator (`gross_booking_value_stays`) and a denominator (`nights_booked`), Minerva API breaks up this request into two sub-requests.</p><h4>Step 2: Apply and Execute Each Subquery</h4><p>With the atomic metrics identified from step 1, Minerva leverages metric configurations stored in S3 to extrapolate the associated metric expressions and metadata in order to generate the subqueries. Let’s stick with the same example: Minerva data API looks up the metric definition of `gross_booking_value_stays` and sees that it is a SUM aggregation, and similarly for the `nights_booked` metric. In both requests, a global filter ‘dim_room_type!=”private-room”’ is applied to ensure that private rooms are excluded from the calculation.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*utscy1Byao92TR23" /><figcaption>The split-apply-combine paradigm in action for the ADR metric</figcaption></figure><p>Once the associated subqueries are generated for each atomic metric, Minerva API finally sends the queries over to Druid or Presto. It chops up the query into several “slices” that span a smaller time range and then combines the results into a single dataframe if resource limitation is reached. The API also truncates any incomplete leading or trailing data before rolling up the dataframe based on the aggregation granularity.</p><h4>Step 3: Combine Atomic Metric Results Into a Single Dataframe</h4><p>Once Minerva rolls up the dataframes for each atomic metric, it then combines them into a single dataframe by joining the dataframes on the timestamp column. As a final step, Minerva API performs any necessary post-aggregation calculations, applies ordering, and limits before returning the final result to the client in serialized JSON format.</p><p>To recapitulate, with Minerva’s data source API and data API, we are able to abstract away the process of identifying “where” to fetch the data and “how” to return the data. This API serves as the single layer of abstraction for Minerva to honor any request coming from downstream applications. However, our story does not simply end here: many of our engineering challenges involve how to integrate different applications with this API. We will explore these challenges in the next section.</p><h3>The Data Consumption Experience</h3><p>Bearing in mind the diverse set of data consumers within Airbnb, we set out to build tools tailored to different personas and use cases. With the Minerva API, we built a wide range of user interfaces that provide a consistent and coherent data consumption experience. As we mentioned briefly in the first <a href="https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70">post</a>, there are four major integration endpoints, each supporting a different set of tools and audience:</p><ul><li><strong>Data Analysis: </strong>Integration with Python and R, used mostly for advanced data analytics</li><li><strong>Data Exploration: </strong>Integration with BI tools such as Superset, <a href="https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278bd#c576">Metric Explorer</a>, and Tableau, tailored for data-savvy analysts who drive insights</li><li><strong>Reporting: </strong>Integration with<strong> </strong><a href="https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70#efb9">XRF</a> (eXecutive Reporting Framework), tailored for an executive audience who wish to know the current state of the business</li><li><strong>Experimentation: </strong>Integration with<strong> </strong><a href="https://medium.com/airbnb-engineering/https-medium-com-jonathan-parks-scaling-erf-23fd17c91166">ERF</a> (Experimentation Reporting Framework), tailored for any data scientists, engineers, or product managers who run A/B tests at Airbnb</li></ul><p>When building out these features, we were constantly trading off between consistency, flexibility, and accessibility. For example, Metric Explorer is built mostly for non-technical users who are not data experts. This means that it needs to optimize consistency and accessibility over flexibility. Metric Explorer enforces strict guardrails that prevent users from doing the wrong thing, and there is very little opportunity to go off the “paved path”.</p><p>At the other extreme, the R and Python clients that are typically favored by data scientists are much more flexible. Users have full controls on how to leverage the clients’ API to perform custom analysis or visualization. In the next few sections, we will explain how some of these consumption experiences are created behind the scenes.</p><h4>Integration with Metric Explorer</h4><p>Metric Explorer was created at Airbnb so anyone, regardless of their level of data expertise, can leverage data to make informed decisions. Because of its broad target audience, Metric Explorer optimizes accessibility and data consistency over flexibility.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*OknXUhNkPk0DtU8P" /><figcaption>The Metric Explorer is great for a non-technical audience who wants to answer high-level business questions</figcaption></figure><p>Under the hood, all of Metric Explorer’s metrics, dimensions, and relevant metadata are sourced from Minerva’s metric repository and ingested into <a href="https://www.elastic.co/elasticsearch/">Elasticsearch</a>. These metadata are conveniently presented on the right sidebar as contexts before users perform any operations on the data.</p><p>When a user chooses to perform data operations such as Group By and Filter, Metrics Explorer presents dimensions in ranked order so that users with little or no business context can easily drill down, without needing to know the dimension values ahead of time — as illustrated above.</p><p>As users slice and dice the data, the Minerva API automatically determines which combination is valid and only surfaces cuts that exist. Nowhere in the experience does a user need to know anything about the underlying physical table from which the metric in question is sourced.</p><h4>Integration with Apache Superset</h4><p>While Metrics Explorer provides high-level information about metrics, more adventurous users who wish to slice and dice the data more can do so in Superset. <a href="https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278bd">Apache Superset</a> is a homegrown tool at the core of Airbnb’s self-serve BI solutions. Given the ubiquity of Superset inside the company, we knew that we needed to provide a functional SQL-like integration with Superset in order for Minerva to be widely adopted.</p><p>While many applications can be built on top of the Minerva API by talking to its RESTful endpoints directly, the client interfaces for BI tools such as Apache Superset and Tableau are more complex. Commonly, these BI tools speak SQL (via a client), not HTTP requests. This meant that Minerva API needed to support a SQL-like interface that adheres to the <a href="https://en.wikipedia.org/wiki/Online_analytical_processing">OLAP</a> type query structure. To build such an interface, we added to Minerva API a SQL parser — leveraging <a href="https://pypi.org/project/sqlparse/v">sqlparse</a> — to parse the SQL statement into an AST which is then validated and transformed into native HTTP requests.</p><p>Adhering to the DRY principle, we leveraged <a href="https://calcite.apache.org/avatica/">Apache Calcite Avatica</a>, which defines a generic database wire API between a client and server. The Minerva API serves as the Avatica HTTP server and the client is either a custom <a href="https://www.python.org/dev/peps/pep-0249/">Python Database API</a> database driver with <a href="https://www.sqlalchemy.org/">SQLAlchemy</a> dialect (Superset) or Avatica provided JDBC connector (Tableau).</p><p>Unlike traditional BI tools for which custom business logic is implemented in the tools themselves, Minerva consolidates and obfuscates all this logic via pseudo SQL-like AGG metric expressions. In the table below, we compare and contrast the queries run in a traditional BI tool to those run in Superset:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*HK1IgDif4Uz5Qmm8LLiFPA.png" /></figure><p>In the query on the left, a user need not specify where the metric should be computed from, nor do they need to specify the correct aggregation function — these details are abstracted away by Minerva.</p><p>Finally, given that there are 12,000 metrics and 5,000 dimensions in Minerva, not all metric-dimension combinations are valid. For example, active listing can be cut by where the host is located, but not by where the guest is from (i.e. this guest attribute could be different for each booking reservation). We added event listeners to the chart controls to make sure that only eligible metric and dimension combinations are surfaced in the left pane. This design helps to reduce cognitive load and to simplify the data exploration process.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*CqG4C2B6ND0XW17h" /><figcaption>Superset is metric-centric. Users can query all metrics and dimensions from a single virtual source</figcaption></figure><h4>Integration with XRF — eXecutive Reporting Framework</h4><p>As presented in <a href="https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70#efb9">Part-I</a>, XRF is a framework for producing succinct, high-fidelity, business critical reports that are consumed by executives and leadership teams. This framework is configured via the Minerva configs and powered entirely by Minerva API.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*hedx5FI-tvWKqhuA" /><figcaption>XRF automates a lot of repeated manual work and allows us to standardize high fidelity business critical reports</figcaption></figure><p>To curate an XRF report, users first define the reporting config and specify the desired business metrics, dimensional cuts, and global filters to apply. In addition, users can configure other controls such as whether a metric should be calculated as a running aggregation (e.g., MTD, QTD, or YTD), and the appropriate unit for growth rate time ratio comparisons (e.g., YoY, MoM, or WoW). Once these settings are specified, the Minerva API performs the necessary aggregations and final pivots to produce the final report.</p><p>The data output by XRF can be rendered in a Google sheet via a custom GoogleSheetHook as well as in Tableau via Presto connection. By leveraging the metric definitions in Minerva and its aggregation logic, we enforce consistency safeguards in the users’ choice of presentation layer.</p><h4>Integration with ERF — Experimentation Reporting Framework</h4><p>Unlike the analytics or reporting use cases, the experimentation use case is unique in that the metrics used for reporting are only a starting point. To make proper causal inferences, metrics must be joined with experiment assignment data before transforming them into summary statistics that can be used for valid statistical comparisons.</p><p>Typically, Minerva supplies the “raw events” to ERF. Depending on the unit of randomization and unit of analysis, we join the Minerva data to the assignment logs using different subject keys so that each event will have the associated subject, as well as the experiment group attached to it. Summary statistics such as means, percent changes, and p-values are then calculated and surfaced in the ERF scorecard.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*wuT_vRG_w43SvZtf" /><figcaption>ERF scorecard showing summary statistics for experiments</figcaption></figure><p>The Experimentation UI also exposes relevant Minerva metadata directly in the tool. Users can view the description and ownership information of the underlying Minerva events. A lineage view, overlayed with ETA information, allows users to <a href="https://medium.com/airbnb-engineering/visualizing-data-timeliness-at-airbnb-ee638fdf4710">track the progress of ERF metrics</a> and helps them contact the relevant Minerva metric owners in case of delays.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ZtOE_1oe6GUtuY1T" /><figcaption>ERF displaying metrics metadata, which links to<a href="https://medium.com/airbnb-engineering/visualizing-data-timeliness-at-airbnb-ee638fdf4710"> SLA Tracker</a> to visualize data lineage and timeliness</figcaption></figure><p>In summary, Minerva and its various integrations enable users to easily track metrics within their scheduled reporting, measure movements due to experimentation, and explore unexpected changes — all with the confidence that the data is correct and consistent. This confidence drastically reduces the time spent deriving insights, increases trust in data, and helps to support data-driven decision making.</p><h3>Closing</h3><p>Minerva introduced a novel way of thinking about data, not only is it centered around a business- and metric-centric user interface, we also need to adapt traditional BI tools (that mostly talk SQL) to the interface of Minerva API. In some sense, it is akin to fitting a new square peg (Minerva) into an existing round hole ( BI Tools).</p><p>As more organizations embrace the concept of a metric layer similar to Minerva, we believe there will be a new set of challenges awaiting us. That said, some of this pioneering work will surely bring analytics to the next level, and we are grateful for contributing to the leading edge of this landscape. We hope that soon more companies will follow suit.</p><h3>Acknowledgements</h3><p>Thanks to everyone who <a href="https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70#8a0a">contributed to the work and outcomes</a> represented in this blog post. In addition to <a href="https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70#8a0a">previous acknowledgements</a> we would also like to thank those who have partnered with us to adopt Minerva within our consumption landscape.</p><p>All trademarks are the properties of their respective owners. Any use of these are for identification purposes only and do not imply sponsorship or endorsement.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=1c0b6a8b9206" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/how-airbnb-enables-consistent-data-consumption-at-scale-1c0b6a8b9206">How Airbnb Enables Consistent Data Consumption at Scale</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Commitment to Craft]]></title>
            <link>https://medium.com/airbnb-engineering/commitment-to-craft-e36d5a8efe2a?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/e36d5a8efe2a</guid>
            <category><![CDATA[culture]]></category>
            <category><![CDATA[people]]></category>
            <category><![CDATA[work-experience]]></category>
            <dc:creator><![CDATA[AirbnbEng]]></dc:creator>
            <pubDate>Thu, 16 Sep 2021 16:59:30 GMT</pubDate>
            <atom:updated>2021-09-16T20:03:27.761Z</atom:updated>
            <content:encoded><![CDATA[<p><a href="https://news.airbnb.com/cto-2018/"><em>Ari Balogh</em></a><em>, CTO at Airbnb</em>, shares how striving towards excellence has served us well in a time of uncertainty.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*EoAwRoDa43XnZypIQz7oUQ.jpeg" /></figure><p>If you’ve ever been part of a startup, you understand the importance of speed. Sometimes it feels like nothing else matters, since getting your products to market quickly can determine whether you survive. When Airbnb was an emerging company with a radical new vision for travel, we often had to prioritize speed in making tough engineering tradeoffs.</p><p>These decisions paid off, and Airbnb grew into a platform that supports millions of Hosts and Guests globally. Now, in addition to delivering fast, our success depends on providing an experience of exceptional quality that considers every detail for a diverse community that spans virtually every country. With this in mind, two years ago our tech organization took a holistic look at what we’d built and where to make changes. To prioritize excellence, we committed to creating an environment that enables people to do their best work and nurtures a mindset of quality — a Commitment to Craft.</p><p>Nobody could have predicted what came next. COVID-19 changed the world and impacted travel in unprecedented ways. With our Commitment to Craft already in place, we were better prepared for these challenges. In turn, we’ve developed an even deeper appreciation for quality and efficiency across our technology organization.</p><h3>What is Commitment to Craft?</h3><p>Commitment to Craft consists of several principles. First, it’s about systems built on sound technical foundations that enable easy adaptation and innovation, while ensuring quality. Second, it’s about enabling the people behind the work. To build on these foundations, it takes great talent combined with an environment that fosters creativity and collaboration, with clear accountability for deliverables. People then need the right tools and, importantly, time to do excellent work. Third, it’s about setting measurable goals: problems are clearly defined, and the individual teams create their plans.</p><p>A critical outcome is that these elements combine to create so much of the magic in our products. When people feel their craft is supported, their personal touches of excellence come through to bring true delight for our Hosts and Guests.</p><h3>Building with craft</h3><p>Change takes time. We cascaded goals to every engineer and data scientist (together we call them technologists) so everyone was part of the transformation. We started small, identifying a few concrete areas of improvement around site reliability, performance and developer tooling. These investments laid a foundation for quality and, over time, transformed how people work.</p><p>Commitment to Craft led to many important outcomes across Airbnb, including improving our page performance, <a href="https://medium.com/airbnb-engineering/data-quality-at-airbnb-e582465f3ef7">investing in our data quality</a>, <a href="https://medium.com/airbnb-engineering/achieving-insights-and-savings-with-cost-data-ec9a49fd74bc">using our compute resources more efficiently</a>, and improving our development practices, including testing.</p><h4>Example: Improving page performance</h4><p>Faster websites lead to happier users. But while we were focused on product innovation and adding more and more features, our pages became significantly slower. One of our Commitment to Craft goals was to reduce page load times. To set a specific target, we decided that “page performance score” — a composite score of user-centric metrics measuring the time it takes for a page to load and feel responsive — was a key measure.</p><p>To enable craft, we built a set of tools to measure fine-grained latencies across many page components. At the same time, our performance experts wrote a “how-to” guide on improving load times. With these resources, individuals across the entire org took ownership of improving the performance of their pages. The improvements were exceptional — we’ll share details in an upcoming blog post.</p><h3>Craft in a crisis</h3><p>We were progressing well on our Commitment to Craft goals when the world changed overnight. COVID-19 hit in early 2020 and Airbnb lost 80% of its business in eight weeks.</p><p>Prior to COVID, one of the elements of the Commitment to Craft program is what we called <em>Performance Efficiency:</em> delivering a reliable, performant experience in a cost-efficient manner. To support this, we started to build tools and techniques to help teams understand and optimize their cost of serving. With COVID, we doubled-down on these tools and techniques — and the use of these tools to improve efficiency and resource utilization. The result was a dramatic reduction in operating costs that helped us weather the storm.</p><h3>Looking ahead</h3><p>Today, Commitment to Craft is more than a set of projects — it’s a philosophy that people have rallied around. We’re starting to see teams across tech choose to prioritize craft simply because it’s “how we do things here.”</p><p>I’ve never been more proud of the work our teams are doing. We still have much to do, but we’re confident that this philosophy will help us navigate the future and keep us focused on what matters. Our goal is to achieve “agility with stability” — have the development agility of a startup combined with the product quality expected of a company of our scale. To get there, we’ll continue investing in the people behind the craft.</p><p><em>-Ari</em></p><p><em>If a culture of craft resonates with you, you might be a great fit for Airbnb. We’re currently hiring for a variety of technical roles, so check out our </em><a href="https://careers.airbnb.com/"><em>career page</em></a><em> for more information.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=e36d5a8efe2a" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/commitment-to-craft-e36d5a8efe2a">Commitment to Craft</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Automating Data Protection at Scale, Part 1]]></title>
            <link>https://medium.com/airbnb-engineering/automating-data-protection-at-scale-part-1-c74909328e08?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/c74909328e08</guid>
            <category><![CDATA[data]]></category>
            <category><![CDATA[privacy]]></category>
            <category><![CDATA[distributed-systems]]></category>
            <category><![CDATA[security]]></category>
            <dc:creator><![CDATA[elizabeth nammour]]></dc:creator>
            <pubDate>Tue, 14 Sep 2021 17:00:16 GMT</pubDate>
            <atom:updated>2021-09-14T17:00:16.451Z</atom:updated>
            <content:encoded><![CDATA[<p>Part one of a series on how we provide powerful, automated, and scalable data privacy and security engineering capabilities at Airbnb.</p><p><a href="https://www.linkedin.com/in/elizabethnammour/">Elizabeth Nammour</a>, <a href="https://www.linkedin.com/in/wendy-jing-jin-81452921/">Wendy Jin</a>, <a href="https://www.linkedin.com/in/shengpu-liu/">Shengpu Liu</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*u5ErTNsWp-x1GE72" /></figure><p>Our community of hosts and guests trust that we will keep their data safe and honor their privacy rights. With frequent news reports of data security breaches, coupled with global regulations and security requirements, monitoring and protecting data has become an even more critical problem to solve.</p><p>At Airbnb, data is collected, stored, and propagated across different data stores and infrastructures, making it hard to rely on engineers to manually keep track of how user and sensitive data flows through our environment. This, in turn, makes it challenging for them to protect it. While many vendors exist for different aspects of data security, no one tool met all of our requirements when it came to data discovery and automated data protection, nor did they support all of the data stores and environments in our ecosystem.</p><p>In this three-part blog series, we’ll be sharing our experience building and operating a data protection platform at Airbnb to address these challenges. In this first post, we will give an overview of why we decided to build the Data Protection Platform (DPP), walk through its architecture, and dive into the data inventory component, Madoka.</p><h3>Data Protection Platform (DPP)</h3><p>Since no one tool was meeting our needs, we decided to build a data protection platform to enable and empower Airbnb to protect data in compliance with global regulations and security requirements. However, in order to protect the data, we first needed to understand it and its associated security and privacy risks.</p><h4>Understanding Airbnb’s Data</h4><p>At Airbnb, we store petabytes of data across different file formats and data stores, such as MySQL, Hive, and S3. Data is generated, replicated, and propagated daily throughout our entire ecosystem. In order to monitor and gain an understanding of the ever-changing data, we built a centralized inventory system that keeps track of all the data assets that exist. This inventory system also collects and stores metadata around the security and privacy properties of each asset, so that the relevant stakeholders at Airbnb can understand the associated risks.</p><p>Since some data assets may contain sensitive business secrets or public information, understanding what type of data is stored within a data asset is crucial to determining the level of protection needed. In addition, privacy laws, such as the European Union General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA), have granted users the right to access and delete their personal data. However, personal data is a less-than-precise term that represents many different data elements, including email addresses, messages sent on the platform, location info, etc. In order to comply with these laws, we need to pinpoint the exact location of all personal data. To do this, we built a scalable data classification system that continuously scans and classifies our data assets to determine what type of data is stored within them.</p><h4>Enabling Automated Data Protection</h4><p>Based on the understanding of the data, the DPP strives to automate its protection, or enables and notifies teams across the company to protect it. This automation focuses on a few key areas: data discovery, prevention of sensitive data leakages, and data encryption.</p><p>Discovering personal data is the first step to privacy compliance. This is especially true as personal data needs to be deleted or returned to a user upon request. Our platform enables us to automatically notify data owners when new personal data is detected in their data stores and integrate this data with our privacy orchestration service to ensure it gets deleted or returned if needed.</p><p>A common cause of data breaches is when sensitive secrets, such as API keys or credentials, are leaked internally and then make their way into the hands of an attacker. This can come from an engineer logging the secret within their service or committing the secret to code. Our data protection platform identifies potential leaks from various endpoints and notifies the engineer to mitigate the leakage by deleting the secret from the code or log, rotating the secret, and then hiding the new secret with our encryption tool sets.</p><p>One of the most popular and important methods of data protection is encryption, since even in case of an infiltration, attackers won’t be able to get their hands on sensitive data. However, breaches due to unencrypted sensitive data are unfortunately a common occurrence within the industry.</p><p>Why does it still happen? Secure encryption with proper key management is technically challenging, and organizations do not always know where sensitive data is stored. The DPP aims to abstract these challenges by providing a data encryption service and client library that engineers can use. It automatically discovers sensitive data, so that we don’t rely on manual identification.</p><h4>Platform Architecture</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*SUuqoIcTshHVhQQ_" /><figcaption>Figure 1: DPP Overview</figcaption></figure><p>The DPP aims to discover, understand, and protect our data. It integrates the services and tools we built to tackle different aspects of data protection. This end-to-end solution includes:</p><ul><li><strong>Inspekt</strong> is our data classification service. It continuously scans Airbnb’s data stores to determine what sensitive and personal data types are stored within them.</li><li><strong>Angmar</strong> is our secret detection pipeline that discovers secrets in our codebase.</li><li><a href="https://medium.com/airbnb-engineering/one-step-forward-in-data-protection-8071e2258d16"><strong>Cipher</strong></a> is our data encryption service that provides an easy and transparent framework for developers across Airbnb to easily encrypt and decrypt sensitive information.</li><li><strong>Obliviate</strong> is our orchestration service, which handles all privacy compliance requests. For example, when a user requests to be deleted from Airbnb, obliviate will forward this request to all necessary Airbnb services to delete the user’s personal data from their data stores.</li><li><strong>Minister</strong> is our third party risk and privacy compliance service that handles and forwards all privacy data subject rights requests to our external vendors.</li><li><strong>Madoka</strong> is our metadata service that collects security and privacy properties of our data assets from different sources.</li><li>Finally, we have our <strong>Data Protection Service</strong>,<strong> </strong>a presentation layer where we define jobs to enable automated data protection actions and notifications using information from Madoka (e.g., automate integrations with our privacy framework)</li></ul><h3>Madoka: A Metadata System</h3><p>Madoka is a metadata system for data protection that maintains the security and privacy related metadata for all data assets on the Airbnb platform. It provides a centralized repository that allows Airbnb engineers and other internal stakeholders to easily track and manage the metadata of their data assets. This enables us to maintain a global understanding of Airbnb’s data security and privacy posture, and provides an essential role in automating security and privacy across the company.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/920/0*OEag9YxDW3CT1iQy" /><figcaption>Figure 2: Madoka Architecture</figcaption></figure><p>Implemented by two different services, a crawler and a backend, Madoka has three major responsibilities: collecting metadata, storing metadata, and providing metadata to other services.The Madoka crawler is a daily crawling service that fetches metadata from other data sources, including Github, MySQL databases, S3 buckets, Inspekt (data classification service), etc. It then publishes the metadata onto an AWS Simple Queue Service (SQS) queue. The Madoka backend is a data service that ingests the metadata from the SQS queue, reconciles any conflicting information, and stores the metadata in its database. It provides APIs for other services to query the metadata findings.</p><p>The primary metadata collected by Madoka includes:</p><ul><li>Data assets list</li><li>Ownership</li><li>Data classification</li></ul><p>For each of the above we handle both MySQL and S3 formats.</p><h4>Data Assets List</h4><p>The first type of metadata that needs to be collected is the list of all data assets that exist at Airbnb, along with their basic metadata such as the schema, the location of the asset, and the asset type.</p><p>For MySQL, the crawler collects the list of all columns that exist within our production AWS account. It calls the AWS APIs to get the list of all clusters in our environment, along with their reader endpoint. The crawler then connects to that cluster using JDBI and lists all the databases, tables, and columns, along with the column data type.</p><p>The crawler retains the following metadata information and passes it along to the Madoka backend for storage:</p><ul><li>Cluster Name</li><li>Database Name</li><li>Table Name</li><li>Column Name</li><li>Column Data Type</li></ul><p>For S3, the crawler collects the list of all objects that exist within all of our AWS accounts.</p><p>At Airbnb, we use <a href="https://www.terraform.io/">Terraform</a> to configure AWS resources in code, including S3 buckets. The crawler parses the Terraform files to fetch the S3 metadata.</p><p>The crawler first fetches the list of all AWS account numbers and names, which are stored in a configuration file in our Terraform repository. It then fetches the list of all bucket names, since each bucket configuration is a file under the account’s subrepo.</p><p>In order to fetch the list of objects within a bucket, the crawler uses <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-inventory.html">S3 inventory reports</a>, a tool provided by AWS. This tool produces and stores a daily or weekly CSV file of all the objects contained in the bucket, along with their metadata. This is a much faster and less costly way of getting the list compared to calling the List AWS API. We’ve enabled inventory reports on all production S3 buckets in Terraform, and the bucket configuration will specify the location of the inventory report.</p><p>The crawler retains the following information and passes it along to Madoka backend for storage:</p><ul><li>Account Number</li><li>Account Name</li><li>Assume Role Name</li><li>Bucket Name</li><li>Inventory Bucket Account Number</li><li>Inventory Assume Role Name</li><li>Inventory Bucket Prefix</li><li>Inventory Bucket Name</li><li>Object key</li></ul><h4>Ownership</h4><p>Ownership is a metadata property that describes who owns a specific data asset.</p><p>We decided to collect service ownership, which allows us to link a data asset to a specific codebase, and therefore automate any data protection action that requires code changes.</p><p>We also decided to collect team membership, which is crucial to perform any data protection action that requires an engineer to do some work or that requires a stamp of approval. We chose to collect team ownership and not user/employee ownership since team members constantly change, while the data asset remains with the team.</p><p>At Airbnb, since we migrated to a service-oriented architecture (SOA), most MySQL clusters belong to a single service and a single team. To determine service ownership, the crawler fetches the list of the services that connect to a MySQL cluster and will set the service with the most number of connections within the last 60 days as the owner of all the tables within that cluster. There are many services that connect to all clusters for monitoring, observability, and other common purposes, so we created a list of roles that should be filtered out when determining ownership.</p><p>There are still some legacy clusters in use that are shared amongst many services, where each service owns specific tables within the clusters. For those clusters, not all tables will have the correct service owner assigned, but we allow for a manual override to correct these mistakes.</p><p>The crawler uses service ownership to determine team ownership, since at Airbnb, team ownership is defined within the service’s codebase on Git.</p><p>At Airbnb, all S3 buckets have a project tag in their Terraform configuration file, which defines which service owns the bucket. The crawler fetches the service ownership from that file and uses it to determine the team ownership, as described above for MySQL.</p><h4>Data Classification</h4><p>Data classification is a metadata property that describes what type of data elements are stored within the asset — e.g., a MySQL column which stores email addresses or phone numbers would be classified as personal data. Gathering data classifications allows us to understand the riskiness of each data set so we can determine the level of protection needed.</p><p>The crawler fetches the data classification from two different sources. First, it fetches data classifications from our Git repositories, since data owners can manually set the classifications in their data schema. However, relying on manual classifications is insufficient. Data owners do not always know what an asset contains, or they may forget to change the classifications when the data asset is updated to store new data elements.</p><p>The crawler will then fetch data classifications from our automated data classification tool, called Inspekt, which we will describe in detail in a later blog post. Inspekt continuously scans and classifies all of our major data stores, such as MySQL and S3. It outputs what data elements were found in each data asset. This ensures that our data is constantly monitored, and classifications are updated as data changes. As with any automated detection tool, precision and recall are never 100%, so false positives and false negatives may occur.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*uArO328-uBKl2WQ-" /><figcaption>Figure 3: Classification Reconciliation</figcaption></figure><p>Since the crawler fetches the data classifications from two different sources, some discrepancies may arise, where the manual classification contains data elements not found by Inspekt or vice versa. The crawler will forward all findings to the Madoka backend, which will resolve any conflicts. The status of the manual classification is marked as <em>new</em> by default and the status of the Inspekt classification is marked as suggested. If the manual classification aligns with the Inspekt result, the classification is automatically confirmed. If there is any discrepancy, we file tickets to the data owners through the data protection service. If the Inspekt classification is correct, the owners may update the data schema in the Git repository, or they can mark the Inspekt classification as incorrect to resolve the conflict.</p><h4>Other Security and Privacy Related Attributes</h4><p>Madoka also stores how data assets have integrated with our security and privacy tools. For example, we may store whether or not the data asset is encrypted using Cipher or is integrated with our privacy compliance service, Obliviate, for data subject rights requests. We built Madoka to be easily extensible and are constantly collecting and storing more security and privacy related attributes.</p><h3>Conclusion</h3><p>In this first post, we provided an overview of why we built the DPP, described the platform’s architecture, and dove into the data inventory component, Madoka. In our next post, we will focus on our data classification system that enables us to detect personal and sensitive data at scale. In our final post we will deep dive into how we’ve used the DPP to enable various security and privacy use cases.</p><h3>Acknowledgements</h3><p>The DPP was made possible thanks to many members of the data security team: Pinyao Guo, Julia Cline, Jamie Chong, Zi Liu, Jesse Rosenbloom, Serhi Pichkurov, and Gurer Kiratli. Thank you to the data governance team members for partnering and supporting our work: Andrew Luo, Shawn Chen, and Liyin Tang. Thank you Tina Nguyen for helping drive and make this blog post possible. Thank you to our leadership, Marc Blanchou, Brendon Lynch, Paul Nikhinson and Vijaya Kaza, for supporting our work. Thank you to previous members of the team who contributed greatly to the work: Lifeng Sang, Bin Zeng, Alex Leishman, and Julie Trias.</p><p>If this type of work interests you, see <a href="https://careers.airbnb.com/">our career page</a> for current openings.</p><p>Tags: data, security</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=c74909328e08" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/automating-data-protection-at-scale-part-1-c74909328e08">Automating Data Protection at Scale, Part 1</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Task-Oriented Conversational AI in Airbnb Customer Support]]></title>
            <link>https://medium.com/airbnb-engineering/task-oriented-conversational-ai-in-airbnb-customer-support-5ebf49169eaa?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/5ebf49169eaa</guid>
            <category><![CDATA[reinforcement-learning]]></category>
            <category><![CDATA[nlp]]></category>
            <category><![CDATA[customer-support]]></category>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[ai]]></category>
            <dc:creator><![CDATA[Gavin Li]]></dc:creator>
            <pubDate>Tue, 10 Aug 2021 16:51:16 GMT</pubDate>
            <atom:updated>2021-08-10T17:45:29.187Z</atom:updated>
            <content:encoded><![CDATA[<p>How Airbnb is powering automated support to enhance the host and guest experience</p><p><a href="https://www.linkedin.com/in/gavin-li-64354117/">Gavin Li</a>, <a href="https://www.linkedin.com/in/mia-zhao-964a9213/">Mia Zhao</a></p><figure><img alt="mother and daughter sitting on a chair, scrolling through their phone" src="https://cdn-images-1.medium.com/max/1024/0*46ISdm7kRuJddwie" /></figure><p>Customer Support (CS) can make or break a guest’s travel experience. To support Airbnb’s community of guests and Hosts, we have been investing heavily in developing intelligent CS solutions leveraging state-of-the-art natural language processing (NLP), machine learning (ML), and artificial intelligence (AI) technologies.</p><p>In this blog post, we’ll introduce the automated support system at Airbnb, which employs the latest task-oriented conversational AI technology, through the lens of a recently launched feature called Mutual Cancellation. We will describe in detail how we framed the business problem as an AI problem, how we collected and labeled training data, how we designed and built the ML models, and how the models were deployed in the online system. Throughout each step, we’ll discuss some technical challenges we faced during this project and the solutions we innovated to address these challenges.</p><h4>A Case Study: Mutual Cancellation</h4><p>Prior to the development of the mutual cancellation model, guests needed to involve CS agents, even if they had already reached an agreement with the host for canceling a reservation. This meant that issues took longer to get resolved and precious CS agent hours were wasted. To solve this issue, we developed AI models that help guests and Hosts self-resolve cancellation and refund issues without involving a CS agent. This empowers hosts and guests to decide what is best for them, while allowing us to focus CS agent hours where they are needed most.</p><p>In the rest of the post, we will use the mutual cancellation feature as an example to describe the technical components of Airbnb’s task-oriented AI system.</p><h3>System Architecture</h3><p>Airbnb’s Intelligent Support Platform team develops cutting-edge AI technologies to help guests and hosts solve their issues in the most efficient manner. Based on the chatbot platform we built, <a href="https://medium.com/airbnb-engineering/using-chatbots-to-provide-faster-covid-19-community-support-567c97c5c1c9">ATIS</a>, our AI models aim to learn and mimic how human agents provide warm and effective customer care. A warm and effective customer care experience starts with a personal and intelligent issue identification that aims to quickly understand the user’s situation, needs, questions and concerns with minimum friction.. Once the issue is clearly identified, we generate responses dynamically and guide users through various product workflows to solve their issues or route them to human agents.</p><p>Our intelligent customer support product is designed as a “task-oriented dialog system” (<a href="https://arxiv.org/abs/2007.12720">Zang et al. 2020</a>, <a href="https://arxiv.org/abs/2008.06239">Madotto et al. 2020</a>). Task-oriented dialog systems are gaining more and more interest in recent years, powering AI products ranging from virtual assistants to smart speakers. These models can understand the user’s intent (e.g., ‘play music’), extract needed parameters (e.g., ‘artist name and name of the song’) from the conversation, ask questions to clarify details (e.g., ‘there are two versions of this song, which one do you like to play?’), and complete the task — all while having a dialogue with the user that seems completely natural.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/851/1*LfN3IPLswc0LJcYVQCdmRQ.png" /><figcaption>Figure 1. Airbnb’s Chatbot as a task-oriented dialog system. It detects user intent and generates appropriate responses and completes the task through actions.</figcaption></figure><h3>Customer Support as a Task-Oriented Dialog Problem</h3><p>In real-world machine learning applications, the most crucial piece of the puzzle is how to formulate the problem. Problem formulation has a much more significant impact on the product’s long-term performance than the model itself. There are lots of decisions and trade-offs to be made before a single line of code is written. We designed a multi-layer issue detection and decision-making system to allow both extensibility and domain-specificity for the customer support problem, as demonstrated in Figure 2.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/882/1*TA0BXmY2hYhuswYJNOJrYA.png" /><figcaption>Figure 2. A multi-layer user issue detection and decision-making model structure.</figcaption></figure><p>When a user sends a message in the Airbnb chatbot, the message is processed by the first layer, a domain classification model. The domain classification model determines which domain the message belongs to, for example, a trip rebooking request, a cancellation refund request, or a question that can be answered with a help article recommendation. If the Mutual Cancellation domain is predicted to be the most likely domain, the system triggers the Mutual Cancellation flow and enters the second layer to further our understanding of the user’s intent and checks the eligibility of the Mutual Cancellation.</p><p>For Mutual Cancellation, there are two models in the second layer: the Q&amp;A-based intent understanding model and the “expected refund ratio prediction” model. The Q&amp;A intent model is trained on a manually labeled dataset. The “expected refund ratio prediction” model is trained on historical cancellation data and refund ratio decided by agents. Refund ratios capture many vital characteristics of the trip that are crucial for the AI system to make decisions on behalf of human agents.</p><p>The multi-layer structure has the benefit of:</p><ul><li><strong>Scalable</strong>: it allows the system to be extended to new domains and domain-specific models for existing domains won’t be affected by new domains.</li><li><strong>Effective</strong>: the top-level model is trained on manually labeled data which is usually high quality, but often difficult and expensive to collect. Domain-specific models are mostly trained from historical data, easy to collect but noisy and biased towards past user behavior. The multi-layer structure allows us to leverage human-labeled data to train the top-layer domain prediction model and historical data to train domain-specific models.</li></ul><h3>Collecting and Labeling Training Data</h3><p>A typical task-oriented dialog system builds an intent taxonomy tree where each node represents some intent, and the nodes are mutually exclusive. Airbnb’s customer support, similar to other shared-economy customer support, users’ issues contain complex issues that are less structural than a typical online marketplace. It is challenging, if possible at all, to define a clean taxonomy tree to capture ALL users’ issues and partition them in a hierarchical tree.</p><p>In addition, a taxonomy tree usually implies that we need to traverse from the root node following a path to the leaf node. Along the path, the system asks questions (e.g., “Do you want to cancel the reservation?”) or collects more information (e.g., “Is the user a Guest or a Host?”) to decide on which branch to continue. In Airbnb’s case, users’ issues are much more complicated and may require different sequences of questions to identify the issue efficiently. For Mutual Cancellation, the first question (“if the host and guest agree with each other”) and the second question(“who initiated the cancellation”) capture different aspects of the cancellation and refund process. It can be challenging to design a simple and clean tree structure taxonomy to cover all user issues and rely on the path down the tree to collect the needed information efficiently. Instead, we model intent understanding as a Question &amp; Answer (Q&amp;A) problem.</p><h4>A Q&amp;A Model for Understanding User Intent</h4><p>Given a user’s initial message to our CS platform, we ask a couple of questions about the user’s intent, and then have human agents/labelers answer those questions. Through this setup, we collect data and train a Q&amp;A model. The trained Q&amp;A model is able to answer those questions similarly. Users’ questions can have multiple answers and users often try to describe the problem from different angles. In some cases, the questions can be mutually exclusive, whereas in other cases the questions may contain redundant information.</p><p>Below are a few examples we ask our labeler team:</p><p><strong><em>User’s message to Airbnb:</em></strong></p><p><em>Hello! I made a reservation wrongly. Thinking it was a whole apartment rental when it was actually just a room. I didn’t pay attention. I immediately spoke to my host, she agreed to refund me and asked me to request the refund money from the app, but I can’t find the option.</em></p><p><strong><em>Question: Who initiated the cancellation?</em></strong></p><p><strong><em>Answer:</em></strong></p><ol><li><em>The host initiated the cancellation, or the host could not accommodate the guest</em></li><li><em>The guest initiated the cancellation</em></li><li><em>Not mentioned</em></li></ol><p><strong><em>Question: Do the host and guest agree on a refund?</em></strong></p><p><strong><em>Answer:</em></strong></p><ol><li><em>Host agrees on offering a refund and the refund amount</em></li><li><em>Host and guest are having some differences on the refund amount</em></li><li><em>Host disagrees with issuing a refund or already declined it</em></li><li><em>Agreement not mentioned about refund</em></li><li><em>Refund not mentioned at all</em></li></ol><p><strong><em>Question: Is the guest asking how they can get what they want? (how to get refund, what to do, etc)</em></strong></p><p><strong><em>Answer:</em></strong></p><ol><li><em>Yes</em></li><li><em>No</em></li></ol><p><strong><em>Question: Is the guest asking how they can get a refund, if is it possible, or how much refund can they get?</em></strong></p><p><strong><em>Answer:</em></strong></p><ol><li><em>Yes</em></li><li><em>No</em></li></ol><p>Q&amp;A problems with multiple-choice answers are normally modeled as a multi-class classification problem, where each class maps to one question. However, <a href="https://arxiv.org/abs/2011.03292">Jiang et al. (2020)</a> proposed the idea of modeling Q&amp;A problems as single-choice binary classification problems. In modeling the problem this way, the difficulty of the problem increases. Picking the correct answer from multiple options is no longer sufficient － the model must predict the correct choice as positive and all other choices as negative. This approach makes consolidating multiple Q&amp;A problems easier, enabling us to increase the pre-training scale. <a href="https://arxiv.org/abs/2005.00700">Khashabi et al. (2020)</a> similarly found that unifying multiple pre-training datasets can help boost the model performance.</p><p>We follow the single-choice binary setup, which enables us to unify related user intent training labels from different domains to increase the scale of our training data and enhance the performance. As stated above, we continuously review the data labeling quality and refine the labeling questionnaire design. As a result, there are many versions of labeling questions and the answers for each version. A single-choice setup allows us to mix all the different versions of our training questions together in training.</p><p>Figures 3 and 4 show the difference between single-choice and multi-choice setups for an example message “<em>My host agreed to fully refund me, so if I cancel now can I get a full refund?</em>”</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/915/1*iHFTwigsFWtMPuQ--aoy5w.png" /><figcaption>Figure 3. Single-choice Q&amp;A model setup</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/885/1*EmjZlJzZMdzpt3POAjMVrw.png" /><figcaption>Figure 4. Multi-choice Q&amp;A setup</figcaption></figure><p>Figure 5 shows the model performance difference in our experiment. Single-choice Q&amp;A setup outperforms traditional multi-class intent classification setup both on offline labeling prediction accuracy and on online conversion prediction.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*3GUwYj0tepuePtLJ0aBsmA.png" /><figcaption>Figure 5. Accuracy of single-choice vs. multi-class intent classification.</figcaption></figure><h4>Benefits and Challenges of Intent Prediction as Q&amp;A</h4><p>Compared with traditional multi-class classification, the Q&amp;A setup makes the data labeling much more manageable. We can continuously refine the questionnaire design and flexibly merge questions from different dimensions, different angles, or those with redundancy.</p><p>One of the biggest challenges of applying machine learning in real-world problems is the lack of high-quality training data. From a few-shot learning point of view, the single-choice Q&amp;A setup allows us to build many capabilities into the model, even with sparse training data. This setup trains the model to encode information in the user message, the question and the answer. The model can also learn from related questions from other domains. For this reason, it has the capability to understand both questions in training labels and some newly constructed, unseen questions.</p><p>A shortcoming of this setup is that it puts a lot of pressure on the serving latency. For example, if we want to use the model to answer five questions and then take actions based on the five questions, we have to run the model five times. Later in this post, we’ll discuss how we reduce the model latency including using GPU.</p><h3>Model Design and Implementation</h3><p>We use autoencoder transformers as model architecture. We tested all kinds of model choices as the backbone. The results are shown below:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*JY2SnLt2CGbwHC7gYjQtGw.png" /><figcaption>Figure 6. Results on out-of-sample data from various intent classification models.</figcaption></figure><p>For most of our use cases, Roberta performs the best. However, the Roberta-base and Roberta-large’s performances vary depending on the scale of training labels. In our online product case, where we have around 20K labels, the Roberta-large model achieved the best performance and is the model that we deployed in production. However, with 335M parameters, it is very challenging to run this model online with a given latency budget.</p><p>To improve the performance of this model, we leveraged three key techniques:</p><ul><li>Pre-training our transformer model with transfer learning;</li><li>Translating training labels to utilize a multilingual model; and</li><li>Incorporating multi-turn intent predictions.</li></ul><h4>Pre-training</h4><p>Perhaps the most critical recent development in deep learning is transfer learning and pre-training. It dominates most state-of-the-art models in almost all kinds of NLP, computer vision(CV), and automatic speech recognition(ASR) domains.</p><p>We experimented with different pre-training methods extensively and found two pre-training methods to be particularly effective in boosting the model performance:</p><ul><li><strong>In-Domain Unsupervised Masked Language Model (MLM) Pre-training:</strong> Based on users’ conversations with our customer service platform, the listing descriptions, and the help articles, we construct a 1.08GB (152M word tokens) unsupervised training corpus. This corpus contains 14 different languages, with 56% in English. As shown through the experiment results in Figure 7, the in-domain MLM pre-training helps to boost the model performance for our tasks.</li><li><strong>Cross-Domain Task Finetune Pre-training: </strong>Pretraining a transformer model based on a cross-domain dataset is often helpful for many tasks. It’s also effective in boosting intent detection accuracy in our use cases. Experiments results can be found in Figures 8 and 9.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*MxI1RhDvxilRZoll83yPBw.png" /><figcaption>Figure 7. In-domain pre-training performance</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ehncNQ9sU2J-_lySRTYAvA.png" /><figcaption>Figure 8. cross-domain task finetune pre-training performance.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*HR9TzCqDhRxUF3lIvVwUHQ.png" /><figcaption>Figure 9. Multilingual task finetune pre-training performance.</figcaption></figure><p>Many challenging cases in our intent understanding problem require the model to have some logical reasoning capability. Similar to the finding in the logical reasoning public dataset in <a href="https://arxiv.org/abs/2002.04326">Yu et al. (2020)</a>, pre-training on the RACE dataset helps to boost the performance the most.</p><h4>Multilingual Model</h4><p>Airbnb customer support serves users from all around the world, currently supporting 14 languages. The top non-English languages, including French, Spanish, German, and Portuguese, represent around 30% of the requests. Since our model is targeted at users who speak all languages but labeled data are mainly in English, we leveraged a translated annotation dataset and multilingual model, XLM-RoBERTa, to boost model performance across all languages.</p><p>Translating the training labels to other languages is an unsupervised data augmentation technique proven effective in many deep learning training cases (<a href="https://arxiv.org/abs/1904.12848">Xie et al., 2020</a>). We translate the labeled English training corpus and the labeling questions and answers into other top languages and include them in the training data to train the XLM-RoBERTa model.</p><p>We also tried training monolingual models on translated text for comparison based on public pre-trained monolingual models. Results show that multilingual models trained on translated datasets significantly outperform the English-only training dataset. Model performance is comparable with monolingual models trained by translated annotation datasets.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*usU-lK5fyOuDn5WWol6x6Q.png" /><figcaption>Figure 10. Multilingual vs. monolingual model performance.</figcaption></figure><h4>Incorporating Multi-Turn Intent Prediction</h4><p>When a user comes to chatbot with a Mutual Cancellation request, we pull all the text sequences from the user’s previous conversations and concatenate the text sequences of the previous messages and the current request message together as a new text sequence input to the transformer model. This works as a <strong>dialog state tracking</strong> (<a href="https://arxiv.org/abs/1908.01946">Gao et al., 2019</a>) module to incorporate the signals from user’s past interactions to better understand user intent. We experimented with two offline approaches to better consume this signal: 1) adding the last N round of messages as additional features to the current model, and 2) calculating multi-turn intent predictions on each message threshold and adding max intention score to the downstream model.</p><p>One challenge is that the computation complexity of transformer models is O(n⁴) of the sequence length, including all the previous conversions. The complexity makes it impossible to infer online in real-time. To solve this, we process the historical conversation asynchronously offline ahead of time and store pre-computer scores. During online serving, the model directly query the pre-computed scores associated to the user.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*zpDgIz3WO9vsTyk1vrmcBg.png" /><figcaption>Figure 11. Multi-turn intent prediction performance and latency.</figcaption></figure><h3>Online Serving</h3><p>Deploying machine learning models online comes with a few major challenges that need to be managed differently than in the offline world.</p><h4>Online Inference GPU Serving</h4><p>One challenge in online serving is the latency of the model in production. We took two key steps to solve for latency requirements: 1) enabling GPU serving, and 2) leveraging transfer learning. Similar to the discussions in the section above, transfer learning techniques like teacher student model is used to reduce the amount of computation needed in online inference. In this section we mainly focus on how GPU serving helped us address this challenge.</p><p>To support GPU inference, we experimented with an offline benchmark on transformer models with 282M parameters on three different instance types — <em>g4dn.xlarge, p3.2xlarge and r5.2xlarge</em>. Figure 12 shows the latency results across these various instance types. The general trend of latency between CPU and GPU as our input messages grow in length can be seen in Figure 13. Shifting to GPU serving has a significant impact on the online latency and is more cost-efficient.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Ihe4tlKCo_r9DGNqz4_Fuw.png" /><figcaption>Figure 12. GPU online serving latency for various instance types.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*3EEzjo6bTnB_rZvS" /><figcaption>Figure 13. Latency using CPU vs. GPU with input message length increasing.</figcaption></figure><p>The results from our later online experiment (Figure 14) also show the improvement in latency from shifting to GPU inference on transformer models. With ~1.1B parameters and average input message length of 100 words, we were able to achieve ~60ms on p95, which is 3x faster on single transform and five times faster on batch transform.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*hkQzw6r7Hk9K96_3" /><figcaption>Figure 14. Model latency in production before and after switching from CPU to GPU .</figcaption></figure><p>Switching to GPU not only improves the latency, it also allows us to run multiple model scoring in parallel. We leverage the PyTorch platform, which has built-in support for non-blocking model scoring, for better scalability.</p><h4>Contextual Bandit and Reinforcement Learning</h4><p>The second challenge in online serving is to adapt and optimize ML models based on new users’ online behavior. As we described in previous sections, the training data of the initial model is collected from historical user interaction over the product flow before the model is deployed. After the model is deployed, users interact with the system in a very different manner compared to the experience when the training data is collected. If the daily traffic is sufficiently large, we can always relabel the new data and update the model using the new data which reflects the updated user behavior, or directly perform multivariate testing on N policies. However, Airbnb’s CS chatbot traffic volume is relatively small compared to other ML systems such as search ranking. It will take a very long time to see the effect of any model change (either retrained model using new data or hyper parameter change).</p><p>To solve the challenge of low traffic volume, we use <strong>contextual bandit-based reinforcement learning</strong> (<a href="https://arxiv.org/abs/1802.04064">Bietti et al., 2019</a>; <a href="https://arxiv.org/abs/1606.03966">Agarwal et al., 2017</a>) to choose the best model and the most appropriate thresholds. Contextual Reinforcement Learning explores all the alternative problems by maximizing the rewards and minimizing the regrets. This allows us to learn from new behavior by dynamically balancing the exploration and exploitation.</p><p>We view this problem through three different actions in the product:</p><ul><li>a0: User is not directed through the mutual cancellation flow</li><li>a1: User is directed to the mutual cancellation UI for guests who have already agreed with the host on the refund</li><li>a2: User is directed to the mutual cancellation UI for cases where it was not clear if the host and guest have reached a mutual agreement</li></ul><p>Our reward function is <em>mutual cancellation flow entering rate</em> and <em>acceptance rate</em>. The reward at time step 𝑡 for any given action can be formulated as:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/228/1*unZjK8QE_0njZb43-0yXMw.png" /></figure><p>where c denotes if a mutual cancellation flow is not entered/accepted.</p><p>We then leveraged greedy-epsilon as our first exploration strategy. If it’s in exploration mode, we compute the probabilities for each action based on policies’ preferences and select it based on the chances. If it’s in exploitation mode, we choose the best policy. We compute the models’ thresholds based on a set of logged (x, a, r, p) tuples. We use an self-normalized inverse propensity-scoring (IPS) estimator (<a href="https://papers.nips.cc/paper/2015/hash/39027dfad5138c9ca0c474d71db915c3-Abstract.html">Swaminathan and Joachims 2015</a>) to evaluate each policy:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/491/1*r7eHhtXDjK3Pbi3EfJY4nw.png" /></figure><p>In production, this approach successfully helped us explore many different models and parameter options and make the best use of the limited online traffic.</p><h3>Conclusion</h3><p>In this post, we introduced how we employ state-of-the-art machine learning and AI models to build support products that better serve the needs of our guests and hosts. We described how we leverage a single-choice Q&amp;A-based model, large-scale pretraining, multilingual models, multi-turn dialog state tracking, and GPU serving and successfully tackled the technical challenges.</p><p>Interested in tackling challenges in the machine learning and AI space?</p><p>We invite you to visit our <a href="https://careers.airbnb.com">careers page</a> or apply for these related opportunities:</p><p><a href="https://grnh.se/36f092141us"><strong>Staff Data Architect, Community Support Platform</strong></a></p><p><a href="https://grnh.se/ae09e08b1us"><strong>Staff Software Engineer — Machine Learning Modeling Platform</strong></a></p><p><a href="https://grnh.se/6648b3961us"><strong>Machine Learning Engineer, Search Ranking</strong></a></p><h3>Acknowledgements</h3><p>Thanks to Cassie Cao, Hao Wang, Bo Zeng, Ben Ma, Wayne Zhang, Mariel Young , Shahaf Abileah, Pratik Shah, Brian Wang, Hwanghah Jeong, Amy Guo, Vita Papernov, Courtney Nam, Aliza Hochsztein, Mike Hinckley, Yushuang Dong, Jan Castor, Ivy Cui, Lucia Ciccio for the great contributions to Mutual Cancellation workflow development, ERF analysis and product launches. Special thanks to Alex Deng for the help on contextual bandit and reinforcement learning work; many designs are originally Alex’s idea. We would also like to thank Atul Ktal, Bahador Nooraei, Shaowei Su, Alfredo Luque for the ML infrastructure support on GPU inference. In addition, we would like to thank the contributors of open source ML libraries such as PyTorch and HuggingFace Transformers, which benefited us a lot. Finally, we want to appreciate Ari Balogh, Tina Su, Andy Yasutake, and Joy Zhang’s leadership support in leveraging machine learning on Customer Support Platforms.</p><h3>References:</h3><ol><li>Zang X, Rastogi A, Sunkara S, Gupta R, Zhang J, Chen J (2020) MultiWOZ 2.2 : A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines. CoRR abs/2007.12720</li><li>Jiang Y, Wu S, Gong J, Cheng Y, Meng P, Lin W, Chen Z, Li M (2020) Improving Machine Reading Comprehension with Single-choice Decision and Transfer Learning. CoRR abs/2011.03292</li><li>Khashabi D, Min S, Khot T, Sabharwal A, Tafjord O, Clark P, Hajishirzi H (2020) UnifiedQA: Crossing Format Boundaries With a Single QA System. In: Cohn T, He Y, Liu Y (eds) Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, EMNLP 2020, Online Event, 16–20 November 2020. Association for Computational Linguistics, pp 1896–1907</li><li>Yu W, Jiang Z, Dong Y, Feng J (2020) ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning. In: 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26–30, 2020. OpenReview.net</li><li>Madotto A, Liu Z, Lin Z, Fung P (2020) Language Models as Few-Shot Learner for Task-Oriented Dialogue Systems. CoRR abs/2008.06239</li><li>Xie Q, Dai Z, Hovy EH, Luong T, Le Q (2020) Unsupervised Data Augmentation for Consistency Training. In: Larochelle H, Ranzato M, Hadsell R, Balcan M-F, Lin H-T (eds) Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6–12, 2020, virtual</li><li>Bietti, Alberto, Alekh Agarwal, and John Langford. A Contextual Bandit Bake-off. Microsoft Research. 21 Mar. 2019</li><li>Agarwal, Alekh, Sarah Bird, Markus Cozowicz, Luong Hoang, John Langford, Stephen Lee, Jiaji Li, Dan Melamed, Gal Oshri, Oswaldo Ribas, Siddhartha Sen, and Alex Slivkins. Making Contextual Decisions with Low Technical Debt. ArXiv.org. 09 May 2017</li><li>Swaminathan A, Joachims T (2015) The Self-Normalized Estimator for Counterfactual Learning. In: Cortes C, Lawrence ND, Lee DD, Sugiyama M, Garnett R (eds) Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7–12, 2015, Montreal, Quebec, Canada. pp 3231–3239</li><li>Gao S, Sethi A, Agarwal S, Chung T, Hakkani-Tür D (2019) Dialog State Tracking: A Neural Reading Comprehension Approach. In: Nakamura S, Gasic M, Zuckerman I, Skantze G, Nakano M, Papangelis A, Ultes S, Yoshino K (eds) Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue, SIGdial 2019, Stockholm, Sweden, September 11–13, 2019. Association for Computational Linguistics, pp 264–273</li></ol><p><em>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5ebf49169eaa" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/task-oriented-conversational-ai-in-airbnb-customer-support-5ebf49169eaa">Task-Oriented Conversational AI in Airbnb Customer Support</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How Airbnb Built “Wall” to prevent data bugs]]></title>
            <link>https://medium.com/airbnb-engineering/how-airbnb-built-wall-to-prevent-data-bugs-ad1b081d6e8f?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/ad1b081d6e8f</guid>
            <category><![CDATA[airflow]]></category>
            <category><![CDATA[data]]></category>
            <category><![CDATA[data-quality]]></category>
            <category><![CDATA[data-engineering]]></category>
            <dc:creator><![CDATA[Subrata Biswas]]></dc:creator>
            <pubDate>Wed, 04 Aug 2021 17:00:02 GMT</pubDate>
            <atom:updated>2021-08-04T17:00:01.993Z</atom:updated>
            <content:encoded><![CDATA[<p>Gaining trust in data with extensive data quality, accuracy and anomaly checks</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*LkY1dXWTna9PbJNJ" /></figure><p>As shared in our Data Quality Initiative <a href="https://medium.com/airbnb-engineering/data-quality-at-airbnb-e582465f3ef7">post</a>, Airbnb has embarked on a project of massive scale to ensure trustworthy data across the company. To enable employees to make faster decisions with data and provide better support for business metric monitoring, we introduced <a href="https://medium.com/airbnb-engineering/data-quality-at-airbnb-870d03080469">Midas</a>, an analytical data certification process that certifies all important metrics and data sets. As part of that process, we made robust data quality checks and anomaly detection mandatory requirements to prevent data bugs propagating through the data warehouse. We also created guidelines on which specific data quality checks need to be implemented as part of the data model certification process. Adding data quality checks in the pipeline has become a standard practice in our data engineering workflow, and has helped us detect many critical data quality issues earlier in the pipelines.</p><p>In this blog post we will outline the challenges we faced while adding a massive number of data checks (i.e. data quality, accuracy, completeness and anomaly checks) to prevent data bugs company-wide, and how that motivated us to build a new framework to easily add data checks at scale.</p><h3>Challenges</h3><p>When we first introduced the <a href="https://medium.com/airbnb-engineering/data-quality-at-airbnb-870d03080469">Midas</a> analytical data certification process, we created recommendations on what kind of data quality checks need to be added, but we did not enforce how they were to be implemented. As a result, each data engineering team adopted their own approach, which presented the following challenges:</p><h4>1. Multiple approaches to add data checks</h4><p>In Airbnb’s analytical data ecosystem, we use Apache Airflow to schedule ETL jobs or data pipelines. Hive SQL, Spark SQL, Scala Spark, PySpark and Presto are widely used as different execution engines. However, because teams started building similar data quality checks in different execution engines, we encountered other inherent issues:</p><ul><li>We did not have any centralized way to view the data check coverage across teams.</li><li>A change in data check guidelines would require changes in multiple places in the codebase across the company.</li><li>Future-proof implementations were nearly impossible to scale. Teams kept re-inventing the wheel and duplicated code spread across the codebase.</li></ul><h4>2. Redundant efforts</h4><p>Different teams often needed to build tools to meet their own requirements for different data checks. Each Data Engineering (DE) team started to build data check tools in silos. Although each of these teams were building solid tools to meet their individual business needs, this approach was problematic for a few reasons:</p><ul><li>We started to build multiple frameworks in parallel.</li><li>Data check frameworks became costly to maintain and introduced operational overhead.</li><li>Missing features and lack of flexibility/extensibility made these frameworks difficult to reuse across the company.</li></ul><h4><strong>3. Complicated Airflow DAG code</strong></h4><p>Each check was added as a separate task in Airflow as part of the ETL pipeline. Airflow DAG files soon became massive. The operational overhead for these checks grew to the point that it became hard to maintain, because of a few different factors:</p><ul><li>There was no support for blocking vs non-blocking checks. Minor check failures or false alarms often blocked the SLA of critical data pipelines.</li><li>ETL logic and data checks became tightly coupled and not reusable.</li><li>Maintenance became operationally challenging, as we tracked the dependencies manually, which also made it difficult to add more checks.</li></ul><h3>Defining the Requirements</h3><p>To address these tooling gaps, we set out to build a unified data check framework that would meet the following requirements and ensure greater usability overtime:</p><ul><li>Extensible : Unify data check methodologies in use at Airbnb</li><li>Configuration-driven: Define the checks as YAML-formatted files for faster development</li><li>Easy to use: Provide a simplified interface to promote faster adoption company wide</li></ul><h3>Introducing Wall Framework</h3><p>Wall is the paved path for writing offline data quality checks. It is a framework designed to protect our analytical decisions from bad data bugs and ensure trustworthy data across Airbnb.</p><p>Wall Framework is written in Python on top of Apache Airflow. Users can add data quality checks to their Airflow DAGs by writing a simple config file and calling a helper function in their DAG.</p><ul><li>Wall provides most of the quality checks and anomaly detection mechanisms currently available in the company under a common framework, making data checks a lot easier to standardize.</li><li>It supports templated custom SQL-based business logic, accuracy checks, and an extensible library of predefined checks.</li><li>Wall is config driven — no code is required to add checks.</li><li>Checks can be used in the ETL pipeline in a <a href="https://airflow.apache.org/docs/apache-airflow/1.10.2/concepts.html?highlight=branch%20operator#subdags">Stage-Check-Exchange</a> pattern or as standalone checks.</li><li>The framework is extensible — any team can add their team-specific checks to Wall quite easily following the open source model (as per the Data Engineering Paved Path team’s approval).</li><li>Business users can easily add quality checks without creating any airflow DAG or tasks for each check.</li><li>Wall takes care of SQL-based checks and anomaly detection task creations. It also takes care of stage and exchange task creations and setting the appropriate dependency on the checks in a decoupled manner. Hence, after migrating to Wall, ETL pipelines were drastically simplified and we’ve seen cases where we were able to get rid of more than 70% of DAG code.</li></ul><h3>Wall Architecture</h3><p>Following our key requirements, this framework was designed to be extensible. It has three major components — WallApiManager, WallConfigManger and WallConfigModel..</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*WkknwY6urhgMsEik" /><figcaption>Wall internal architecture</figcaption></figure><h4>WallApiManager</h4><p>The Wall Api Manager is the public interface to orchestrate checks and exchanges using Wall. Wall users only use this from their DAG files. It takes a config folder path as input and supports a wide variety of ETL operations such as Spark, Hive etc.</p><h4>WallConfigManager</h4><p>The Wall Config Manager parses and validates the check config files and then calls the relevant CheckConfigModels to generate a list of Airflow tasks. Wall primarily uses Presto checks to generate data checks.</p><h4>CheckConfigModel</h4><p>Each Wall check is a separate class that derives from BaseCheckConfigModel. CheckConfigModel classes are primarily responsible for validating check parameters and generating Airflow tasks for the check. CheckConfigModel makes the framework extensible. Different teams can add their own CheckConfigModel if existing models do not support their use cases.</p><h3>Key Features</h3><p>Wall framework provided the following key features to address the requirements we mentioned above.</p><h4>Flexibility</h4><ul><li>Wall configs can be located in the same repository where teams are already defining their data pipeline DAGs — teams or DAG owners can decide where they’re located. Teams can either use a separate YAML file for each table or a single YAML file for a group of tables to define checks.</li><li>Each check config model can define an arbitrary set of parameters and it can override parameters if needed. The same check configs can be orchestrated and run differently based on running context. i.e. as part of ETL’s stage-check-exchange or as pre/post checks.</li><li>A check property can be hierarchical (i.e. it can be defined at team level, file level, table level or at check level). Lower level property values override upper level values. Teams can define their team level defaults in a shared YAML file instead of duplicating the same configurations and checks in different YAML files.</li><li>In the case of stage-check-exchange checks, users can specify blocking and non-blocking checks. It makes Wall more flexible while onboarding new checks.</li></ul><h4>Extensibility</h4><ul><li>It’s easy to onboard a new type of check model. Wall is able to support commonly used data checks/validations mechanisms.</li><li>Each check config model is decoupled from each other and it can define its own set of params, validations, check generation logic, pre-processing etc.</li><li>Check config models can be developed by the data engineering community with the collaboration of the Data Engineering Paved Path team.</li></ul><h4>Simplicity</h4><ul><li>Easy to copy-paste to apply similar checks in different tables or contexts.</li><li>Check models are intuitive.</li><li>Checks are decoupled from DAG definition and ETL pipeline so that they can be updated without updating ETL.</li><li>Easy to test all the checks at once.</li></ul><h3>Adding a Wall check</h3><p>At the every high level, users need to write a yaml config and invoke Wall’s API from their DAG to orchestrate their ETL pipeline with data checks.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*R6UrxoyuLlaZ4dsI" /><figcaption>High level diagram of how users interact with Wall.</figcaption></figure><p>As an example of how easy it is to add a new data quality check, let’s assume you’d like to add a data quality check — verifying that a partition is not empty — to a table named foo.foo_bar in the wall_tutorials_00 DAG. It can be done by following these two steps:</p><ol><li>Decide on a folder to add your wall checks configs i.e. projects/tutorials/dags/wall_tutorials_00/wall_checks. Create a check config file (i.e. foo.foo_bar.yml ) with the following contents in your wall check config folder:</li></ol><pre>primary_table: foo.foo_bar<br>emails: [&#39;<a href="mailto:subrata.biswas@airbnb.com">subrata.biswas@airbnb.com</a>&#39;]<br>slack: [&#39;#subu-test&#39;]<br>quality_checks:<br>   - check_model: CheckEmptyTablePartition<br>     name: EmptyPartitionCheck</pre><p>Update the DAG file (i.e. wall_tutorials_00.py) to create checks based on the config file.</p><pre>from datetime import datetime</pre><pre>from airflow.models import DAG</pre><pre>from teams.wall_framework.lib.wall_api_manager.wall_api_manager import WallApiManager</pre><pre>args = {</pre><pre>&quot;depends_on_past&quot;: True,</pre><pre>&quot;wait_for_downstream&quot;: False,</pre><pre>&quot;start_date&quot;: datetime(2020, 4, 24),</pre><pre>&quot;email&quot;: [&quot;subrata.biswas@airbnb.com&quot;,],</pre><pre>&quot;adhoc&quot;: True,</pre><pre>&quot;email_on_failure&quot;: True,</pre><pre>&quot;email_on_retry&quot;: False,</pre><pre>&quot;retries&quot;: 2,</pre><pre>}</pre><pre>dag = DAG(&quot;wall_tutorials_00&quot;, default_args=args)</pre><pre>wall_api_manager = WallApiManager(config_path=&quot;projects/tutorials/dags/wall_tutorials_00/wall_checks&quot;)</pre><pre># Invoke Wall API to create a check for the table.</pre><pre>wall_api_manager.create_checks_for_table(full_table_name=&quot;foo.foo_bar&quot;, task_id=&quot;my_wall_task&quot;, dag=dag)</pre><p><strong>Validate and Test</strong></p><p>Now if you check the list of tasks of the wall_tutorials_00 you’ll see the following tasks created by the Wall Framework:</p><pre>&lt;Task(NamedHivePartitionSensor): ps_foo.foo_bar___gen&gt;</pre><pre>   &lt;Task(SubDagOperator): my_wall_task&gt;</pre><p>Wall created a SubDagOperator task and a NamedHivePartitionSensor task for the table in the primary DAG (i.e. wall_tutorials_00). Wall encapsulated all the checks inside the sub-dag. To get the check tasks list you would need to look at the sub-dag tasks i.e. run list_tasks for the wall_tutorials_00.my_wall_task dag. It returns the following list of tasks for this case:</p><pre>&lt;Task(WallPrestoCheckOperator): EmptyPartitionCheck_foo.foo_bar&gt;</pre><pre>   &lt;Task(DummyOperator): group_non_blocking_checks&gt;</pre><pre>      &lt;Task(DummyOperator): foo.foo_bar_exchange&gt;</pre><pre>&lt;Task(DummyOperator): group_blocking_checks&gt;</pre><pre>   &lt;Task(DummyOperator): foo.foo_bar_exchange&gt;</pre><pre>&lt;Task(PythonOperator): validate_dependencies&gt;</pre><p>Note: You probably noticed that Wall created a few DummyOperator tasks and a PythonOperator task in the sub-DAG. It was required to maintain control flows i.e. blocking vs non-blocking checks, dependencies, validation etc. You can ignore those tasks and don’t need to take dependencies on these tasks since they may change or can be deleted in future.</p><p>Now you can test your check tasks just like any airflow tasks i.e.</p><pre>airflow test wall_tutorials_00.my_wall_task EmptyPartitionCheck_foo.foo_bar {ds}</pre><h3>Wall in Airbnb’s Data Ecosystem.</h3><p>Integrating Wall with other tools in Airbnb’s data ecosystem was critical for its long term success. To allow other tools to integrate easily, we publish results from the “check” stage as Kafka events, to which other tools can subscribe. The following diagram shows how other tools are integrated with Wall:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*zPIHSSuv-7zdHmzJ" /><figcaption>Wall in Airbnb’s data ecosystem</figcaption></figure><h3>Conclusion</h3><p>Wall ensures a high standard for data quality at Airbnb and that the standard does not deteriorate over time.</p><p>Through enabling standardized but extensible data checks that can be easily propagated across our distributed data engineering organization, we continue to ensure trustworthy, reliable data across the company. As a result all of Airbnb’s critical business and financial data pipelines are using Wall and we have hundreds of data pipelines running thousands of Wall checks every day.</p><p>If this type of work interests you, check out some of our related positions:</p><p><a href="https://grnh.se/706bf4e01us">Senior Data Engineer</a></p><p><a href="https://grnh.se/a207325d1us">Staff Data Scientist- Algorithms, Payments</a></p><p>and more at <a href="https://careers.airbnb.com/">Careers at Airbnb</a>!</p><p>You can also learn more about our <em>Journey Toward High Quality</em> by watching our recent <a href="https://fb.watch/72Oumx3pJJ/">Airbnb Tech Talk</a>.</p><p>With special thanks to <a href="https://www.linkedin.com/in/nikuma/">Nitin Kumar</a>, <a href="https://www.linkedin.com/in/bharatrangan/">Bharat Rangan</a>, <a href="https://www.linkedin.com/in/kenneth-jung-71495256/">Ken Jung</a>, <a href="https://www.linkedin.com/in/victor-ionescu-3a029b5a/">Victor Ionescu</a>, <a href="https://www.linkedin.com/in/siyu-qiu-05b482a1/">Siyu Qiu</a> for being key partners while evangelizing this framework.</p><p><em>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ad1b081d6e8f" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/how-airbnb-built-wall-to-prevent-data-bugs-ad1b081d6e8f">How Airbnb Built “Wall” to prevent data bugs</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Using Sentiment Score to Assess Customer Service Quality]]></title>
            <link>https://medium.com/airbnb-engineering/using-sentiment-score-to-assess-customer-service-quality-43434dbe199b?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/43434dbe199b</guid>
            <category><![CDATA[ai-model]]></category>
            <category><![CDATA[a-b-testing]]></category>
            <category><![CDATA[ai]]></category>
            <category><![CDATA[machine-learning-ai]]></category>
            <category><![CDATA[customer-experience]]></category>
            <dc:creator><![CDATA[Shuai Shao (Shawn)]]></dc:creator>
            <pubDate>Tue, 27 Jul 2021 15:48:00 GMT</pubDate>
            <atom:updated>2021-07-27T21:50:15.137Z</atom:updated>
            <content:encoded><![CDATA[<p>How AI-based Sentiment Models Complement Net Promoter Score</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*oVSUzHkUykPwADBZ" /></figure><p>By <a href="https://medium.com/@shuai_shao">Shuai Shao</a>, <a href="https://medium.com/@cenzhao06">Mia Zhao</a>, <a href="https://medium.com/@chloe.yuanyuan.ni">Yuanyuan Ni</a></p><p>Net Promoter Score (NPS) is a well-accepted measurement of customer satisfaction in most customer-facing industries. We leverage NPS at Airbnb to help measure how well we serve our community of guests and hosts through our customer service. But NPS has two major drawbacks: 1) NPS is <em>sparse</em>, given only a fraction of users respond to the survey, and 2) NPS is <em>slow</em>. It takes at least a week for results to show up. Airbnb uses A/B testing heavily across our core products and customer service offerings. In the A/B testing world, the longer it takes to see results and interpret experiments, the longer it takes to iterate on the quality of our customer service. This is why we needed a much more <em>sensitive</em> and <em>robust</em> metric.</p><p>To address these limitations, Airbnb has developed an AI-based sentiment model to complement NPS. Sentiment models process messages users send to customer support (CS) representatives to extract signals reflecting users’ sentiment. Compared to NPS, the sentiment score has the following advantages:</p><ul><li>Higher <em>coverage</em>: we are not limited to those who submit a survey, and therefore more users in a given experiment register a value for this metric;</li><li>Better <em>sensitivity</em>: it takes much less time to reach statistical significance while running an experiment;</li><li><em>Causal relationship</em> with long term customer loyalty: we can ‘translate’ user sentiment scores into long term business values.</li></ul><p>This blog post provides insights on how we developed the sentiment model and the metric which aggregates the raw sentiment scores to measure customer sentiment. We leveraged Entropy Balancing (<a href="https://web.stanford.edu/~jhain/Paper/eb.pdf">Hainmueller, 2012</a>) to create a counterfactual group, in order to detect the relationship between the sentiment metric and future revenue. From our study, we show great results of sentiment metric compared to NPS.</p><h3>Sentiment Model Development</h3><p>Sentiment analysis is a great method to gauge consumers’ feeling of a particular product or service. In Airbnb’s customer support, sentiments from our guests and hosts are important signals for us to build better products and services, and ship changes with our community in mind. .</p><p>There are two main challenges we face when developing sentiment models in the customer support domain.</p><ul><li><strong>Skewed</strong><em> </em><strong>Data</strong><em>:</em> Most text inputs are negative in sentiment. Unlike when leaving reviews or messaging with hosts, guests typically contact customer support when they are experiencing an issue with Airbnb.</li><li><strong>Multilingual Input:</strong> More than 14 languages are supported by Airbnb’s customer service. Hosts and guests might be communicating in different languages in the same support ticket.</li></ul><p>To make a sentiment model tailored to our use case, we developed <strong>customized rating guidelines</strong> for customer support messages to make our model aware of domain-specific knowledge and contextual information. Examples below illustrate how the same messages are labelled differently when presented as a CS message versus a Social Media post or App Store review. In the CS domain, we focus on how well customers “think” the issue gets solved as a <em>positive</em> indication and how frustrating they “feel” the issue is as a <em>negative</em> indication.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*WxB1wIGnyMsmpRnn" /></figure><p>We address data skewness via multiple iterations of sampling data for human annotations using ML model and retraining model using newly labelled data. The first round of annotation is performed based on random sampling, while subsequent annotation datasets are stratified on existing model predictions. This leads to a more balanced dataset for training.</p><p>We built and tested two deep learning architectures, both support multilingual inferences:</p><ul><li><a href="https://medium.com/airbnb-engineering/widetext-a-multimodal-deep-learning-framework-31ce2565880c">WIDeText</a> uses a CNN-based architecture to process text channels, while all categorical features are processed through the WIDe channel.</li><li><a href="https://arxiv.org/pdf/1911.02116.pdf">XLM-Roberta</a> uses a transformer-based architecture and leverages a pre-trained multilingual model to have CS messages trained in 14 languages. .</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*otPxo8B6qRoHOtv9" /><figcaption>WIDeText Architecture</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/366/0*95onJYQ62BgRs-gI" /><figcaption>Transformer Architecture</figcaption></figure><p>Transformer-based models achieve slightly better performance on English sentiment analysis and much better performance on less frequently used languages. We chose transformer-based classifier for production inference pipeline.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ld-Sd5q4Iznj9hqT-sVqmQ.png" /></figure><h3>Sentiment Metrics Development</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/946/0*r2iNOyss8cXLq35v" /></figure><p>From the raw sentiment scores, we developed the sentiment metric aiming to optimize the following criteria:</p><ul><li>Strong correlation with NPS</li><li>Sensitivity in experimentation</li><li>Demonstrable causal relationship with long-term business gains</li></ul><h3>Correlation with NPS</h3><p>Despite the limitations of NPS, it is still considered to be the gold-standard of users’ sentiment. It is desirable to make the sentiment metric, now more sensitive and robust, correlates well with NPS. We tested various ways to design the metric by aggregating the message-level raw sentiment scores (e.g., mean, cutoff, slope) to correlate with NPS.</p><p>The two charts below illustrate that sentiment scores and NPS correlate well for guest and host sentiment.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/863/0*ULuPwKX14HSpn6F8" /></figure><p>NPS (green) vs Sentiment Metrics (orange) on guest sample</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/856/0*ECJNOsyJnhRMin8O" /></figure><p>NPS (green) vs Sentiment Metrics (orange) on host sample</p><h3>Sensitivity in Experimentation</h3><p>We revisited two types of past experiments (Scenario 1 and 2) to compare the sensitivity in experimentation between NPS and sentiment metric. The goal was to determine if sentiment metric can provide quicker or more accurate feedback in response to a shift in user sentiment.</p><h4>Scenario 1</h4><p>In the first type of experiments, a new product/service feature hurt the user experience from user research (e.g., the service required extra steps to contact a support agent), yet these features did not show any statistically significant changes in NPS.</p><p>For example, in one of our Interactive Voice Response (IVR) experiments, we successfully reduced contact rate by adding more questions to our automated phone messaging system. However, this also increased friction for users trying to reach customer support. At the end of the experiment, NPS trended negative but was not statistically significant after running for 30 days.</p><p>When we applied sentiment metrics to this experiment, we were able to detect that the change in new sentiment metrics reached statistical significance within 5 days.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*MrcorRynIU3biIsnnkLHCg.png" /></figure><h4>Scenario 2</h4><p>The second type of experiments have features in product/service that hurt the user experience and did impact NPS in a statistically significant way. For example, one of our <a href="https://medium.com/airbnb-engineering/using-chatbots-to-provide-faster-covid-19-community-support-567c97c5c1c9">chatbot </a>experiment decreased both NPS and sentiment metrics but NPS reached statistical significance at day 10, while sentiment metric converged much faster, detecting a shift by day 5.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*X8WX3nicGLPVcCtsQX1Gtg.png" /></figure><h3>Relationship with Long-term Customer Loyalty</h3><p>As a low-frequency marketplace, one of the challenges in Airbnb’s experimentation framework is the difficulty of evaluating long-term customer loyalty such as user churn rate and future booking revenue in product iterations. For customer support teams, our products have an especially large impact on users’ experience. The experimentation should help the decision makers to answer the question “Should we launch a product/service feature if it reduces cost but hurts users’ satisfaction levels?”</p><p>Our third assessment quantifies the future booking impact of customer service using the sentiment score metric.</p><p>It would be very expensive, if possible at all, to run A/B tests with two distinct pools of agents who provide different standards of service to different groups of users. Instead, we use a novel causal inference technique to detect sentiment effects on a user’s future one-year booking revenue with observational data.</p><p>We divide the users into two groups: a <em>control</em> group, with comparatively lower sentiment scores, and a <em>treatment</em> group, with higher, more positive sentiment. We need to control for the fact that these two groups may be fundamentally different from each other in many ways, such as their tolerance to different levels of service quality, loyalty to our platform, and historical booking experience.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/882/0*Yrn1pWAswJu-JX3t" /></figure><p>Analysis workflow of establishing relationship between sentiment score and future revenue</p><p>In order to evaluate more reliable long-term effects of providing good customer service, we established a procedure to: 1) find confounding factors, 2) control these covariates using entropy balancing, and 3) evaluate treatment effects using weighted data.</p><h4>Confounding Variable Selection</h4><p>It took several rounds of iteration before we were able to narrow down the appropriate confounding variables and generate the covariate matrix. We listed all possible confounding variables that should be taken into account. This covered multiple disciplines including user account information, previous booking behaviors, customer contact habits, etc. We then selected related variables that correlated with both sentiment and future booking. For example, users with more previous bookings tend to book more and are more positive when communicating with customer support agents. Finally,<strong> </strong>we cross checked correlations among all variables to remove redundant ones. This helped us to select a short list of confounding variables.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*6KfIB1PS0QaKby0K06fpsA.png" /></figure><h4>Entropy Balancing</h4><p>We use <a href="https://web.stanford.edu/~jhain/Paper/eb.pdf">Entropy Balancing</a> to achieve covariate balance. Entropy Balancing is a maximum entropy reweighting scheme to create balanced samples that satisfy a set of constraints. Here are two most important features in the scheme:</p><p><strong>1. Equalized moments of the covariate distributions. </strong>By assigning weight wi to each sample unit, we want the moments of the covariate distribution (e.g., mean, variance, and skewness) between the treatment and the reweighted control group to be equal (defined in equation 2). A typical balance constraint is formulated with mr containing the rthorder moment of a given variable Xj from the treatment group, whereas the moment functions are specified for the control group as cri(Xij)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*aA3mjawjoqS17c6s6iZ7SA.png" /></figure><p><strong>2. Minimized distance from base weights</strong>. We also want to minimize the. distance between estimated weights wiand base weight qi(usually set as 1/n0 , uniformly distributed) to retain information as much as possible (defined in equation 3).</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GuVv6BTriCaFHg5jEJpQWg.png" /></figure><p>Compared to more frequently used Propensity Score Matching, Entropy Balancing has several proven advantages:</p><ul><li><strong>It is good at balancing results even to high degrees of moments</strong>. In contrast to most other preprocessing methods that involve multiple rounds of manual adjustments on both model and matching until reaching balanced results (which often fails on high dimensional samples), entropy balancing directly searches for weights that can achieve exact covariate balance in finite samples. It significantly improves the balance that can be obtained by other methods, which are validated by an insurance use case <a href="https://www.thieme-connect.de/products/ejournals/abstract/10.1055/a-1009-6634">Matschinger (2019)</a>.</li><li><strong>It retains valuable information without discarding units</strong>. Entropy Balancing retains valuable information by allowing the unit weights to vary smoothly across units, so that we don’t have to throw away any unmatched data.</li><li><strong>It is versatile.</strong> The weights we get can be used to almost any standard estimation of treatment effects such as weighted mean and weighted regression.</li><li><strong>It is computationally inexpensive</strong>. It only takes a couple seconds to get balanced results for over 1M records.</li></ul><p>Evaluating Treatment Effects</p><p>We were able to reach balanced results for all confounding variables after using entropy reweighting:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/374/0*1JfKfSricjCrVLaf" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/378/0*rUOEG3pjW3Qtsbja" /></figure><p>With the weighted results, we found that <strong>guests on Airbnb with higher sentiment (potentially good CS experiences with sentiment metrics &gt;= 0.1) produce significantly more revenue in the subsequent 12 months</strong>. This result can be applied to trade-off analysis whenever we see an opposite result in cost and user CS sentiment score and help us make the right launch decision taking long-term revenue into consideration.</p><h3>Takeaways</h3><p>In this blog post, we provided details of sentiment model development and the framework of assessing sentiment metrics.</p><p>For ML practitioners, the success of a sentiment analysis depends on domain-specific data and annotation guidelines. Our experiments show transformer-based classifiers perform better than CNN-based architectures, especially in less frequently used languages.</p><p>For customer service providers who struggled with the pain of NPS, sentiment analysis has provided promising results to describe customers’ satisfaction levels. If you have user communication text, exploring sentiment analysis may solve the long lasting pain of NPS. However, if you only have phone call recordings, exploring audio to text transcription could be a good start before exploring emotion detection in audio.</p><p>For data analysts and data scientists, the framework of metrics development from a new signal (model output) is reusable: considering many user feedback metrics are either slow or sparse, data professionals can assess the new signals from coverage, sensitivity, and causal relationship with business values. For causal analysis challenges, it is worth spending some time to explore the new Entropy Balancing techniques, which may save you time from Propensity Score Matching.</p><p>If this type of work interests you, check out some of our related positions:</p><p><a href="https://grnh.se/049bfea61us">Senior Data Scientist — Analytics, Support Products</a></p><p><a href="https://grnh.se/36f092141us">Staff Data Architect, Community Support Platform</a></p><p>and more at <a href="https://careers.airbnb.com/">Careers at Airbnb</a>!</p><h3>Acknowledgements</h3><p>Thanks to Zhiying Gu and Lo-hua Yuan for providing important knowledge support on causal inference. Thanks to Mitral Akhtari and Jenny Chen for knowledge sharing on <a href="https://medium.com/airbnb-engineering/how-airbnb-measures-future-value-to-standardize-tradeoffs-3aa99a941ba5">Airbnb’s Future Incremental Value system</a>. We would also like to thank Bo Zeng for sentiment modeling guidance, Mariel Young for the metrics iteration, and Aashima Paul, Evan Lin, and Keke Hu for their hard work on labelling the sentiment data. Last but not least, we appreciate Joy Zhang, Nathan Triplett, and Shijing Yao for their guidance.</p><h3>References:</h3><ol><li>Jens Hainmueller (2012) Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies, <em>Political Analysis</em>, 20:25−46 doi:10.1093/pan/mpr025</li><li>Herbert Matschinger, Dirk Heider, Hans-Helmut König (2020) A Comparison of Matching and Weighting Methods for Causal Inference Based on Routine Health Insurance Data, or: What to do If an RCT is Impossible,<em>Gesundheitswesen, </em>82(S 02): S139-S150 DOI: 10.1055/a-1009–6634</li></ol><p>Further Reading</p><p><a href="https://docs.google.com/document/d/1irNF89bKsTGgjNCmPoJXBVEaNPv00Fl3skwCAjBHK8M/edit">WIDeText: Multimodal Deep Learning Framework, and its application on Room Type Classification</a> goes into the details of Deep learning framework used in Airbnb</p><p><a href="https://ieeexplore.ieee.org/document/8964147">Bighead: A Framework-Agnostic, End-to-End Machine Learning Platform</a> goes into the details of the Airbnb Machine Learning Infrastructure. <em>DSAA</em>’2019</p><p><a href="https://medium.com/airbnb-engineering/how-airbnb-measures-future-value-to-standardize-tradeoffs-3aa99a941ba5">How Airbnb Measures Future Value to Standardize Tradeoffs</a> goes into details of how Airbnb optimizes for long-term decision-making through the propensity score matching model</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=43434dbe199b" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/using-sentiment-score-to-assess-customer-service-quality-43434dbe199b">Using Sentiment Score to Assess Customer Service Quality</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
    </channel>
</rss>