<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[The Airbnb Tech Blog - Medium]]></title>
        <description><![CDATA[Creative engineers and data scientists building a world where you can belong anywhere. http://airbnb.io - Medium]]></description>
        <link>https://medium.com/airbnb-engineering?source=rss----53c7c27702d5---4</link>
        <image>
            <url>https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png</url>
            <title>The Airbnb Tech Blog - Medium</title>
            <link>https://medium.com/airbnb-engineering?source=rss----53c7c27702d5---4</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Thu, 05 May 2022 01:26:08 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/airbnb-engineering" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Continuous Delivery at Airbnb]]></title>
            <link>https://medium.com/airbnb-engineering/continuous-delivery-at-airbnb-6ac042bc7876?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/6ac042bc7876</guid>
            <category><![CDATA[migration]]></category>
            <category><![CDATA[technology]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[deployment]]></category>
            <dc:creator><![CDATA[jens vanderhaeghe]]></dc:creator>
            <pubDate>Fri, 22 Apr 2022 17:09:17 GMT</pubDate>
            <atom:updated>2022-04-22T17:09:17.675Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/939/1*_bvb5WtcQRE3mL-32b0F4g@2x.png" /></figure><p><a href="https://www.linkedin.com/in/jensvanderhaeghe">Jens Vanderhaeghe</a>,<a href="https://www.linkedin.com/in/manishma"> </a><a href="mailto:manish.maheshwari@airbnb.com">Manish Maheshwari</a></p><h3>Introduction</h3><p>Over the years, Airbnb’s tech stack has <a href="https://medium.com/airbnb-engineering/building-services-at-airbnb-part-1-c4c1d8fa811b">shifted</a> from a monolith to 1,000+ services in our service-oriented architecture (SOA). While this migration solved our problems scaling our application architecture, it also introduced an array of new challenges.</p><p>In this blog post we’ll cover the deployment challenges faced on the road to our current architecture and how we’ve solved those problems by adopting Continuous Delivery best practices on top of <a href="https://spinnaker.io/">Spinnaker</a>. We’ll do a deep dive into how we’ve solved such a large scale migration in a short timespan while maintaining developer productivity along the way.</p><h3>From Deployboard to Spinnaker</h3><p><a href="https://medium.com/airbnb-engineering/introducing-deploy-pipelines-to-airbnb-fc804ac2a157">Deployboard</a>, Airbnb’s legacy deployment tool, was designed for a monolith having a few centrally managed pipelines. As we started moving to SOA, thousands of code changes across hundreds of service teams were being deployed. Deployboard was not designed for the SOA architecture, which is characterized by decentralized deployments. We needed something much more templated so that teams could quickly get a standard, best-practice pipeline, rather than start from scratch for every new service. Rather than continuing to build in-house solutions with siloed knowledge, it made the most sense for us to adopt open source solutions built from the ground-up for decentralized, SOA pipelines.</p><p>Spinnaker is proven at Airbnb’s scale, and beyond, by industry peers like Google and Netflix. We believe continuous delivery isn’t a problem unique to Airbnb, and decided we’d benefit from collaborating with the larger community. We chose Spinnaker as the replacement for Deployboard in part because we could bridge functionality gaps by plugging in custom logic easily, without forking the core code. Also, it was important to us that Spinnaker automated canary analysis (ACA), an extremely effective strategy in reducing the blast radius of buggy deployments.</p><h3>Migrating to Spinnaker</h3><p>When deciding to switch rather than evolve, we created a new problem: How do we get a globally distributed team of thousands of engineers working on thousands of services (each with their own deploy pipeline), working under business pressure to continuously improve their product and code base, to change one of the most important tools they depend on for day-to-day productivity.</p><p>We were particularly worried about the “long-tail migration problem,” where we successfully get 80% of the services migrated in the first year or so, but the remaining ones become stuck indefinitely on the old system. Having to operate in such a hybrid mode is costly, and it also is a reliability and even security risk, because the “legacy” systems (including the legacy deploy system) receive less and less attention over time.</p><p>Rather than forcing yet another new tool on our engineers, we came up with a migration strategy based on three pillars: focus on the benefits, automated onboarding, and data.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/732/0*2fjFQ8VIEm7LD_Iz" /><figcaption>The 3 pillars of our migration strategy</figcaption></figure><h4>Focus on Benefits</h4><p>By focusing on the benefits of Spinnaker, we encouraged engineering teams to adopt Spinnaker voluntarily rather than forcing them.</p><p>We started out by manually onboarding a small group of early adopters. We identified a set of services that were prone to causing incidents or had a complicated deployment process. By migrating these services onto Spinnaker and automating their release process using a deployment pipeline with ACA, we were quickly able to demonstrate value. As we onboarded more teams, we iterated on the feature gaps between Deployboard and Spinnaker. These early services served as case studies, proving to both the rest of engineering as well as leadership that adopting an automated and standardized deployment process provides huge benefits.</p><p>These early adopters saw benefits so significant that they ended up becoming evangelists for continuous delivery and Spinnaker, spreading the word to other teams organically.</p><h4>Automated Onboarding</h4><p>As more and more services started adopting Spinnaker, the Continuous Delivery team could no longer keep up with demand. We switched gears and focused on building automated tooling to onboard services to Spinnaker.</p><p>At Airbnb, we store configuration as code <a href="https://www.infoq.com/presentations/airbnb-kubernetes-services/">using a framework called OneTouch</a>. This allows engineers to make changes to the code as well as the infrastructure running their code in a single commit and in the same folder. All infrastructure changes are version controlled.</p><figure><img alt="Example of a codified Spinnaker pipeline" src="https://cdn-images-1.medium.com/max/1024/0*1fytVc5gswBQQYwZ" /><figcaption>Example of a codified Spinnaker pipeline</figcaption></figure><p>Following the OneTouch philosophy, we created an abstraction layer on top of Spinnaker that enables all continuous delivery configuration to be source controlled and managed by our existing tools and processes.</p><p>Today, when new services are created they get Spinnaker integration, including ACA, for free out of the box.</p><h4>Data</h4><p>In addition to focusing on the benefits and making it easy to onboard, we wanted to clearly communicate the value-add of adopting Spinnaker in a data-driven way. We automatically instrumented <a href="https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278bd">Superset</a> dashboards for each service that adopted Spinnaker.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*UaIkauaDzJcPZuOZ" /></figure><p>Example of an instrumented dashboard for a service that has adopted Spinnaker</p><p>Service owners get insight into deployment data like deploy frequency and number of regressions prevented by ACA. Most service owners saw a significant increase in deployment frequency and a marked decrease in production incidents by adopting our new tooling. By arming our users with the right data, they can more easily advocate for the benefits of adopting continuous delivery.</p><h3>Clearing the final hurdle</h3><p>As expected, we eventually hit an inflection point in adoption. Organic adoption slowed as we reached ~85% of deployments being done on Spinnaker.</p><p>Once we hit this point, it was time to switch our strategy again, to adopt the lagging services. Our plan consisted of the following steps.</p><ol><li><strong><em>Stop the bleeding</em></strong> <br>The first thing we did is stop any new service from being deployed with Deployboard. This kept our list of remaining services to adopt static. We did this by giving engineers ample heads-up that this change was coming.</li><li><strong><em>Announce deprecation date + increase friction </em></strong><br>We gradually increased friction when using Deployboard over Spinnaker by adding a banner and warning inside Deployboard. We also instituted an exemption process that would allow us to catch major blockers well before the actual deprecation date without hurting customer experience.</li><li><strong><em>Send out automated PRs for the remaining services. </em></strong><br>To ensure we could also help onboard services where owners are resource constrained we once again leveraged tools like our in-house refactor tool,Refactorator, to do the heavy lifting.</li><li><strong>Deprecation date and post-deprecation follow-up. </strong><br>On deprecation date, we had code in place that blocked any OneTouch deploy from Deployboard. We had some loopholes in place in case there were services that still needed to use Deployboard for emergency reasons. The exemption list allows them to temporary get access to Deployboard. Engineers on the CD team can also still deploy with Deployboard, a simple page to the on-call can quickly help service owners in this case. As of today, the number of those cases remains very minimal given the amount of preparation we’ve done.</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*vXsxUvTvvx0rP7gw" /><figcaption>By adding a banner to Deployboard recommending engineers to adopt Spinnaker, we were able to drive adoption more quickly.</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*-QuiF4QGkdQN1MV_" /><figcaption>Example of an automated Pull Request that migrates a service from Deployboard to Spinnaker with minimal engineering effort.</figcaption></figure><h3>Future Plans and Opportunities</h3><p>Now that we’ve standardized our deployment process, we’re excited to integrate various existing tools at Airbnb into our continuous delivery pipelines. In 2022 and beyond, we are investing resources into integrating automated load testing, providing a way to safely toggle feature flags, and enabling blue/green deployments to facilitate instant rollbacks. More broadly, we see Spinnaker not only as a tool for code deployments, but also for the automation of various manual processes, allowing engineers to orchestrate any arbitrary workload as a pipeline.</p><p>During our migration, we’ve made a ton of modifications, both large and small, to Spinnaker, which is a testament to how flexible the tool is. We will be focused on upgrading to the latest open-source version and are looking forward to contributing some of our changes back to the open-source community.</p><h3>Conclusion</h3><p>In our move from a monolithic architecture to SOA, we needed to rethink the way we do deployments at Airbnb.</p><p>By creating a Continuous Delivery team focused on delivering great tools to safely and easily deploy code, we were able to migrate from our in-house tool, Deployboard, to Spinnaker. This was a very carefully planned and crafted migration. To adopt the majority of services, we focused on the benefits using a data-driven and automated approach to migration.</p><p>As expected, there was a long tail of services that didn’t organically adopt our new tools. We were able to get to the 100% finish line by shifting our strategy towards adding more friction and eventually deprecating our old tool.</p><p>This migration now serves as a blueprint for other infrastructure related migrations at Airbnb and we look forward to continuing iterating on our strategies for bringing better tools to our engineers while maintaining existing productivity and reducing toil.</p><h3>Acknowledgments</h3><p>All of our achievements wouldn’t have been possible without support of the entire Continuous Delivery team: <a href="mailto:jerry.chung@airbnb.com">Jerry Chung</a>, Freddy Chen, Alper Kokmen, Brian Wolfe, <a href="mailto:dion.hagan@airbnb.com">Dion Hagan</a>, Ryan Zelen, Greg Foster, Jens Vanderhaeghe, Mohamed Mohamed, Jake Silver, Manish Maheshwari and Shylaja Ramachandra. The entire Developer Platform organization rallied behind this effort. We’re also grateful to the countless engineers at Airbnb that have adopted Spinnaker over the years and have provided us with valuable feedback. We’d also like to thank all of the people at our peer companies and volunteers who have spent countless hours working on the open source Spinnaker project.</p><p><strong><em>Interested in working at Airbnb? Check out these open roles:</em></strong></p><p><a href="https://careers.airbnb.com/positions/3696687/?gh_src=08eeee991us">Senior/Staff Software Engineer, Developer Infrastructure</a><br><a href="https://careers.airbnb.com/positions/3903900/?gh_src=e91bd0291us">Senior Frontend Infrastructure Engineer, Web Platform</a></p><p><em>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=6ac042bc7876" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/continuous-delivery-at-airbnb-6ac042bc7876">Continuous Delivery at Airbnb</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[My Journey to Airbnb — Florian Andes]]></title>
            <link>https://medium.com/airbnb-engineering/my-journey-to-airbnb-florian-andes-5080685262d3?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/5080685262d3</guid>
            <category><![CDATA[tech]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[business-development]]></category>
            <category><![CDATA[people]]></category>
            <category><![CDATA[program-management]]></category>
            <dc:creator><![CDATA[AirbnbEng]]></dc:creator>
            <pubDate>Tue, 12 Apr 2022 17:56:39 GMT</pubDate>
            <atom:updated>2022-04-12T17:56:06.942Z</atom:updated>
            <content:encoded><![CDATA[<h3>My Journey to Airbnb — Florian Andes</h3><p>From building airplanes to Staff Technical Program Manager at Airbnb</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*gHm8C-tJ3j2bavkT" /></figure><p><a href="https://www.linkedin.com/in/floandes/"><em>Florian Andes</em></a><em> is a Staff Technical Program Manager at Airbnb. He has over 10 years of experience that spans the software, manufacturing, and strategy consulting industry. He studied in Frankfurt, London, Singapore, and Boston, where he received a bachelor’s and MBA degree in Business and Entrepreneurship.</em></p><p><em>Though it can be hard and intimidating to find your place in the “big tech” industry in Silicon Valley, Florian has relied on curiosity and openness to establish a successful career at Airbnb. Read on for Florian’s own words on working at the intersection of business and software engineering, transferring to the US and scaling tech programs from zero to 10x for Airbnb, and more.</em></p><h3>A global citizen finding a home for his career</h3><p>Many years ago, Airbnb had a tagline that really inspired me: “Don’t Go There. Live There.” I’ve tried to embrace that idea as much as I could. I’ve had the chance to live and work in several different countries — Germany, the UK, Singapore, China, and now the US, where I’m currently based in San Francisco.</p><p>I grew up in Southern Germany, specifically a smaller city called Ulm (which is famous for Albert Einstein, and for having the tallest church building in the world). Growing up, my dad was a great inspiration for me. In his twenties, he started his own business. His journey taught me a lot about perseverance, dedication, and visionary thinking. I’m still inspired by how he pioneered the intersection of hardware and software engineering in the very early days of computers.</p><p>In my career, I’ve broadly moved from hardware to software engineering across different industries. (My first job was folding pizza boxes at a friend’s restaurant.) In Germany, there’s a large hardware and manufacturing presence: cars, industrial machines, and appliances in general. I started off at Airbus, building airplanes with advanced plastics and fiber materials, and then moved into the automotive industry and strategy consulting in the mobility space.</p><p>Along the way, I became really interested in software companies and internet technology. In Singapore, where I studied for my MBA, I joined a fast-growing tech startup to manage their partnerships across APAC. I loved it. I was flying around Southeast Asia to speak at startup events, pitch to investors, explain the idea and what problem we were solving — it was all very exciting to me.</p><p>I ended up attending a fireside chat with Mike Curtis, Airbnb’s VP of Engineering at that time, hosted by a local startup co-working space, where he shared lessons he picked up on his journey. I was inspired and ended up connecting with Mike and some folks from Airbnb after the talk, and the opportunity for me to join Airbnb grew organically from there.</p><h3>Pioneering projects at the intersection of tech and business</h3><p>TPMs are involved in every major release at Airbnb. Some TPMs are more product and business-focused (that’s me), and others are more infrastructure and platform-oriented. The potential for impact is high because you’re often very close to engineering leaders. You have conversations with the CTO, and many senior leaders in engineering — and on our product teams, as well.</p><p>I’ve been with Airbnb now for more than five years, and over time, my work has expanded in technical depth and also in breadth. I started out with a focus on business operations and strategy in EMEA (based in Berlin), then transferred to the US to build out an entirely new API program from scratch, and I’m now overseeing all technical programs related to hosting products at Airbnb. It’s a really interesting area that bridges the gap between the tech (engineering, product, data science, and design) and commercial parts of our business.</p><p>There are two projects I have been involved in recently that demonstrate the breadth of our programs. One is the adoption of our <a href="https://airbnb.design/building-a-visual-language/">Design Language System</a> (DLS), a repository of prebuilt components that designers and engineers can reuse instead of building something new. So whenever an engineer at Airbnb has to implement a button, they don’t have to build this from scratch. Another is reducing our <a href="https://medium.com/airbnb-engineering/our-journey-towards-cloud-efficiency-9c02ba04ade8">AWS costs</a>. We introduced a new attribution model at Airbnb that directly associates AWS costs to different teams, and my role was monitoring our organization’s consumption and championing a lot of cultural change to think about AWS cost-efficiency whenever we build products.</p><h3>Strategies for remote program management</h3><p>Recently a big focus has been, naturally, keeping teams engaged and collaborative during remote work. Communicating a clear program vision and using frameworks to keep projects on track are two strategies that are more important than ever.</p><p>One other thing that I consider critical is celebrating wins and key milestones. Before, when we were in the office, it was much easier to celebrate big wins. At Airbnb, we have a tool where you can send appreciation to others. I use it all the time, because when I work with multiple stakeholders across design, product, engineering, and QA, people are generally contributing at different stages. When the project ends, you might not have this big forum anymore, because most people have moved on already. But it’s important to still give credit to the work that everyone contributed along the way and make sure their managers have visibility into their contributions.</p><h3>What makes the TPM role unique at Airbnb</h3><p>TPM is relatively new as a function itself, and every company approaches it slightly differently. Even at Airbnb, it’s continuously evolving and progressing. One thing that’s always the case, though, is that TPMs need to use influence to lead programs, teams, and products — without exercising direct authority. As a TPM, you have to champion ideas, be a great communicator, and work with your partners to align priorities and push projects forward.</p><p>You don’t have to study software engineering to be a technical program manager — I think you need to show that you have the ability to grow and learn on the technical side, and this can happen before the job or on the job. For instance, at first I didn’t have much context about AWS optimization, frontend design language systems, or open source, but people at Airbnb are super open to sharing knowledge which allowed me to quickly onboard and take on these programs. You just need to be curious and open to learn.</p><p>I love working at Airbnb because of the people and the mission-driven nature of the company. And I think what makes being a TPM at Airbnb extremely unique is that there’s still a lot of “greenfield” areas and unexplored territory, where you can really help define a new strategy and vision.</p><p><em>Interested in joining Airbnb as a TPM? Check out these open roles:</em></p><p><a href="https://careers.airbnb.com/positions/4024213/?gh_src=6b8b81e61us">Senior TPM, Guest and Host Technology</a></p><p><a href="https://careers.airbnb.com/positions/3955056/?gh_src=8a794a6e1us">Staff TPM, Insurance Platform</a></p><p><a href="https://careers.airbnb.com/positions/3651016/?gh_src=77ab28041us">Staff TPM, Infrastructure Regionalization</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5080685262d3" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/my-journey-to-airbnb-florian-andes-5080685262d3">My Journey to Airbnb — Florian Andes</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Hacking Human Connection: The Story of Awedience]]></title>
            <link>https://medium.com/airbnb-engineering/hacking-human-connection-the-story-of-awedience-ebf66ee6af0e?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/ebf66ee6af0e</guid>
            <category><![CDATA[connection]]></category>
            <category><![CDATA[meetings]]></category>
            <category><![CDATA[pandemic]]></category>
            <category><![CDATA[virtual-events]]></category>
            <category><![CDATA[engineering]]></category>
            <dc:creator><![CDATA[Avand Amiri]]></dc:creator>
            <pubDate>Tue, 05 Apr 2022 17:29:35 GMT</pubDate>
            <atom:updated>2022-04-11T22:22:11.531Z</atom:updated>
            <content:encoded><![CDATA[<h4>How a home-grown product helps Airbnb employees feel more connected during solitary times</h4><figure><img alt="A screenshot of Awedience during an all-company meeting. Brian Chesky, CEO, is in the center and is surrounded by thousands of employees represented by tiny squares. Each square is either a picture of the employee, a color, or a letter that people have arranged to spell words or draw shapes. Emojis are captured emerging from some of the seats." src="https://cdn-images-1.medium.com/max/1024/1*u9pnag1uWfgwnT8tv42I1g.jpeg" /></figure><h3>Introduction</h3><p>This is the story of how Airbnb employees stayed connected during a time they had never felt more apart. In this post, you’ll learn how an idea turned into an internal product that is now a core part of how Airbnb operates.</p><p>When you walk through the doors of an Airbnb office, you feel an energy that’s both inspiring and intimidating. After more than five years with the company, I explain this duality as Airbnb being both incredibly entrepreneurial and aspirational.</p><p>Airbnb company meetings are no different. Brian Chesky and his team keep our all-hands meetings exciting. I know what you’re thinking: “exciting meetings?!” But in all seriousness our all-hands are not just informative, they’re spectacular. Whether it’s drinking a smoothie of dehydrated bugs in solidarity with Engineering or eating spicy chicken wings in a Hot Ones-style Q&amp;A, our meetings are informative, energizing, and engaging. In somber moments, they’re human and heartfelt.</p><p>The pandemic changed that. Feeling connected to the presenter, feeling connected to our peers, or feeling the presenter’s connection to the audience all vanished. Instead, we each separately watched the presenter streaming through a 16:9 rectangle on our laptops. Other people were watching concurrently (one could assume based on the invite) but it couldn’t be <em>felt</em>. Inspired, I set out to solve this, wondering,“<a href="https://en.wikipedia.org/wiki/The_Six_Million_Dollar_Man">we have the technology</a>, why can’t we see and interact with everyone watching live?”</p><h3>Inspiration</h3><p>It’s impossible to know under which circumstances inspiration will find us, and in hindsight it seems perfectly planned.</p><p>Airbnb is a community based on connection and belonging, which is the reason so many of us came to work here. However, in March of 2020, as the spread of COVID-19 forced us to shelter in place, we struggled to find ways to preserve those traits within our company culture. What it meant to feel connected to the world and to each other was being redefined by emojis over video. Video chat helps us stay in communication, but it’s <a href="https://www.youtube.com/watch?v=DYu_bGbZiiQ">comically clunky</a>, dry, and lifeless. If these technologies feel contrived it’s because they are. We all know what an authentic human connection actually feels like, and it’s not that.</p><p>For almost two years before the pandemic hit, I volunteered to help produce Airbnb’s quarterly engineering all-hands. Unbeknownst to me, I was actually studying the question, “how does one make people feel more connected?” Whether it meant hosting an orca-themed relay race across our Portland, Seattle, and San Francisco offices, or projecting live chat in auditoriums to make the audience more engaged, I had been finding ways to foster human connection.</p><figure><img alt="Engineers dressed up in costumes working in pairs at laptops. Ping pong balls are being throw at them from the crowd, while they try to focus on solving engineering problems on the computers." src="https://cdn-images-1.medium.com/max/1024/1*SIXAHtcfgeFICxZ6B11UwA.gif" /><figcaption>Pairs of engineers complete programming challenges, while being pelted with ping pong balls by the audience. This was just one of the many ridiculous segments of Nerds@, the engineering all-hands meeting I voluntarily produced for two years.</figcaption></figure><p>Isolated at home with all these insights into event production, it’s not surprising that, while I watched our CEO, Brian Chesky, address thousands of employees via live stream, my attention drifted to the little number in the top right corner that showed how many other people were watching. These were my colleagues, my friends — some of the most talented people in the world. In our isolation, the only affordance that existed to capture our experience of watching this live stream together was an aggregate count. Instagram and YouTube allowed people to express themselves with emojis and comments during live broadcasts. Internally, we could not.</p><figure><img alt="Photos of various employees at-home workstations. Some photos are laptops on a desk or coffee table. Others are projected onto a TV in a living room. Two of the photos feature pets in the background." src="https://cdn-images-1.medium.com/max/1024/1*t-XAOqp7jvfTDsFhQpSejQ.png" /><figcaption>A look at life before Awedience: everyone watching the same stream at home alone, with the exception of some furry pals.</figcaption></figure><p>An idea started to emerge: supplement the live stream with small, thumbnail-sized videos of all the viewers’ webcams and capture audience sentiment with emojis. It seemed simple enough.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*rat4XcYbupe-pho3KM1wqw.jpeg" /><figcaption>The original sketch. Simple, right?</figcaption></figure><p>Yet even this concept proved untenable. I had never built a fully real-time web application and would likely need months to figure out the webcam piece. I didn’t have months. I was only willing to dedicate a few days to see if this idea had merit.</p><p><a href="https://entrepreneurshandbook.co/how-airbnb-founders-sold-cereal-to-keep-their-dream-alive-d44223a9bdab">Cereal Entrepreneurs</a> will attest that ideas are cheap — nobody copies ideas. Only <em>proven</em> ideas get copied, and this idea was definitely not proven. So I started to collaborate with some of my peers and <a href="https://www.linkedin.com/in/stepan-parunashvili-65698932">Stepan Parunashvili</a>, helped us get the ball rolling. “Punt on video for now,” he said, “start with profile pictures from our company directory. Firebase can handle all the real-time stuff, and we already have an internal authentication service. Boom!”</p><p>Stepan continued to offer his support with the initial infrastructure. We needed a name and thought about it for all of a minute. This product was all about the “audience” and “aww” is one sound an audience makes when they’re experiencing something together. Inspiring “awe” was also part of the motivation of this work so we decided on “Awedience.”</p><p>Within a few hours, Stepan had the scaffolding complete. People could sign in and <a href="https://en.wikipedia.org/wiki/%22Hello,_World!%22_program">“hello world”</a> with other users. Our authentication service played gatekeeper, guaranteeing that the application would have access to an employee’s LDAP username after they signed in. That username enabled me to load a profile picture from our company directory. <a href="https://firebase.google.com/docs/database/">Firebase</a> served as the realtime database, and React sat right on top of it, bound (almost directly) to Firebase events. I could finally focus on my specialty, UI and UX. With an iframe embedded front and center, the UI naturally formed a U-shaped auditorium with virtual seats. When you clicked a seat, your picture would appear, and as you reacted, emojis would float out of your seat for everyone to see. You could also write short messages and they would pop out of your seat too, simulating shouts to the crowd.</p><p>We had built something. Now, would anyone care?</p><h3>Growth</h3><p>Attention is an incredibly valuable resource and there are lots of ways to get it. Attention is commonly bought. Attention can be diverted from other channels. It can even be stolen.</p><p>But attention can also be <em>earned</em>. When people <em>love</em> a product, it not only has true staying power but will grow organically. Therefore, one way to see if people love something new is to say nothing and observe.</p><p>I invited close colleagues to try Awedience for an all-hands to see what would happen. Intuitively, they took a seat, started reacting, and used it throughout the meeting. The feedback was <a href="https://sive.rs/hellyeah">overwhelmingly positive</a>. Awedience didn’t do much but what it did do, it did well enough.</p><figure><img alt="A screenshot of Airbnb’s Slack while Audience was being used for the first time. Some messages say “we’re sitting together,” “love this feature it’s so cute,” “this is the coolest,” and “I noticed you sat next to me.”" src="https://cdn-images-1.medium.com/max/1024/1*DPnN31xW0LgGXbbysUO_fw.png" /><figcaption>A glimpse into our company Slack: first reactions to Awedience at Airbnb.</figcaption></figure><p>At the time, Brian hosted all-company Q&amp;As weekly. I created a calendar event alongside the all-company one with an alternative URL and only invited people that had previously used Awedience. Within a few months, Awedience was so popular that it was offered as a secondary option in the official calendar invites.</p><p>With the increased popularity, it was hard to support Awedience on nights and weekends. I asked my team for time to redirect my focus to Awedience for a few months, and they were supportive. The only request was that I figure out the product’s future by the end of that time and not leave things open-ended. Would it become a part of <a href="https://www.airbnb.com/s/experiences/online">Online Experiences</a>? Would it become a part of another team’s roadmap? We even speculated that it could be a completely new line of business.</p><p>While it was tempting to keep adding functionality, resourcefulness was now the name of the game. Awedience was crashing during peak moments so performance was and still is the most important feature. Before we implemented throttling, we were binding reactions directly to our app state, which triggered a deluge of re-renders:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/9cc2af478f93a52dbd1e74dfafeb2e11/href">https://medium.com/media/9cc2af478f93a52dbd1e74dfafeb2e11/href</a></iframe><p>A crude <em>batchedThrottle</em> function reduced renders when users mashed an emoji button:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/e7477b5316cc110ea5df6409c5d86694/href">https://medium.com/media/e7477b5316cc110ea5df6409c5d86694/href</a></iframe><p>Later, additional performance gains were found by detaching the React UI from Firebase real-time callbacks. Eventually, reactions would be managed natively without React at all:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/de71ca2d02402ba3df6f5db2228c4141/href">https://medium.com/media/de71ca2d02402ba3df6f5db2228c4141/href</a></iframe><p>There were more affordances I wanted to explore. At sporting events, attendees often hold up signs, flags, or even paint things on their bodies to spell out a message. Replicating this in Awedience was a huge hit. Rather than a profile picture, attendees could now pick a color, letter, or a portion of a graphic to display from their seat. People show up early and coordinate amongst themselves to spell out messages to represent their team, city, or the company. The result is magical. Awedience didn’t make it easy to tell your neighbor to change their seat picture. People were going out of their way to coordinate with one another. Connection between colleagues was happening organically and it was thrilling to see.</p><figure><img alt="A screenshot of Awedience during an all-company meeting. Brian Chesky, CEO, is in the center and is surrounded by thousands of employees represented by tiny squares. The squares spell out words like “insurance,” “human,” or “trust.” There are also a few Airbnb logos being drawn out in 5x5 tiles." src="https://cdn-images-1.medium.com/max/1024/1*DsAVOD_cZgUwAP39X6qQZQ.jpeg" /><figcaption>An earlier version of Awedience where people were spelling words, representing their teams, cities, and the company. Or the CEO’s face.</figcaption></figure><p>Making sure there were enough seats for everyone was also a challenge. Too few seats and some people can’t participate; too many and the auditorium feels empty. To handle this, Awedience does something its skeuomorphic counterpart can’t do: adding seats as needed. This feature felt vital for a product built at a company so focused on belonging. Later, we would improve on this feature by increasing seating density such that almost 1,000 people are visible “above the fold.”</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*kwLwo5MNpcT8HLk8xq3L7g.gif" /><figcaption>Adding rows of seats to the bottom worked for a long time but limited users from seeing everyone at once. It took the addition of virtual aisles to afford seats being added horizontally without compromising user-generated seat art.</figcaption></figure><p>Self-service features were also prioritized. Brian’s staff immediately wanted to know what content was spurring engagement — a question they hadn’t been able to answer since going remote. Cumulative data from each event was piped into a graphing library for quick and dirty analytics. Similarly, our video production team wanted to be able to create and edit auditoriums without relying on me so that self-service tooling came as well.</p><figure><img alt="A stacked line graph of emojis over time. One line, applause, for example goes up to over 300 reactions for a moment. Later, hearts, spike to nearly 150. Each emoji has its own usage graphed on the chart." src="https://cdn-images-1.medium.com/max/1024/1*ceUehJwN6__G7Q_OIQoZrA.png" /><figcaption>Awedience helps presenters understand exactly which parts of their presentation landed for their audience.</figcaption></figure><p>Later, during a hackathon, we even created applause sound effects that naturally scale up from the sound of a few hands clapping to an uproar based on audience engagement.</p><figure><a href="https://video.airbnb.com/media/t/1_o3egj5jk"><img alt="A video demo of Awedio, in which you can see Brian Chesky being interviewed on CBS while members of the audience applause around him. In addition to seeing the applause emojis rise from the audience, you can also hear the applause generated by the software." src="https://cdn-images-1.medium.com/max/1024/1*N_NlPojNdwUIK83bev6Rug.jpeg" /></a><figcaption>Awedio allows you to hear the audience’s applause reactions.</figcaption></figure><h3>Moments</h3><p>Awedience made Airbnb feel like Airbnb again. There’s now a place where you can see everyone and feel connected to them. It’s become home to celebratory moments and a place where we can sit alongside one another during somber ones.</p><p>When Airbnb announced a cut back to our workforce, there was an all-hands scheduled to honor and appreciate the employees who were leaving. However, with VPN access cut to roughly 2,000 soon-to-be alumni, Awedience was suddenly only accessible to the spared employees. Resident security guru, <a href="https://www.linkedin.com/in/keeleysam">Sam Keeley</a>, and I committed to making Awedience accessible outside of VPN and almost overnight switched authentication to Google IAP. When the founders addressed the company, they invited a standing ovation for our departing peers and Awedience obliged. It’s hard to imagine what kind of impersonal and solitary send-off we would have had without Awedience.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*znVI-1UvXbpPEn9WClZzJw.gif" /><figcaption>Hundreds of employees joined our founders in a virtual standing ovation for the members of our team that were let go as a result of the pandemic cut backs.</figcaption></figure><p>In May, in the wake of social action around George Floyd’s murder, the company met to address the Black Lives Matter movement. At the end of this meeting, Brian invited the company to take an 8 minute and 46 second moment of silence.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*-7x_Yi1B3DiKxQTq6yv_aA.gif" /><figcaption>Employees join in a somber yet moving virtual moment of silence for George Floyd.</figcaption></figure><h3>Conclusion</h3><p>At Airbnb, Awedience is here to stay and now receives ongoing support and maintenance. In collaboration with our Employee Experience team, we found a home where it would make sense long term. In fact, if this is the kind of work you find interesting, you may even consider joining our team to help us build internal tools to foster connection — <a href="https://careers.airbnb.com/positions/">we’re hiring</a>!</p><p>I feel fortunate to work for a company that creates space to bring these types of projects to life. Airbnb is an inspiring place — the combination and culmination of a rigorous entrepreneurial spirit and an ongoing commitment to outdo the status quo. That’s the type of environment you need for ideas like Awedience to flourish.</p><p>Awedience is more than just a triumph of passion and creativity. The spark of the idea was just that: a spark. In the words of <a href="https://twitter.com/richardbranson/status/264067714266587136">Richard Branson</a>, “opportunities are like the buses — there’s always one coming.” Without the help and support of many amazingly talented colleagues, there would literally be nothing to write about.</p><p>What makes Awedience awesome is the people. Big ideas are rarely the consequence of one person’s ideas or effort. It takes a lot of people to do incredible things.</p><h3>Acknowledgements</h3><p>To Stepan Parunashvili for fueling the fire and bootstrapping the infrastructure that got Awedience going. Without you, it would not have been possible. Thank you.</p><p>To Sam Keeley for enabling and evolving Awedience access for the entire company.</p><p>To Joe Gebbia for creating some air space for Awedience to grow and evolve.</p><p>To Byoung Bae, Allison Frelinger, Darrick Brown, and Judd Antin of my former team for taking a gamble on Awedience with me.</p><p>To Liz Kleinman and Beth Axelrod for creating a role for me to continue this work.</p><p>To Shawdi Ilbagian Hahn, Dave O’Neill, Kylie McQuain, Kelly Bechtel, Kate Walsh, Benny Etienne, Carrie Kissell, Alyce Thompson, John Lawrence, and Samantha Eaton for your collaboration and partnership in keeping the company engaged and connected.</p><p>To Cory Boldt, Steven McNellie, Garrett McGrath, Alex Lacayo, John Espey, and Scott Ethersmith for your help and creativity on the technical productions.</p><p>To Jenna Cushner, Ortal Yahdav, Lucille Hua, Christian Williams, Shawn Terasaki, Brian Wallerstein, Ben Muschol, Mike Fowler, Jason Goodman, Caty Kobe, Joe Lencioni, Nicolas Haunold, Christian Baker, Alan Sun, and Jacqui Watts for your early contributions and feedback.</p><p>To Kevin Swint, Danielle Zloto, Christine Berry, Federica Petruccio, and Consuelo Hernandez for going above and beyond to try Awedience with Online Experiences and the powerful insights that were created as a result.</p><p>To Nicholas Roth, Izzy Rattner, Jonathan Lieberman, Stephen Gikow, Steve Flanders, Lonya Breitel, Alan Shum, Brian Savage, Veronica Mariano, Allie Hastings, Alica Del Valle, Rajiv Patel, and Emily Bullis for your legal support in protecting Awedience’s intellectual property and making external partnerships possible.</p><p>To Sarah Baker for always rallying people together to create seat artwork.</p><p>To Gaurav Mathur, Hope Eckert, Sean Abraham, Jessie Li, Vaithiyanathan Sundaram, Andy Yasutake, Virginia Vickery, Jonathan Rahmani, Andrew Pariser, Sunakshi Kapoor, Diane Ko, Biki Berry, Francisco Diaz, Erik Ritter, Tony Gamboa, Mohsen Azimi, Bruce Paul, Omari Dixon, Sonia Anderson, CJ Cipriano, Chihwei Yeh, Arie Van Antwerp, Victor De Souza, Sam Shadwell, Deanna Bjorkquist, Jenna Cushner, Richard Kirk, Jake Silver, Alex Rosenblatt, David He, LA Logan, Ryan Booth, Pistachio Matt, Melanie Cebula, Brian Morearty, and Victor Caruso for your participation and support!</p><p>To Stephanie Wei, Micah Roumasset, Ryland Harris, Waylon Janowiak, and Ben Arnon for your willingness to try Awedience outside of Airbnb.</p><p>To Jerry Chabolla, Nicholas Schell, Ryan Jespersen, Sergio Garcia Murillo, Wes Dagget, and the entire team at Millicast for enabling real-time streaming.</p><p>To Brett Bukowski, Cara Moyer, Nicki Williams, Dylan Hurd, and Lauren Mackevich for encouragement and support in writing this blog post.</p><p>And lastly to Danee Chavez for powering the light bulb. 💡</p><p><strong>Interested in working at Airbnb? Check out these open roles:</strong></p><p><a href="https://careers.airbnb.com/positions/3714489/">Senior Software Engineer, Airfam Products</a></p><p><a href="https://careers.airbnb.com/positions/3955056/">Staff Technical Program Manager, Insurance Platform</a></p><p><a href="https://careers.airbnb.com/positions/3988445/">Staff Automation Engineer, BizTech Global Ops</a></p><p><a href="https://careers.airbnb.com/positions/4003012/">Operations Engineer</a></p><p><em>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ebf66ee6af0e" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/hacking-human-connection-the-story-of-awedience-ebf66ee6af0e">Hacking Human Connection: The Story of Awedience</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Measuring Latency Overhead with Own Time]]></title>
            <link>https://medium.com/airbnb-engineering/measuring-latency-overhead-with-own-time-f4373f586ca?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/f4373f586ca</guid>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[graphql]]></category>
            <category><![CDATA[service-mesh]]></category>
            <category><![CDATA[data]]></category>
            <category><![CDATA[technology]]></category>
            <dc:creator><![CDATA[Jimmy O’Neill]]></dc:creator>
            <pubDate>Mon, 21 Mar 2022 20:53:37 GMT</pubDate>
            <atom:updated>2022-03-21T23:05:47.028Z</atom:updated>
            <content:encoded><![CDATA[<p>by: <a href="https://www.linkedin.com/in/jimmyoneill">Jimmy O’Neill</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*JQ6ZtmHuSu-86FXV1i7Lmg.jpeg" /></figure><h4>A new metric to quantify the latency overhead of our Viaduct framework</h4><p><a href="https://medium.com/airbnb-engineering/taming-service-oriented-architecture-using-a-data-oriented-service-mesh-da771a841344">Viaduct</a>, a GraphQL-based data-oriented service mesh, is Airbnb’s paved road solution for fetching internal data and serving public-facing API requests. As a unified data access layer, the Viaduct framework handles high throughput and is capable of dynamically routing to hundreds of downstream destinations when executing arbitrary GraphQL queries.</p><h3>Performance Challenges in Viaduct</h3><p>Viaduct’s role as a data access layer puts it in the critical path of most activity on Airbnb. This makes runtime performance of utmost importance as overhead in the framework will apply universally and can have a multiplicative effect. At the same time, Viaduct accepts arbitrary queries against the unified data graph. In practice, this amounts to many thousands of heterogeneous queries in production, each of which is capable of making an arbitrary number of downstream and often concurrent calls during the course of query execution.</p><p>This presented a challenge for us. Runtime overhead in Viaduct is crucial for us to monitor and improve, but we did not have a good measure for it. Metrics on end-to-end query latencies are confounded by the performance of downstream services, making it difficult to accurately judge the effect of a performance intervention in Viaduct. We needed a metric that <em>isolates </em>the performance impact of Viaduct changes from the performance impact of downstream services.</p><h3>Defining Own Time</h3><p>To do this, we created a metric called “own time”. Own time measures the portion of a request’s wall-clock time that occurs when there are zero downstream requests in flight. The following is pseudocode to compute own time given a root request time span and a set of downstream fetch time spans:</p><pre>def calculateOwnTime(rootSpan, fetchSpans):<br>  ownTime = 0<br>  maxEndTimeSoFar = rootSpan.startTime<br>  sortedFetchSpans = fetchSpans sorted by increasing start-time<br>  for fetchSpan in sortedFetchSpans:<br>    if (maxEndTimeSoFar &lt; fetchSpan.startTime)<br>      ownTime += (fetchSpan.startTime - maxEndTimeSoFar)<br>    maxEndTimeSoFar = max(maxEndTimeSoFar, fetchSpan.endTime)<br>    ownTime += (rootSpan.endTime - maxEndTimeSoFar)<br>  return ownTime</pre><p>The own time metric allows us to focus on aspects of Viaduct’s overhead that are clearly unrelated to downstream service dependencies. While it does not capture <em>all </em>aspects of Viaduct’s overhead, we’ve found it captures enough to be a valuable indicator of overhead costs.</p><p><strong>Examples</strong></p><p>In the trivial case where all downstream calls are made serially, own time is a simple span difference of the root operation span and the sum of the downstream time spans.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*-fwKbBCLNP-GkWJP" /></figure><p>When there are multiple downstream calls, they may be made fully or partially in parallel.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*DVUD3CPpix-Kt6h3" /></figure><p>In this example, the downstream calls happen partially in parallel, and the resulting own time value doesn’t include the time that any downstream request is in flight, parallel or not.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ezhwxOXWnSHMf1wj" /></figure><h3>Identifying and Reducing Runtime Latency</h3><p><strong>Measuring the influence of CPU vs. I/O on request latency</strong></p><p>Normalizing operation own time by overall operation latency gives us an estimate of how CPU-bound vs. I/O-bound an operation is. We call this the “own time ratio” of a query. For example, the Viaduct operation graphed below had an own time ratio of 20%, indicating that 20% of the request runtime in Viaduct was spent with no downstream request in flight. After deploying an internal Viaduct performance improvement, this operation’s own time ratio dropped to 17%, since Viaduct overhead improved while downstream performance remained constant.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*wy6PADUW1fd6-F-X" /><figcaption>This graph shows a day-over-day reduction in own time ratio for a Viaduct operation after a runtime overhead improvement was deployed.</figcaption></figure><p>A low own time ratio for an operation indicates that the biggest overall latency gains will likely be found by optimizing downstream services, not Viaduct. A high own time ratio indicates that the meaningful latency gains can come from optimizing internal Viaduct runtime for the operation. When making such optimizations for the sake of one operation, we can also use own time ratios across all operations, and especially low-ratio ones, to ensure we aren’t introducing a regression more broadly.</p><p><strong>Quantifying the impact of query size on runtime overhead</strong></p><p>Viaduct users reported that large queries were running slower than expected, attributing the slow execution to Viaduct overhead. Before own time, we had no metrics to assess such reports. After introducing own time, we had a starting point, but we needed to refine the metric further for this use case.</p><p>One would expect own time to increase as the number of fields returned by an operation increases. But was that a reasonable expectation? We found that normalizing own time by the count of fields returned by an operation yields a metric that more usefully indicates, across a heterogeneous set of operations, when own time is excessive. We defined field count to include both object fields and individual array elements.</p><p>The following graph shows that there is indeed an overall relationship between own time and field count across our set of operations, as well as some outliers that have unusually high own-time-to-field-count ratios.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*MoOIoSyyD2fDoUog" /><figcaption>This chart plots the number of fields resolved against own time for unique GraphQL operations.</figcaption></figure><p>This relationship between field count and own time encouraged us to focus on framework logic that runs on every field for all operations, rather than other parts of the codebase. Through some CPU profiling, we were able to quickly identify bottlenecks. One resulting improvement was a change to our multithreading model for field execution, which decreased own time for all operations by 25%.</p><p><strong>Quantifying the impact of internal caching on runtime overhead</strong></p><p>Viaduct saw another performance issue. For some operations, latency appeared to vary an unusual amount, even between identical requests. Here again, we used own time to guide our investigation into root causes.</p><p>Viaduct relies on a number of internal caches to ensure that execution is fast, such as a cache for parsed and validated GraphQL documents. Own time metrics indicated that Viaduct runtime overhead, not downstream service dependencies, was causing the variance in latencies. We theorized that cache misses were the culprit. To test this theory, we instrumented our caches to report whether any lookup miss occurred during an operation execution and attached this hit/miss status to our own time metric output. This allowed us to report on own time by cache hit/miss status on a per-cache, per-operation basis.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*E3j_g3qCzFxhw_IN" /></figure><p>Adding this information to own time allowed us to both confirm our theory and quantify the potential benefit of implementing a solution, such as additional cache warming or moving in-memory caches to distributed caches, prior to committing actual engineering resources. Migrating the in-memory cache that stores the validation state of GraphQL documents to a distributed cache reduced miss rates. This had a significant impact on tail latencies, especially for low QPS operations that were more likely to encounter cold cache states.</p><h3>Setting Runtime Overhead Goals</h3><p>Establishing the own time metric normalized by field count ended up being a great way to account for changes in query patterns. Thus, we now use this metric, aggregated across all operations, to set framework-level performance targets that are isolated from changes in client query patterns. In particular, after measuring the base rate of normalized own time at the beginning of a quarter, we set a goal to improve normalized own time by a specific percentage quarter-over-quarter.</p><p>We also use this metric, aggregated on a per-operation basis, to let operation owners know how their operation overhead compares to the rest of the system.</p><h3>Integrating Own Time Into The Release Cycle</h3><p>To quantify the runtime performance impact of a change, we can set up experiments where two staged control and treatment applications receive identical production traffic replay. We can then graph the difference in own time between them. This allows us to quantify the impact of various framework interventions on runtime overhead and measure each intervention’s impact against our performance goals.</p><p>While replay experiments help us to assess the potential runtime improvements of a change on a limited set of use cases, narrowly-targeted optimizations can lead to broader performance regressions may still happen accidentally. To guard against such regressions, we leverage an automated canary analysis process before deployment. A canary instance and baseline instance receive identical production replay traffic for a period of time, and large discrepancies between them can automatically stop the deployment process. By inspecting the own time difference between the canary and baseline instances, we can identify unexpected performance regressions prior to the regression making it to production.</p><p>In addition to automated canary analysis, graphing day-over-day, week-over-week and month-over-month own time in production shows us long-term isolated performance trends and allows us to bisect any regressions that make it to production.</p><h3>Limitations and Future Work</h3><p>By ignoring what Viaduct does during all downstream calls, own time does not account for possible optimizations to a call pattern of the downstream requests themselves. For example, a request execution may be sped up by increasing concurrency of downstream calls or removing some calls altogether.</p><p>Although own time gives a measure of wall-clock runtime service overhead, it does not say <em>what</em><strong> </strong>is causing the overhead or how to best improve it, which will vary across operations in a GraphQL server. However, tracking downstream request spans in memory provides baseline data that can be enriched with other metadata and further filtered to measure the contribution of application-specific activity to own time.</p><p>Tracking down the root cause of unexpected own time changes or understanding why an operation is an own time outlier requires manual inspection and sometimes additional one-off measurements, which take valuable engineering time. We can automate the first steps in these investigations by measuring the contribution of various parts of the application to own time. This would speed up root cause analysis and limit time spent manually profiling CPU usage.</p><h3>Conclusion</h3><p>Own time has allowed us to isolate the runtime performance characteristics of Viaduct, our GraphQL-based data-oriented service mesh. Using own time, we can precisely measure the production runtime performance effects of application changes, set downstream-independent performance goals, and measure our long-term progress against those goals for an arbitrary underlying application. Enriching own time with application-specific data, such as fetched field counts and cache hit/miss states in Viaduct, gives us an overarching view of the relationship between an application’s state and its runtime performance characteristics.</p><h3>Acknowledgements</h3><p>Thanks to everyone who made this work possible by supporting the Viaduct framework, brainstorming ideas and providing feedback on this post, including Aileen Chen, Yuchun Chen, Zoran Dimitrijevic, Adam Miskiewicz, Parth Shah, Raymie Stata, and Kim Strauch.</p><p>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f4373f586ca" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/measuring-latency-overhead-with-own-time-f4373f586ca">Measuring Latency Overhead with Own Time</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Artificial Counterfactual Estimation (ACE): Machine Learning-Based Causal Inference at Airbnb]]></title>
            <link>https://medium.com/airbnb-engineering/artificial-counterfactual-estimation-ace-machine-learning-based-causal-inference-at-airbnb-ee32ee4d0512?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/ee32ee4d0512</guid>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[experimentation]]></category>
            <category><![CDATA[causality]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[causal-inference]]></category>
            <dc:creator><![CDATA[zhiying gu]]></dc:creator>
            <pubDate>Wed, 16 Mar 2022 19:34:04 GMT</pubDate>
            <atom:updated>2022-03-16T19:34:04.610Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*EQ_C2aqZE91XHEJ4" /></figure><p><strong>By:</strong><a href="https://www.linkedin.com/in/zhiying-gu-2293a353/"><strong> Zhiying Gu</strong></a><strong>, </strong><a href="https://www.linkedin.com/in/qianrongwu/"><strong>Qianrong Wu</strong></a></p><h3>Summary</h3><p>What if you wanted to measure the impact of a change to your business, but it was not possible to run a randomized controlled experiment? That’s exactly the problem we faced when measuring the benefit of a new tool used by Airbnb operations to automate part of their workflow. Due to organizational constraints, it was simply not possible to randomly assign the tool to operations agents; even if we could make random assignments, the sample sizes were too small to generate sufficient statistical power. So what did we do? We imagined a parallel universe in which the operations agents who did not use the new tool were identical in all respects to those who did–in other words, a world in which the assignment criteria were as good as random. In this blog post, we explain this new methodology, called <strong>ACE (Artificial Counterfactual Estimation)</strong>, which leverages machine learning (ML) and causal inference to artificially reproduce the “counterfactual” scenario produced by random assignment. We’ll explain how this works in practice, why it is better than other methods such as matching and synthetic control, and how we overcame challenges associated with this method.</p><h3>The Non-Randomizable Operations Problem</h3><p>There are two key assumptions undergirding randomized controlled <a href="https://medium.com/airbnb-engineering/experiments-at-airbnb-e2db3abf39e7">experiments</a> (often referred to as “A/B tests”):</p><ol><li>The treatment and control groups are similar. When you have similar groups, outcomes are independent of group attributes such as age, gender, and location, meaning that any difference between the groups can be attributed to a treatment that was received by one group but not the other. In statistical terms, we assume that we have controlled all confounders, thereby reducing the bias of our estimates.</li><li>The sample sizes are sufficiently large. Large sample sizes serve to reduce the magnitude of chance differences between the two randomized groups, giving us confidence that the treatment has a true causal impact. In technical lingo, we assume that we have reduced the variance of our estimates enough to give us appropriate statistical power.</li></ol><p>Given the need for similar groups and large sample sizes when running A/B tests, any organization with operational teams presents challenges. To start, there are general concerns about unfairness and disruptive experience when running randomized experiments on operations agents. Second, the operational sites are located in different countries with varied amounts of employees, skill levels and so on so we cannot simply assign certain geographies to treatment and some to control without introducing apples-to-oranges comparison, which will lead to bias of the measurement. Finally, we have millions of customers but not millions of operations agents, so the sample size for this test is always going to be much smaller than that of other experiments.</p><h3>ACE to the Rescue</h3><p>With the ACE (<strong>Artificial Counterfactual Estimation)</strong>, we have the next best thing to a randomized experiment. The trick is to achieve <strong>bias reduction and variance reduction</strong> at the same time using a machine learning-based causal impact estimation technique.</p><p>Causal inference is a process of estimating the counterfactual outcome that would have occurred had the treated units not been treated. In our case, we want to know how productive our operations agents would have been, had they not used the new workflow automation tool. There are many ways to construct such a counterfactual outcome, but the most common methods are:</p><ul><li>Use the control group from a randomized controlled experiment (unfortunately, is often times not possible in our case)</li><li>Construct a group that is similar to the treated group using matching methods such as Propensity Score Matching (Weighting), <a href="https://gking.harvard.edu/files/political_analysis-2011-iacus-pan_mpr013.pdf">Coarsened Exact Matching</a>, or <a href="https://web.stanford.edu/~jhain/Paper/PA2012.pdf">Entropy Balancing</a></li><li>Construct the counterfactual outcome with time-series predictions (e.g., <a href="https://research.google/pubs/pub41854/">Causal Impact Model</a>)</li><li>Construct the counterfactual outcome as the weighted average of all non-treated units (<a href="https://economics.mit.edu/files/11859">Synthetic Control</a>, <a href="https://www.cambridge.org/core/journals/political-analysis/article/generalized-synthetic-control-method-causal-inference-with-interactive-fixed-effects-models/B63A8BD7C239DD4141C67DA10CD0E4F3">Generalized Synthetic Control</a>)</li></ul><p>We can construct the counterfactual outcome by ML prediction using both confounding and non-confounding factors as features. In a nutshell, we use a holdout group (i.e., the group not treated)) to train an ML model that predicts the counterfactual outcome being not treated in the post-treatment period. We then apply the trained model to the treated group <strong>for the same period. </strong>The<strong> </strong>predicted outcome serves as the counterfactual (new control) representing the imagined scenario in which the treatment group had not been treated in the post-treatment period<strong> </strong>(<em>Y’’</em><strong> </strong>in the equation below).</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/194/1*NKttYN8--2qKUiGFtU6b3w.png" /></figure><p><strong>In the equation above,<em> t </em>is the difference between the observed treatment group outcome </strong>(Y)<strong> and the predicted outcome </strong>(<em>Y’’</em>). It represents <strong>a <em>naive</em> estimate of the impact </strong>because it<strong> is <em>biased</em>. </strong>The following graph illustrates ACE at a high level. It has the following steps as illustrated in Figure 1:</p><ol><li>We train a machine learning model using data from a hold out group, i.e. a group without treatment.</li><li>We apply the trained model on the treatment group to obtain the predicted outcome had we not applied treatment on this group.</li><li>The difference between the actual and the predicted outcome for the treatment group is the estimated impact.</li></ol><p>We will flesh out the detailed challenges in a later section before its application.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1007/0*GymYMQAYRWRjpbf-" /><figcaption>Figure 1: Estimation Process</figcaption></figure><h3>Challenges of ACE, and Solutions</h3><p>There are two major challenges in developing ACE: bias estimation and construction of confidence intervals.</p><h3>Challenge 1: Bias estimation</h3><p>The predicted outcome <strong><em>Y’’</em> </strong>from the machine learning models is often biased for two reasons, causing the estimated causal impact <em>t</em> to also be biased (see <a href="https://academic.oup.com/ectj/article/21/1/C1/5056401">Chernozhukov et. al. (2018)</a>). The two reasons for bias are 1) regularization, and 2) overfitting.</p><p>The figure below shows the ML model prediction error on 100 synthetic A/A tests, for which the estimated impact should always be zero. Clearly, however, the distribution of estimates is not centered around zero. The average prediction error is actually 2%, meaning that the ML prediction <em>Y’’</em> is, on average, overestimated by 2%.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/492/0*AQMF97y43O2klwcr" /><figcaption>Figure 2: Prediction Bias</figcaption></figure><h3>Challenge 2: Construction of Confidence Intervals</h3><p>Unlike in a traditional t-test for A/B testing, there is no analytical solution for confidence intervals when we are doing ACE. As a result, we have to construct empirical confidence intervals for the estimates. To address these two challenges, we took an empirical approach to removing bias from the prediction and then constructed our confidence intervals based on that same empirical approach.</p><p>In ACE, we use A/A tests both for debiasing and for constructing confidence Intervals.</p><h3>Solution to Challenge 1: Debias</h3><p>One natural idea is that if we can confidently estimate the magnitude of the bias, we can simply adjust the prediction by the estimated bias. The estimation then becomes:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/408/1*tf49yKKBFKPqxqyxkTa4EA.png" /></figure><p>Practitioners can freely choose any machine learning models to use — <em>f(X) </em>— for the prediction of <em>Y’’.</em> Figure 2 shows a 2% bias for 100 A/A samples. The question is: can we say the true bias is 2%? If we can verify that the bias is systematically 2% (i.e., consistent across different A/A samples during the same periods and repeatable across different time periods), we can say bias = 2%. Figure 3 shows the repeatability of the bias estimation over time. The estimates are always biased upwards and the average estimates of bias are around 2%. Figure 4 shows the average prediction error after removing the bias (2%). With bias correction, the distribution of estimated impact is centered around zero.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*3VxewhXE-I6q6e3B" /><figcaption>Figure 3: the stability of bias estimation</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/846/0*BIyfw_s9Jo80_zya" /><figcaption>Figure 4: Distribution of impact estimates based on A/A after bias correction</figcaption></figure><h3>Solution to Challenge 2: Construct Empirical Confidence Intervals</h3><p>We can use data from A/A tests to construct empirical confidence intervals and p-values.</p><ul><li>Empirical confidence interval: to be more specific, the 95% confidence interval is constructed by looking at the distribution of 100 bootstrapped A/A samples. Given that we know the true differences of A/A tests are 0, and if 5% of estimated impacts from 100 A/A tests are outside [-0.2, 0.2] range, then we know the 95% confidence interval is [-0.2, 0.2].</li><li>Empirical p-value: we can estimate Type I error via A/A tests estimated from ML models as follows. Suppose we estimated a 3% of the impact for the treatment. P-value is to estimate the probability of obtaining an estimate that is outside [-3%, 3%] when the null hypothesis is true — there is no impact. This probably is estimated with the empirical distribution of iterative A/A tests. If the probability is 1%, we will conclude that we have at least 98% (i.e 100% — (1%*2)) confidence that the alternative hypothesis — the impact is not zero — is true.</li></ul><h3>Validation</h3><p>To validate if ACE can accurately measure the impact, we further ACE to the data from a large scale randomized A/B data and compared ACE results with the A/B tests results. The result from the A/B test is considered as ground truth for validation because A/B testing is the gold standard for measurement. The results are nearly identical.</p><h3>Advantages of ACE</h3><p>There are several advantages of ACE over other estimation methods:</p><ul><li>It is flexible in the choice of estimation model. We can freely choose any cutting-edge ML models to achieve desired level of accuracy, based on various use cases and data properties..</li><li>Its validity and accuracy can be easily assessed during the design phase of the measurement plan by conducting A/A tests.</li><li>It can be applied on both experimental data for variance reduction and on non-experimental data for bias correction as well as for variance reduction.</li><li>For experimental data:<br>- It is less prone to biases compared to regression adjustments. <br>- It has more power compared to stratification when the ML model has a good performance. <br>- It estimates the magnitude of the impacts instead of only the existence of the impacts compared to rank tests.</li></ul><p>You’ll recall that we applied ACE to estimate the incremental benefit of a tool that helps operations agents to automate part of their workflow. We generated p-values for three different measurement methodologies: (1) classic t-test; (2) <a href="https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test">non-parametric rank test</a> and (3) ACE non-parametric test based on the empirical confidence interval we described in the previous section. The following is a performance comparison for t-test, rank test, and ML-based methods for the same sample size, in particular, when sample size is small when we try to conduct inference with classic t-test as we do in A/B testing.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*EnfVbOcLKkcDHoEa" /></figure><h3>Recap</h3><p>In this blog post, we explained how one can leverage ML for counterfactual prediction, using an estimation problem for the efficacy of an agent tool as our motivating example.</p><p>Combining statistical inference and machine learning methods is a powerful approach when it’s not possible to run an A/B test. However, as we have seen, it can be dangerous to apply ML methodologies if intrinsic model bias is not addressed.. This post outlined a practical and reliable way to correct for this intrinsic bias, while minimizing Type I error relative to competing methods.</p><p>Currently, we are working to turn our code template into an easy-to-use Python package that will be accessible to all data scientists within the company.</p><p>If this type of work interests you, check out some of our related positions!</p><p><a href="https://careers.airbnb.com/positions/3859241/">Senior Data Scientist — Payments</a></p><h3>Acknowledgments</h3><p>Thanks to Alex Deng and Lo-hua Yuan for providing feedback on the development of ACE and spending time reviewing the work. We would also like to thank Airbnb Experiment Review Committee Members for feedback and comments. Last but not least, we really appreciate Joy Zhang and Nathan Triplett for their guidance, and feedback and support from Tina Su, Raj Rajagopal and Andy Yasutake.</p><h3>References</h3><ul><li>Stefano M. Iacus, King, Gary, Giuseppe Porro, 2017. <a href="https://gking.harvard.edu/files/political_analysis-2011-iacus-pan_mpr013.pdf">Causal Inference without Balance Checking: Coarsened Exact Matching</a>, <em>Political Analysis.</em></li><li>Jens Hainmueller, 2012, <a href="https://web.stanford.edu/~jhain/Paper/PA2012.pdf">Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies</a>, <em>Political Analysis.</em></li><li><a href="https://research.google/people/KayBrodersen/">Kay H. Brodersen</a>, Fabian Gallusser, Jim Koehler, <a href="https://research.google/people/NicolasRemy/">Nicolas Remy</a>, Steven L. Scott, 2015. <a href="https://research.google/pubs/pub41854/">Inferring causal impact using Bayesian structural time-series models</a>, <em>Annals of Applied Statistics</em>.</li><li>Alberto Abadie, Alexis Diamond, and Jens Hainmueller, 2010. <a href="https://economics.mit.edu/files/11859">Synthetic Control Methods for Comparative Case Studies: Estimating the Effect of California’s Tobacco Control Program</a>, <em>Journal of the American Statistical Association.</em></li><li>Yiqing Xu, 2017.<a href="https://www.cambridge.org/core/journals/political-analysis/article/generalized-synthetic-control-method-causal-inference-with-interactive-fixed-effects-models/B63A8BD7C239DD4141C67DA10CD0E4F3">Generalized Synthetic Control Method: Causal Inference with Interactive Fixed Effects Models</a>, <em>Political Analysis.</em></li><li>Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, James Robins, 2018. <a href="https://academic.oup.com/ectj/article/21/1/C1/5056401">Double/debiased machine learning for treatment and structural parameters</a>,<em> The Econometrics Journal.</em></li></ul><h3>Further Reading on Similar Topic</h3><ul><li><a href="https://medium.com/airbnb-engineering/how-airbnb-measures-future-value-to-standardize-tradeoffs-3aa99a941ba5">How Airbnb Measures Future Value to Standardize Tradeoff</a></li></ul><h3>****************</h3><p><em>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ee32ee4d0512" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/artificial-counterfactual-estimation-ace-machine-learning-based-causal-inference-at-airbnb-ee32ee4d0512">Artificial Counterfactual Estimation (ACE): Machine Learning-Based Causal Inference at Airbnb</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rebuilding Payment Orchestration at Airbnb]]></title>
            <link>https://medium.com/airbnb-engineering/rebuilding-payment-orchestration-at-airbnb-341d194a781b?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/341d194a781b</guid>
            <category><![CDATA[technology]]></category>
            <category><![CDATA[tech]]></category>
            <category><![CDATA[payments]]></category>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[infrastructure]]></category>
            <dc:creator><![CDATA[Bryon Ross]]></dc:creator>
            <pubDate>Thu, 24 Feb 2022 19:47:55 GMT</pubDate>
            <atom:updated>2022-02-24T19:48:41.588Z</atom:updated>
            <content:encoded><![CDATA[<h4>How we maintained reliable money movement while migrating Airbnb’s payment orchestration system from the legacy monolithic application to a service-oriented architecture</h4><p><strong>By:</strong> <a href="https://www.linkedin.com/in/bryon-ross/">Bryon Ross</a>, <a href="https://www.linkedin.com/in/feifeng-yang-339b8b33/">Feifeng Yang</a>, <a href="https://www.linkedin.com/in/sophie-behr-6874b734/">Sophie Behr</a>, <a href="https://www.linkedin.com/in/johnsont/">Theresa Johnson</a>, <a href="https://www.linkedin.com/in/xin-lin-39527b58/">Xin Lin</a>, <a href="https://www.linkedin.com/in/yunjincho/">Yun Jin Cho</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*xkVmheTk8AghzmfFEJuIKg.jpeg" /></figure><h3>Introduction</h3><p>Airbnb’s payment orchestration system is responsible for ensuring reliable money movement between hosts, guests, and Airbnb. In short, guests should be charged the right amount at the right time using their selected payment methods; hosts should be paid the right amount at the right time to their desired payout methods. For historical reasons, Airbnb’s billing data, payment APIs, payment orchestration, and user experiences were tightly coupled with the concept of a reservation for a stay. Unfortunately, this meant that a payment-related feature for stays had to be rebuilt for other products — for example, Airbnb Experiences — and each implementation may have its own product-specific quirks. As you can imagine, this approach is neither scalable nor easy to maintain.</p><p>For several years, Airbnb has been migrating away from our monolithic Ruby on Rails application toward a service-oriented architecture (SOA). This migration has been discussed extensively in several Airbnb <a href="https://medium.com/airbnb-engineering/building-services-at-airbnb-part-1-c4c1d8fa811b">tech</a> <a href="https://medium.com/airbnb-engineering/building-services-at-airbnb-part-2-142be1c5d506">blog</a> <a href="https://medium.com/airbnb-engineering/building-services-at-airbnb-part-3-ac6d4972fc2d">posts</a>. We will gloss over some of the technical discussions common to those migrations and instead focus on some of the aspects that were unique to migrating our payments systems. While many teams at Airbnb chose to create a one-to-one replacement when migrating to SOA, the payments organization instead decided to use it as an opportunity to fundamentally redesign our services to provide a sound technical foundation for future growth. As a consequence of this decision, the migration process took longer to complete than a more straightforward one-to-one replacement.</p><h3>Why Redesign?</h3><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FMssx8PleeYc%3Ffeature%3Doembed&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DMssx8PleeYc&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FMssx8PleeYc%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube" width="854" height="480" frameborder="0" scrolling="no"><a href="https://medium.com/media/20c047e574ac84523c61f08a3e5c51b0/href">https://medium.com/media/20c047e574ac84523c61f08a3e5c51b0/href</a></iframe><p>As Brian shared in the video above, support for on-platform payments has played a critical role in establishing trust among Airbnb’s hosts and guests. Airbnb has grown significantly since our first payment system was created over a decade ago and, with that growth, the scope and scale of payments at Airbnb have also grown and changed. Many of the original payment models were tied closely to reservations for a stay. This made sense in the early days of Airbnb as there was only one product, and the engineers working on payments at that time did an excellent job developing a solution that solved the needs of guests and hosts. While these original models used for payments have proven extremely versatile and powerful, this tight coupling between stays and payments has led to increased complexity when adding new products like Experiences or features like the Resolution Center.</p><p>When planning for the SOA migration, Airbnb’s payments teams made a bold decision to fundamentally redesign the payments system. Our goal was to create a payment platform that would allow teams across Airbnb to quickly, easily, and safely integrate new features and products with payments. It’s not feasible to list all of the enhancements in a single blog post, so this post will focus on some design highlights affecting the new payment orchestration system: idempotency, platformization, and data immutability.</p><h4>Idempotent Orchestration</h4><p>As discussed in an <a href="https://medium.com/airbnb-engineering/avoiding-double-payments-in-a-distributed-payments-system-2981f6b070bb">earlier blog post</a>, idempotency is a common technique to maintain consistency among distributed services. The new payment orchestration system was designed around Orpheus (the idempotency framework described in that post). Every major workflow is divided into a directed acyclic graph (DAG) of retryable idempotent steps, each with well-defined behavior. This allows the payment orchestration layer to maintain eventual consistency with other key services (such as the payment gateway layer and product fulfillment services). This approach has led to five 9s (99.999%) of consistency for payments.</p><p>The idempotency framework works well for both synchronous and asynchronous communication between services. For asynchronous communication, payments services primarily use a Kafka-based message bus to send “events” to one another. Event processors use the idempotency framework to enhance the at-least-once guarantee of Kafka into an exactly-once guarantee. The transactional integrity analysis tools described in <a href="https://medium.com/airbnb-engineering/measuring-transactional-integrity-in-airbnbs-distributed-payment-ecosystem-a670d6926d22">this post</a> provide an additional layer of confidence by ensuring consistency between events and transactional data sources.</p><h4>Product-Agnostic Platform</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*wXTahHCWmRKVpdsQeFwa3w.png" /><figcaption>The payments SOA migration decoupled product fulfillment, payment orchestration, and pricing</figcaption></figure><p>A significant disadvantage of our legacy payment data models is that they were closely tied to a single product, reservations for stays. For this reason, our new payment orchestration service was intentionally architected to avoid tightly coupling the payments system to any particular product. Instead, the new orchestration layer was designed around generic payment-specific workflows (e.g., validation, payment processing, financial reporting) with payment-specific logic and product-specific logic isolated from one another, with the exception of a few well-defined integration points. When combined with the generic billing and pricing APIs described in <a href="https://medium.com/airbnb-engineering/scaling-airbnbs-payment-platform-43ebfc99b324">this blog post</a>, this approach allows new products to integrate quickly and easily with existing generic payment flows, drastically reducing both engineering effort and time to delivery. Additionally, as new features are added to the payment systems, these features can be easily adopted by other products.</p><h4>Data Immutability</h4><p>Immutable data is easier to understand, audit, and reconcile. All of the new payment services were built around the idea of data immutability. For payment orchestration, data immutability manifests in two major forms: persistent events and versioning. Events are naturally append-only. It is the responsibility of the event consumer to determine if a new event represents a modification to an existing event. When an existing product is altered (e.g., adding another night to a stay), the modifications to the payment orchestration plan are modeled as a new version in a sequence of plans for that product. The combined information from all the versions provides a complete history of the intended and actual money movement related to that product.</p><h3>A Phased Migration</h3><p>Various teams at Airbnb took different approaches to the migration towards a service-oriented architecture (SOA). Many teams chose to migrate functionality in small blocks, replacing the legacy implementation with an equivalent SOA one. Generally, with this approach, the existing system would be broken down into discrete, cohesive, functional blocks. Each block could be migrated mostly independently of the others. The behavior of each block would be well defined and the result could be trivially compared across both systems to ensure consistent results.</p><p>The Airbnb payments organization took a different approach for the migration of the various payments systems. Instead of small functional blocks, the migration for the payments systems was broken down into four major phases: Pricing, Payouts, Bookings, and Data Migration. The Pricing phase remodeled each of the product-specific pricing models into a generic model that could be used across all Airbnb products. The Payouts and Bookings phases fundamentally redesigned the way that money movement is orchestrated at Airbnb to more easily support new products, features, and business needs. The majority of the work related to payment orchestration was contained within these phases. The Data Migration phase migrated existing bookings from the legacy system to SOA, allowing the legacy system to be wound down and deprecated.</p><p>Within each phase, the migration was divided into smaller migrations, usually by feature or product. For example, in the Bookings phase, bookings for stays were migrated independently from bookings for experiences. When reasonable, those subphases were further broken down as well. The migration of bookings for stays was subdivided into over 30 milestones based on characteristics of the bookings. The relatively small scope of each milestone allowed engineers and data scientists to thoroughly test and validate each set of migrations. Additionally, the relatively independent nature of each milestone allowed many of them to be completed in parallel.</p><h3>Maintaining Two Systems</h3><p>The new payment orchestration system introduced a fundamentally redesigned data model based around the concept of a bill. Unlike the legacy model, the new data model is not tied to any specific product, but rather focuses on being sufficiently powerful, extensible, and generic to be useful for existing and future Airbnb products. One important consequence of fundamentally redesigning the payment data model was that it became non-trivial to convert from one data model to another.</p><p>In general, historical bookings and payouts were not moved from one system to another as part of the initial migration process. Rather, new bookings and payouts would be routed to SOA if they were deemed eligible. Otherwise, they would continue to be routed to the legacy system. Throughout most of the migration process, existing bookings would continue to proceed through their lifecycle in the legacy monolithic system. Only at the tail end of the migration were active bookings transitioned from the legacy system to SOA. As a result, engineering teams needed to maintain two parallel payment orchestration systems throughout virtually the entire migration process.</p><p>Most consumers of payments data don’t actually care whether the data is stored in the legacy or SOA system; they just want the data. In order to provide an easy and consistent experience for those client services, a new transformation layer was built to transparently retrieve data from the correct underlying source and to seamlessly convert them into a unified data model that could be consumed by all clients. The translation layer proved incredibly valuable as it decoupled the work of the teams working on the migration from the work of the client teams.</p><p>Nothing happens in a vacuum. While the migration was in progress, business needs arose and features had to be added to the payment orchestration system. For each feature, teams had to decide whether the changes should be implemented in only one system or in both. In many cases, this led to twice as much work in order to maintain a consistent user experience across both systems. In other cases, features were simply deferred or redesigned to avoid duplication of effort.</p><p>Finally, special care had to be taken to ensure that both systems behaved in the way that our guests and hosts expected. Ideally, guests and hosts wouldn’t even notice the difference apart from some improvements in performance. Additional tooling and workflows were created to ensure that Airbnb’s support ambassadors continued to provide a consistent experience for our guests and hosts regardless of which system was used to orchestrate payments.</p><p>One key learning from this experience was how critical it is to communicate with all stakeholders to ensure that everyone is aligned on timelines, constraints, and priorities. Maintaining two parallel systems over an extended period of time creates a lot of overhead and slows down iteration speeds for new features. It is vital to ensure that the broader organization is aligned on the timeline so that product teams aren’t unnecessarily slowed down by unexpected work related to a partially migrated system. Splitting the migration into phases helps reduce the time during which teams are impacted.</p><h3>Commitment to Craft</h3><p>Perhaps the most important part of the migration process was ensuring that the new system was built with Airbnb’s <a href="https://medium.com/airbnb-engineering/commitment-to-craft-e36d5a8efe2a">Commitment to Craft</a> in mind and thoroughly validated before being rolled out. A dedicated team of quality assurance engineers performed comprehensive manual testing of hundreds of scenarios to help to ensure consistency with the legacy system across a wide spectrum of use cases. In addition, an extensive set of unit tests, shallow integration tests, and end-to-end integration tests were created across the entire payments engineering organization to ensure the correct behavior of key payment flows. As an additional safeguard, whenever possible, asynchronous “matchup” jobs would compare the new data model and the old data model to validate that both codepaths produced consistent results.</p><h3>Conclusion</h3><p>Payments systems are complex. Taking the time to thoughtfully redesign the system can lead to improvements in maintainability, extensibility, performance, and resiliency. However, there are also noteworthy disadvantages to a long-lived migration process. The process can lead to uncertainty among clients of the service and consume resources that might otherwise be spent creating new features or optimizing existing flows. It is possible to mitigate some of these concerns by dividing the migration into smaller, well-defined milestones and ensuring regular communication with stakeholders. A thorough testing and validation plan is vital for ensuring that the new service can seamlessly replace legacy systems. By following this approach, we were able to launch a new payment orchestration system that is faster, easier to maintain, and can more easily support new products, features, and business needs.</p><p>Watch the recording of the <a href="https://www.facebook.com/AirbnbTech/videos/airbnb-tech-talk-make-money-moves/349403395953262/">Make Money Moves tech talk</a> for a more in-depth discussion of the migration of payments services to SOA.</p><p>If this type of work interests you, check out some of our related positions:</p><p><a href="https://careers.airbnb.com/positions/3393082/?gh_src=5a0351831us">Senior Software Engineer, Payments</a> (San Francisco or Seattle)</p><p><a href="https://careers.airbnb.com/positions/3393185/?gh_src=3eaf43fe1us">Staff Software Engineer, Payments</a> (San Francisco or Seattle)</p><p><a href="https://careers.airbnb.com/positions/2768475/">Manager, Engineering Payments Compliance</a> (Bangalore, India)</p><p><a href="https://careers.airbnb.com/positions/2925359/">Senior Software Engineer, Payments Compliance</a> (Bangalore, India)</p><p><a href="https://careers.airbnb.com/positions/2773515/">Staff Software Engineer, Payments Compliance</a> (Bangalore, India)</p><p><a href="https://careers.airbnb.com/positions/3197040/">Software Engineer </a>— Cities (Bangalore, India)</p><h3>Acknowledgments</h3><p>This migration has been a long journey that wouldn’t have been possible without the contributions of many people at Airbnb across several organizations including Payments, Hosting, Guest Experience, QA, and Finance. Too many people helped on this project to thank all of them here, but the authors would like to recognize Musaab At-Taras, Xuemei Bao, Ryan Bi, Abhijit Borude, Ben Bowler, Yizheng Cai, Jiaqi Chen, Haoran Cheng, Cynthia Adams, Pat Connors, David Cordoba, Chong Chung, Anqi Dai, Xinyue Deng, Rex Du, Ali Goksel, Ömer Faruk Gül, Jiajia Han, Jing Hao, Toland Hon, Jeremy Kane, Hide Kato, Fanchen Kong, Victoria Ku, Pasha Lahutski, Serena Li, Tina Li, Harry Liu, Michael Liu, Wenguo Liu, Yixia Mao, Elena Moskvichev, Eric Ning, Ika Ogeil, Christina Ou, Payut Pantawongdecha, Yixiao Peng, Yaritza Perez, Wentao Qi, Zachary Sabin, Rajen Shah, Patrick Shay, Bo Shi, Derek Shimozawa, Erika Stott, Huayan Sun, Sam Tang, Claire Thompson, Neo Tong, Alex Virrueta, Jing Wang, Bryan Wehner, Michel Weksler, Claudio Wilson, Xuanxuan Wu, Liang Xiao, Chao Xin, Serdar Yildirim, Hang Yuan, Brian Zhang, Yunfei Zhao, Jaclyn Zhong, and Linglong Zhu for their contributions over the lifetime of this project.</p><p>All product names, logos, and brands are property of their respective owners. All company, product and service names used in this website are for identification purposes only. Use of these names, logos, and brands does not imply endorsement.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=341d194a781b" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/rebuilding-payment-orchestration-at-airbnb-341d194a781b">Rebuilding Payment Orchestration at Airbnb</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[My Journey to Airbnb — Lucius DiPhillips]]></title>
            <link>https://medium.com/airbnb-engineering/my-journey-to-airbnb-lucius-diphillips-79d1f0bc72a2?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/79d1f0bc72a2</guid>
            <category><![CDATA[diversity]]></category>
            <category><![CDATA[leadership-development]]></category>
            <category><![CDATA[leadership]]></category>
            <dc:creator><![CDATA[AirbnbEng]]></dc:creator>
            <pubDate>Thu, 17 Feb 2022 19:54:26 GMT</pubDate>
            <atom:updated>2022-02-17T19:56:34.003Z</atom:updated>
            <content:encoded><![CDATA[<h3>My Journey to Airbnb — Lucius DiPhillips</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*hnM9txCDUVpdDN-u9Z9lJQ.jpeg" /></figure><p>Airbnb’s CIO on sponsorship, belonging, and the power of human connection</p><p><em>Lucius DiPhillips is the Chief Information Officer (CIO) at Airbnb. He has over 20 years of experience that spans Product Development, Information Technology, Customer Service, Financial Services, Payments, eCommerce, and Trust &amp; Safety. He has a Degree in Management Information Systems from Rensselaer Polytechnic Institute and serves as the executive sponsor for several diversity and belonging groups and initiatives across the company. Through his sponsorship, Lucius has been instrumental in helping to improve the ways in which Airbnb attracts and retains diverse technical talent.</em></p><h3>Breaking barriers and growing from adversity</h3><p>I grew up in Upstate New York, in a small town called Hudson Falls. I was raised by a single-parent mom, and I’m an only child. Growing up, we struggled financially, and I helped out wherever I could. From delivering papers as a ten-year-old to waiting tables as a high-schooler, I always had something to balance. That’s helped me as a leader to this day: balance and having that hard work ethic, and seeing my mom’s struggle as a single mom.</p><p>I’m multiracial: my mom is white and my dad has Black heritage. At an early age, I became acutely aware that I was different, and sometimes I didn’t feel like I belonged — because of how I looked, because I didn’t have both parents in the picture, and because we didn’t have a lot financially. Rather than letting my differences hold me back, I immersed myself in many things, from playing sports to the school choir and musicals. I wanted to get to know a lot of different people and ultimately go beyond the superficial labels and barriers between us.</p><p>That has become part of how I lead to this day, and how I build teams. It’s very much about connecting with people beyond what you might see on the surface, and really trying to find common ground. It was a skill that came from a dark place early on in my career, that has now become a skill that helps me be a coach, mentor, and sponsor, who invests in others and leads them to develop in their own careers.</p><h3>A career path shaped by curiosity, connections, and conversations</h3><p>I first got interested in tech in the 90s, as a student curious about this new thing called the internet. While my career started in traditional IT, I later got into product development and software development for end-users. Normally, those are two different profiles, but I’m more of a hybrid with a broad understanding of all facets of tech. I love technology, but I also love operations, leadership, and people. I have an appreciation for how we make sure that we connect what’s happening with tech to real customers, real people at the end of the day.</p><p>Making and maintaining many different personal connections with mentors and colleagues has led to a variety of opportunities in my career, and eventually brought me to Airbnb. I first came to Airbnb leading our Payments technology organization. Airbnb has a structured framework for career conversations that involves assessing your dream job, your story, your strengths, and what you want to do better, and from there identifying career development opportunities. This process led to my current role as the first CIO at Airbnb.</p><p>I feel like I have the best job as a CIO. I feel like I work for the best company in the world at Airbnb. That’s why I’m still glowing and here, going on four years later. And to me, this is just the beginning.</p><h3>Diversity and belonging in tech</h3><p>I am the co-sponsor of the Tech Diversity Council, a group of senior technical leaders at Airbnb tasked with amplifying and advocating for diversity-related projects and initiatives across our Tech org. It’s one of the most important roles that I have to play, if not the most important. And we’ve created the Council because we still have a long way to go in terms of representation across tech and across Airbnb. To me, the best way to get involved is to give my time and push ideas and vision into action that creates impact.</p><p>There isn’t just one initiative to talk about here, but rather many parallel efforts that span from wide-scale to personal. In addition to the Tech Diversity Council, we have a hyperfocus on Black in Tech as a group, and we have the Black Sponsorship Program, developed and led by Airbnb’s Black Employee Resource Group, Black@. I lead a monthly series for anyone who’s in technology that self-identifies as Black, who optionally wants to come together, to have a safe place to share, to contribute.</p><p>At Airbnb, we’ve always prided ourselves in standing for what we believe in unapologetically. With the Black Lives Matter movement and the George Floyd protests, I felt like we had the support to speak up about what we were feeling and the experiences we were having. The Black@ group created <a href="https://news.airbnb.com/activism-and-allyship-guide/">a guide</a> on how to be an ally, and we hosted many conversations about what it means to be Black in America. To me, that was the most important thing we could have been doing in that moment of time, and we continue doing it.</p><h3>Redesigning our hiring process</h3><p>I’m proud of Airbnb, because most companies don’t even talk about where they hope they go. They don’t share representation numbers. We not only share them, we say we can do better, and we’re going to do better, and here’s how and when.</p><p>One of the things we’ve done is go back to the drawing board to redesign our hiring process. Having a love of operations, data, and driving process improvements, I approached our hiring process like a product. Step by step, we looked at the data and asked “Is there a disproportionate drop-off here for certain demographics? What can we do differently?”</p><p>We realized that engineers are very unique — not just in their gender and ethnicity and work experience, but in how they’re most comfortable interviewing. So we decided to give candidates more flexibility: they might choose either to do a take-home coding test or show us some open source work they’re proud of. We also got more managers involved at the ground level to support our diversity and inclusion candidates and help them feel seen, understood, and connected to their future team. Engaging more of our diverse engineers early on in the hiring process had a huge impact.</p><p>Starting from my time with the Payments organization, I recognized the urgency of the moment and the stakes at play for underrepresented candidates and pushed the recruiting team to put changes into action rather than waiting or holding back. I call it breaking some glass — you need to break some glass every once in a while to challenge the status quo.</p><h3>A human-centric way to lead</h3><p>If you focus on belonging and engagement, and you make it a priority, then you can create a better environment for your team. When traumatic things happen, it’s important to educate others so they can be allies, as well as creating a safe space for people to share. As part of our wellness programs, we host “listening sessions.” I’ve hosted them with my leadership team, for Black@, for what was happening with the Afghan refugee situation, or when the COVID-19 pandemic was spiking in India.</p><p>I’m also passionate about demystifying the fact that work-life balance is a real thing you can actually conquer. It’s a pet peeve of mine that we talk about work-life balance. My balance is very different than any one of yours individually. So let’s talk about flexibility, and having empathy for each other’s unique needs and situations.</p><p>I care about being transparent and available, and part of the way I do that is by offering an office hours slot twice a day that anyone can sign up for at any time. We actually took that idea and scaled it with something called coffee chats. Anyone in our organization can sign up to have a coffee chat with someone else. You don’t know who it’s going to be until you show up. And that’s what I loved about my office hour slots, being able to ask, “What’s your story? How long have you been here? What’s one personal thing you’re thinking about?” At heart I want to connect with people. I want to demonstrate a human-centric way to lead.</p><p>–</p><p>Interested in working with Lucius at Airbnb? Check out these open roles:</p><p><a href="https://careers.airbnb.com/positions/3897689/">Senior Engineering Manager, Tax Platform</a></p><p><a href="https://careers.airbnb.com/positions/3873636/">Systems Engineer, Client Engineering</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=79d1f0bc72a2" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/my-journey-to-airbnb-lucius-diphillips-79d1f0bc72a2">My Journey to Airbnb — Lucius DiPhillips</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Past, Present, and Future of react-dates]]></title>
            <link>https://medium.com/airbnb-engineering/the-past-present-and-future-of-react-dates-b351ab739d3f?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/b351ab739d3f</guid>
            <category><![CDATA[open-source]]></category>
            <category><![CDATA[frontend]]></category>
            <category><![CDATA[front-end-development]]></category>
            <category><![CDATA[react]]></category>
            <category><![CDATA[javascript]]></category>
            <dc:creator><![CDATA[Diane Ko]]></dc:creator>
            <pubDate>Fri, 21 Jan 2022 17:45:50 GMT</pubDate>
            <atom:updated>2022-01-24T22:44:18.497Z</atom:updated>
            <content:encoded><![CDATA[<p><a href="https://www.linkedin.com/in/kodiane/">Diane Ko</a></p><figure><img alt="Silhouettes of two people in front of the inside of a large, clear clock overlooking a city." src="https://cdn-images-1.medium.com/max/1024/1*VymqCVttV2_VOqmmApgakw.jpeg" /></figure><p>In 2016, Airbnb released react-dates, a React date picker component library. The <a href="https://github.com/airbnb/react-dates/stargazers">project has amassed more than 11,000 stars</a>. GitHub also tells us that <a href="https://github.com/airbnb/react-dates/network/dependents">react-dates is used by over 30,000 repos</a>.</p><p>In more recent years, Airbnb’s requirements for a date picker have changed in a way that has diverged from react-dates. If we were to have made those changes to the library, it would have severely limited the flexibility of the library, one of its key features. To better support the react-dates community, we’ve made the decision to transfer ownership of the react-dates repo to a new <a href="https://github.com/react-dates">react-dates GitHub organization</a>. We believe this new home will better serve the community and continue to evolve the original goals of react-dates.</p><p>If you want to help react-dates grow, please check out the <a href="https://github.com/airbnb/react-dates/issues">open issues</a> and <a href="https://github.com/airbnb/react-dates/pulls">pull requests</a> — the <a href="https://github.com/airbnb/react-dates/labels/pull%20request%20wanted">“pull request wanted” tag</a> is a great starting point.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=b351ab739d3f" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/the-past-present-and-future-of-react-dates-b351ab739d3f">The Past, Present, and Future of react-dates</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Intelligent Automation Platform: Empowering Conversational AI and Beyond at Airbnb]]></title>
            <link>https://medium.com/airbnb-engineering/intelligent-automation-platform-empowering-conversational-ai-and-beyond-at-airbnb-869c44833ff2?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/869c44833ff2</guid>
            <category><![CDATA[engineering]]></category>
            <category><![CDATA[ai]]></category>
            <category><![CDATA[automation]]></category>
            <category><![CDATA[chatbots]]></category>
            <category><![CDATA[customer-support]]></category>
            <dc:creator><![CDATA[Zhiheng Xu]]></dc:creator>
            <pubDate>Tue, 11 Jan 2022 18:10:01 GMT</pubDate>
            <atom:updated>2022-01-11T21:19:55.329Z</atom:updated>
            <content:encoded><![CDATA[<p>How Intelligent Automation Platform supports conversational AI and agent-automation to improve the Airbnb customer experience</p><p>By <a href="https://www.linkedin.com/in/zhiheng-xu-50249b31/">Zhiheng Xu</a>, <a href="https://www.linkedin.com/in/yi-alex-zhou-1284651b/">Alex Zhou</a>, <a href="https://www.linkedin.com/in/chutianwang/">Jeremy Wang</a>, <a href="https://www.linkedin.com/in/zecheng-xu-11bb778a/">Zecheng Xu</a>, <a href="https://www.linkedin.com/in/ziyi-wang-6651b5b1/">Ziyi Wang</a>, <a href="https://www.linkedin.com/in/jiayu-lou-337ba785/">Jiayu Lou</a>, <a href="https://www.linkedin.com/in/liuming-zhang-4b120894/">Liuming Zhang</a>, <a href="https://www.linkedin.com/in/fengjian-pan/">Gary Pan</a>, Jeffrey Zhao, Yisong Wang, <a href="https://www.linkedin.com/in/priyanksinghal/">Priyank Singhal</a>, <a href="https://www.linkedin.com/in/clairexiong/">Claire Xiong</a>, <a href="https://medium.com/@waynezhang511">Wayne Zhang</a>, <a href="https://www.linkedin.com/in/benmatata2020/">Ben Ma</a>, <a href="https://www.linkedin.com/in/hao-wang-2661553/">Hao Wang</a>, Carter Appleton, Anthony Clifton</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*-OP5Y1xe4uxuNzvn" /></figure><p>With the rapid development of Machine Learning and Natural Language Processing technologies, conversational AI has attracted huge attention in recent years. More and more conversational AI applications such as virtual assistants, smart speakers, and customer support chatbots have been developed to help people in their daily lives.</p><p>At Airbnb, we have developed multiple conversational AI products to enhance our host and guest experience. Examples include our <a href="https://medium.com/airbnb-engineering/using-chatbots-to-provide-faster-covid-19-community-support-567c97c5c1c9">chatbot systems</a>, which support users through in-app messaging or automated phone calls, our <a href="https://medium.com/airbnb-engineering/task-oriented-conversational-ai-in-airbnb-customer-support-5ebf49169eaa">task-oriented ML framework</a> for issue detection and automatic problem solving, and various on-trip support products to proactively help guests improve their experience while they are on trip.</p><p>In this blog post, we introduce the <strong><em>Intelligent Automation Platform</em></strong> (AP), a generic enterprise-level platform developed by Airbnb to support a suite of conversational AI products. From this point forward, the Intelligent Automation Platform will be referenced as “AP”.</p><p>By modeling Conversational AI products as <a href="https://en.wikipedia.org/wiki/Markov_decision_process">Markov Decision Process</a> (MDP) workflows, AP provides a unified representation of workflows and actions to facilitate workflow consolidation and action reusability. Additionally, the platform offers a GUI development tool to enable drag-and-drop workflow creation, facilitate fast iteration of products, and empower non-technical teams to build conversational AI products.</p><h3><strong>1. Platform Architecture</strong></h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*UIcZmMClcOTgHDDW" /><figcaption>Figure 1: AP Architecture</figcaption></figure><p>Figure 1 shows the high-level architecture of AP, which consists of 4 main components:</p><ol><li><strong>Event Orchestrator</strong>, the event orchestration layer of the platform. It translates input/output messages between clients and Workflow Engine, to ensure that workflows on AP can be built and executed in a generic way.</li><li><strong>Workflow Engine</strong>, the “brain” of the platform. It is responsible for managing and executing all the workflows powered by the platform.</li><li><strong>Action Store</strong>, the action execution engine of the platform. It supports action requests during workflow execution. Action Store is an open platform for developers to create new actions or reuse existing ones. By using actions in the Action Store, we standardize task execution based on different systems and backends, and ensure consistent user experience across different products.</li><li><strong>Flow Builder</strong>, the workflow creation GUI tool of the platform. It’s a collaborative, drag-and-drop interface that simplifies creation and management of workflows. The output of Flow Builder are workflows that can be loaded and executed by Workflow Engine.</li></ol><p>Figure 2 shows an example of a demo “Q &amp; A” workflow on AP. The demo workflow, configured via Flow Builder, can answer users’ questions from different channels (such as messaging or phone).</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*FnBOBUiWhA2gjW8t" /><figcaption>Figure 2: A Demo Q&amp;A Workflow on AP</figcaption></figure><p>When the platform receives a request for the “Q &amp; A” workflow, it triggers:</p><ol><li>Event Orchestrator to normalize the request and find the corresponding workflow session if it exists (a workflow session is a single instance of the workflow), and then forward the request to Workflow Engine.</li><li>Workflow Engine to restore the previous state of the workflow or create a new one from the start node (state), and then execute the workflow: a) Execute the actions defined for the current workflow state. b) Move the workflow to the next state based on the action results or other conditions. c) Pause the workflow and wait for the next input if needed.</li><li>Action Store to execute all the actions required by Workflow Engine.</li></ol><h3>2. Key Components of Intelligent Automation Platform</h3><h4>2.1 Event Orchestrator</h4><p>One of the design principles of AP is to provide channel-agnostic problem solving capabilities (channels represent the source of requests, such as in-app chatbot or phone). Workflows and Actions are intended to be channel-agnostic, focusing on the core of the problem no matter which channel users choose to contact us via to resolve their issues.</p><p><strong><em>Event Orchestrator</em></strong> is the event orchestration layer of AP. It normalizes the input and output of the platform to ensure that conversational workflows can be built and executed in a channel-agnostic way. Figure 3 provides the architecture of Event Orchestrator, which contains 3 layers: orchestration layer, context data layer, and workflow request layer.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*B_Xp_EsngxICFpgh" /><figcaption>Figure 3: Event Orchestrator Architecture</figcaption></figure><p>The orchestration layer handles all the requests and responses. It currently supports 3 types of input:</p><ol><li><strong>Channel message</strong>. These are messages delivered from different channels, such as phone, email or in-app messaging.</li><li><strong>Async events</strong>. These are async events (such as <a href="https://kafka.apache.org/intro">Kafka</a> events) generated by different Airbnb internal systems, like cancellation events.</li><li><strong>Internal service requests</strong>. Event Orchestrator also provides a few endpoints to handle workflow requests from other Airbnb internal services directly.</li></ol><p>Context data layer stores all contextual information related to the platform requests. Before creating a workflow request to the <em>Workflow Engine</em>, context data layer: a) Identifies whether the request is about a new workflow session or an existing one, by looking up the session mapping tables. b) Restores critical contextual information for workflow execution by reading from session data tables.</p><p>Workflow request layer prepares the request to <em>Workflow Engine</em> for workflow execution and processes the response from <em>Workflow Engine</em>. It makes sure that platform requests from different sources are converted into the same Workflow Engine requests so that <em>Workflow Engine</em> can handle all workflows in a generic way.</p><h4>2.2 Workflow Engine</h4><p><strong><em>Workflow Engine</em></strong> is the “brain” of AP, responsible for executing and monitoring all the workflows powered by the platform.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*KCemaFJ_3_SHp3s5" /><figcaption>Figure 4: Workflow Engine Architecture</figcaption></figure><p>Figure 4 shows the overall architecture of Workflow Engine, which consists of 4 main components:</p><ol><li><strong>Session Manager</strong>. Session Manager manages the lifecycle of entire workflow execution. After receiving a workflow execution request, it will restore the previous state of the workflow (if a workflow is resumed) or create a new workflow from the start state (if a new workflow is created). When workflow needs to pause and wait for user response, Session Manager will store the current state and all workflow variables into the database, to be restored by the next request of the same session.</li><li><strong>Schema Loader</strong>. Schema Loader loads the workflow schema generated by <em>Flow Builder</em>, the workflow creation UI tool of AP. A workflow schema is a JSON schema file automatically generated by <em>Flow Builder </em>(see more details in the <em>Flow Builder</em> section).</li><li><strong>Workflow Executor</strong>. Workflow Executor executes the workflow based on the workflow schema, starting from the current state of the workflow. It processes the action defined in the current state by sending a request to the <em>Action Store</em>, handles the response, and saves the variables to the Variable Manager. After that, it moves the workflow to the next state according to the transition conditions and starts processing the next workflow state. The Workflow Executor will keep repeating the process until the workflow needs to be paused (and waiting for user response), or until it reaches the end of the workflow.</li><li><strong>Variable Manager</strong>. Variables are the data supporting workflow execution. Variable Manager manages all the variables and is accessible by Workflow Executor to read and update variables during workflow execution.</li></ol><h4>2.3 Action Store</h4><p><strong><em>Action Store</em></strong> is the action execution engine of AP, supporting action execution requests from <em>Workflow Engine</em>. It is also an open platform for developers to create new actions or reuse existing ones. All actions in the Action Store are available on <em>Flow Builder</em> for creating workflows.</p><p>As shown in figure 5, all actions in the Action Store implement a common interface, so that they can be processed in the same way during action execution (by <em>Workflow Engine</em>) and workflow creation (by <em>Flow Builder</em>). An action can be as simple as fetching a user’s reservation data or as complicated as issue prediction, which might involve multiple machine learning models and feature generation pipelines.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*mGHSc3l3YH9cd9GJ" /><figcaption>Figure 5: Action Interface</figcaption></figure><p>Figure 6 shows the high level Architecture of Action Store, which contains 3 main components:</p><ol><li><strong>Action Executor</strong>. Action Executor supports action execution requests. When receiving a request, Action Executor will load the action implementation from Action Manager based on the action type and invoke the execution function defined in the implementation. Many actions rely on external services to finish the execution, and the Action Executor will be responsible for sending those external requests and processing the response.</li><li><strong>ActionInfo Handler</strong>. ActionInfo Handler supports <em>Flow Builder</em> for workflow creation by serializing all the action information (e.g., metadata, payload, results, etc.) to <em>Flow Builder</em> to render the actions on the UI and support action configuration when creating workflows. More details are available in the <em>Flow Builder</em> section.</li><li><strong>Action Manager</strong>. Action Manager registers and manages all the actions created in the Action Store. It provides action implementation to Action Executor and ActionInfo Handler based on the action type.</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*0upy1aVoDkIG8tVJ" /><figcaption>Figure 6: Action Store Architecture</figcaption></figure><h4>2.4 Flow Builder</h4><p><strong><em>Flow Builder</em></strong> is the workflow creation UI tool of AP, supporting drag-and-drop workflow creation. It integrates with <em>Action Store</em> to retrieve all action information and sends the generated workflow schema to <em>Workflow Engine</em> during workflow execution.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*I0WVsWNOe_UV_C1f" /><figcaption>Figure 7: Flow Builder UI (Action Configuration)</figcaption></figure><p>Figure 7 illustrates the UI of Flow Builder when configuring actions in workflow. On the left is the Action Panel, which lists all available actions in the <em>Action Store</em> and supports searching by action name or description. Workflow creators can drag and drop any actions in the workflow panel and then configure the action payload by clicking the action node.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*9_Fdqmq1D3vyGtLA" /><figcaption>Figure 8: Flow Builder UI (Configure the Workflow Graph)</figcaption></figure><p>Figure 8 shows the UI when configuring the workflow graph. Workflow creators can create transitions between workflow nodes (each node can be viewed as a step or state of the workflow) by creating links between nodes and configuring the transition conditions. After all the workflow nodes and links are configured, the workflow is ready to be tested and published.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*5cY6rYs24KtGgbda" /><figcaption>Figure 9: Flow Builder Architecture</figcaption></figure><p>Figure 9 is the high level architecture of Flow Builder. It contains two major components:</p><ol><li>The frontend layer, which is built with a third-party library <a href="https://github.com/projectstorm/react-diagrams">React-diagrams</a>, supports the UI and all operations on the UI.</li><li>The backend layer, Workflow Management service, which is responsible for: a) Getting all action information from the <em>Action Store</em> and passing to the frontend layer. b) Generating workflow schema that can be executed by <em>Workflow Engine</em> from the configured workflow graph on the UI. c) Serving the workflow schema to <em>Workflow Engine</em> during workflow execution.</li></ol><p>Figure 10 gives an example of an auto-generated workflow schema that can be executed by <em>Workflow Engine</em>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*h451jjvwaI49jZTduC8Nwg.png" /><figcaption>Figure 10: Example of Auto Generated Workflow Schema</figcaption></figure><h3>3. Conclusion</h3><p>In this post, we introduced our Intelligent Automation Platform, a generic and business friendly enterprise platform to support a suite of conversational AI products at Airbnb including chatbots for customers, on-trip support products, and agent automations. With Intelligent Automation Platform, we can simplify and speed up conversational AI product development, democratize AI technology to business teams, and scale up more and more intelligent solutions to improve the Airbnb customer experience.</p><h3>Acknowledgements</h3><p>Thanks to Danny Deng, Xirui Liu, Zixuan Yang, Xiang Lan, Keyao Yang, Changhui Liu, Wenbin Zhang, Hengyu Zhou, Stephanie Pang, Jack Chen, Bart Bu, Carter Appleton, Shahaf Abileah, Mariel Young, Shuo Zhang, Wei Ji, Jiayu Liu, Kevin Jungmeisteris, Pratik Shah, Xiaoyu Meng, Michael Zhou, Haoran Zhu, Jon Sandness and Conor D’Arcy for the product collaborations.</p><p>Thanks to Tina Su, Andy Yasutake, Joy Zhang, Raj Rajagopal, Navjot Sidhu, James Eby and Julian Warszawski’s leadership support for the Intelligent Automation Platform.</p><p><em>Interested in working at Airbnb? Check out these roles:</em></p><p><a href="https://grnh.se/7de3db391us">Staff Software Engineer, CSP — Contact Solutions</a></p><p><a href="https://grnh.se/29257d691us">Senior Software Engineer, Community Support Platform</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=869c44833ff2" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/intelligent-automation-platform-empowering-conversational-ai-and-beyond-at-airbnb-869c44833ff2">Intelligent Automation Platform: Empowering Conversational AI and Beyond at Airbnb</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Airbnb’s Page Performance Score on Android]]></title>
            <link>https://medium.com/airbnb-engineering/airbnbs-page-performance-score-on-android-f9fd5e733e?source=rss----53c7c27702d5---4</link>
            <guid isPermaLink="false">https://medium.com/p/f9fd5e733e</guid>
            <category><![CDATA[mobile-performance]]></category>
            <category><![CDATA[android-performance]]></category>
            <category><![CDATA[mobile-app-development]]></category>
            <category><![CDATA[android]]></category>
            <category><![CDATA[mobile]]></category>
            <dc:creator><![CDATA[Luping Lin]]></dc:creator>
            <pubDate>Fri, 17 Dec 2021 21:06:55 GMT</pubDate>
            <atom:updated>2021-12-17T21:06:55.251Z</atom:updated>
            <content:encoded><![CDATA[<p><em>Part 4 of our series on </em><a href="https://medium.com/airbnb-engineering/creating-airbnbs-page-performance-score-5f664be0936"><em>Airbnb’s Page Performance Score</em></a>.</p><p><a href="https://www.linkedin.com/in/lupinglin/">Luping Lin</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*jv0-M5bsGxi2bcXb" /></figure><p>Airbnb’s home grown <a href="https://medium.com/airbnb-engineering/creating-airbnbs-page-performance-score-5f664be0936">Page Performance Score</a> (PPS) is designed to capture the rich, complex realities of performance by collecting a multitude of user-centric performance metrics and formulating them into one single 0-100 score. In this post we will deep dive into how we define and implement these metrics on Android. Make sure you read the <a href="https://medium.com/airbnb-engineering/creating-airbnbs-page-performance-score-5f664be0936">overview blog post</a> first to familiarize yourself with our PPS metrics and formula.</p><h3>Instrumentation</h3><h4>Universal Page Tracking System</h4><p>The entire customer journey on Airbnb is divided into different pages, each of which has its own measured PPS. In order to support this page-based performance tracking system, we built a standardized infrastructure that enables engineers to configure pages representing their features.</p><p>On Android a page is associated with a <em>Fragment</em>. Each fragment must provide a <em>LoggingConfig</em> object specifying a page name, which can later be retrieved whenever the page name needs to be referenced. We collect performance data throughout the fragment’s lifecycle, and only emit the logging event when the fragment is paused.</p><p>A universal <em>PageName</em> enum is used to uniquely identify each page, and is referenced across all platforms to consistently represent each page in our user journey.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/f32323e5d2deb216aa9f32f7949a1958/href">https://medium.com/media/f32323e5d2deb216aa9f32f7949a1958/href</a></iframe><h4>Capturing Wait Time Perceived by Users</h4><p>A key differentiator of our new Page Performance Score (PPS) is that it measures wait time that users can see. While our early measurement effort (mentioned in our <a href="https://medium.com/airbnb-engineering/creating-airbnbs-page-performance-score-5f664be0936">overview blog post</a>), which was based on the commonly known <a href="https://web.dev/interactive/">Time To Interactive</a> (TTI) metric, measures code execution time and length of asynchronous calls. For example, PPS measures how long a user sees the loading indicators on screen, while TTI measures how long it takes for a network request to return results and how long it takes to build the view models. We believe PPS more closely reflects performance experienced by our users.</p><p>In order to capture visually perceived wait time, we needed all views with a loading state to implement an API that reports their loading state changes. We created a simple interface called <em>LoadableView</em>.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/04447f5c61f6521ef61e07add16903f4/href">https://medium.com/media/04447f5c61f6521ef61e07add16903f4/href</a></iframe><p>We provide primitives such as a base <em>ViewGroup</em>, a base <em>TextView</em>, and a base <em>ImageView,</em> all of which implement the <em>LoadableView</em> interface. Our developers simply need to inherit from these primitives for their views to be automatically instrumented.</p><p>One challenge was that we needed to keep track of a view’s visibility because if a view is not at least 10% visible on the screen we don’t want to include its loading time in our measurement. The computation of the percentage of visibility of every view is both frequent and recursive. Furthermore, most of our views are in a <em>RecyclerView</em> and we must ensure their visibility is updated correctly on each scroll event, while keeping the <em>RecyclerView</em> performant. We devised algorithms to reduce the frequency and complexity of these calculations, including caching the visibility states within the <em>RecyclerView</em>.</p><h3>Metric Implementation</h3><h4>Time to First Layout (TTFL)</h4><p>TTFL measures how long a user has to wait before seeing <em>any</em> content on the screen. TTFL starts at fragment initialization and ends at the first <em>onGlobalLayout </em>event after the fragment is laid out, at which point the system has finished inflating, measuring, and laying out the fragment’s view hierarchy.</p><p>A slow TTFL often indicates that the fragment’s view hierarchy is overly complicated, or the UI thread is preoccupied with unnecessary tasks during fragment initialization.</p><h4>Time to Initial Load (TTIL)</h4><p>TTIL measures how long a user sees loading indicators (excluding media loading which is measured separately) before meaningful content is displayed on screen. TTIL starts at fragment initialization like TTFL, and ends when no more views on screen are in a loading state. If a screen (Fragment) is static or cached we don’t show a loading indicator. In that scenario TTIL would be the same as TTFL.</p><p>A slow TTIL often reveals opportunities in improving network latency or client rendering time. For network latency we look for slow backend services, large payloads, unutilized cache, or a less optimized data parser. For rendering time we try to follow best practices in using the RecyclerView, avoid doing heavy or recursive computation when building view models, and reduce over drawing, etc.</p><p>As mentioned above, views with a loading state can inherit from base primitives with built-in <em>LoadableView</em> implementations. The API automatically reports the view’s loading state changes to our logging framework. We use a simple counter that increments when a view enters loading state and decrements when the data is loaded. When the counter is 0, we know that there are no more loading views on screen.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/46ba94e7102640cf23a74c52146e8368/href">https://medium.com/media/46ba94e7102640cf23a74c52146e8368/href</a></iframe><p><em>This GIF demonstrates TTFL (marked when the gray background with the Airbnb logo is shown) and TTIL (marked when the loading dots are replaced by meaningful content).</em></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/600/0*53ZcfBamEiTotrgi" /></figure><h4>Main Thread Hangs (MTH)</h4><p>Users experience screen freezes, lags, and stutters when ui frames take too long to render. Each android device has a target frame refresh rate based on the device’s capacity. However when the main thread is too busy, the device renders slower than the frame rate it’s capable of. We define a MTH as whenever any frame takes more than twice the system’s frame refresh rate to render.</p><p>Frequent MTHs indicate that the main thread might be overloaded. Heavy operations or computations should be moved off the UI thread or delayed until contents are rendered.</p><p>MTH is calculated using <a href="https://developer.android.com/reference/android/view/FrameMetrics">FrameMetrics</a> reported by the Android system. We obtain the frame refresh rate from the system and use it to calculate the threshold for the thread hangs. We then listen for system callbacks to receive <a href="https://developer.android.com/reference/android/view/FrameMetrics">FrameMetrics</a>, if the frame duration is above our threshold, we record the delta <em>(frameDuration - hangThreshold)</em> as a hang.</p><h4>Additional Load Time (ALT)</h4><p>ALT measures any wait time that occurs after the initial load, such as waiting for list paginations or for content to be updated after a Save button is pressed. ALT starts whenever a view enters the loading state <em>after</em> TTIL has already been marked, and ends when no more loading views are shown. ALT can start and end multiple times, each time is recorded as a separate ALT.</p><p>Opportunities to improve ALT often lie in predicting and prefetching additional content. The overall PPS can also be improved by balancing how much content to load in initial load vs additional loads.</p><p><em>This GIF demonstrates ALT (marked when the loading indicator at the bottom is replaced by paginated content loaded from the network).</em></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/600/0*fptmsQJ6LfgBRQdS" /></figure><h4>Rich Content Load Time (RCLT)</h4><p>RCLT measures how long a user sees a placeholder or a loading indicator until an image, a video, or some rich media content is fully displayed. <em>ImageView</em> and other rich media containers implement the same <em>LoadableView</em> API to report loading state changes to the PPS logger.</p><p>To improve RCLT, we look to reduce image size, improve image caching, optimize image formats and serving, strategically schedule loading rich content that is not yet on screen, and select performant streaming libraries, etc.</p><p><em>This GIF demonstrates RCLT (marked when the place holders are replaced with actual images loaded from the network).</em></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/600/0*BtqfXhapm7jDuKL9" /></figure><h3>Conclusion</h3><p>We successfully built an instrumentation framework on Android to capture much richer and user-centric performance metrics, guided by the same design principles in <a href="https://medium.com/airbnb-engineering/creating-airbnbs-page-performance-score-5f664be0936"><em>Airbnb’s Page Performance Score</em></a> across web and native platforms. On top of this framework and the data collected, we built out dashboards to monitor performance across the entire app, set up automatic alerts targeting page owners, streamlined performance goal setting at team and org levels, and systematically tracked and mitigated performance regressions.</p><p>In 2022, we plan to improve the granularity and accuracy of our instrumentations such as measuring tap responsiveness, better differentiating performance during scrolling, and providing primitives with built-in performance optimizations. We will also devote resources to build tooling to improve debuggability, and enable early regression detection and prevention via synthetic testing.</p><p>PPS gives our engineers and data scientists better insights and more ways to improve our products. It also strengthens our <a href="https://medium.com/airbnb-engineering/commitment-to-craft-e36d5a8efe2a">Commitment to Craft</a> culture. We hope that you apply these learnings in your organization as well.</p><h4>Appreciations</h4><p>Thank you to everyone who has helped build PPS on Android: <a href="https://www.linkedin.com/in/eli-hart-54a4b975/">Eli Hart</a>, <a href="https://www.linkedin.com/in/charlesx2013/">Charles Xue</a>, <a href="https://www.linkedin.com/in/nickbryanmiller/">Nick Miller</a>, <a href="https://www.linkedin.com/in/scheuermann/">Andrew Scheuermann</a>, <a href="https://www.linkedin.com/in/hdezninirola/">Antonio Niñirola</a>, <a href="https://www.linkedin.com/search/results/all/?keywords=joshua%20nelson%20%E2%9C%A8&amp;origin=RICH_QUERY_SUGGESTION&amp;position=0&amp;searchId=959d4aca-c80e-448a-b415-4a732ba7a84d&amp;sid=Rr6">Josh Nelson</a>, <a href="https://www.linkedin.com/in/adityapunjani/">Aditya Punjani</a>, <a href="https://www.linkedin.com/in/joshpolsky/">Josh Polsky</a>, <a href="https://www.linkedin.com/in/jnvollmer/">Jean-Nicolas Vollmer</a>, <a href="https://www.linkedin.com/in/wensheng-mao-76ab7142/">Wensheng Mao</a> and everyone else who helped along the way.</p><p>Interested in working at Airbnb? Check out these roles:<br><a href="https://grnh.se/6c9839421us">Staff Android Engineer</a><br><a href="https://grnh.se/1e5c9bf51us">Senior Android Engineer</a> <br><a href="https://grnh.se/aa366a2e1us">Senior Android Engineer</a><br><a href="https://grnh.se/20c296251us">Android Engineer, Special Projects</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f9fd5e733e" width="1" height="1" alt=""><hr><p><a href="https://medium.com/airbnb-engineering/airbnbs-page-performance-score-on-android-f9fd5e733e">Airbnb’s Page Performance Score on Android</a> was originally published in <a href="https://medium.com/airbnb-engineering">The Airbnb Tech Blog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
    </channel>
</rss>